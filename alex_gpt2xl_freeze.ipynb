{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expandable_segments:True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, AdamW, get_scheduler, GPT2Config\n",
    "from torch.nn.functional import softmax\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchmetrics import F1Score\n",
    "pd.options.mode.copy_on_write = True\n",
    "from accelerate import init_empty_weights, infer_auto_device_map\n",
    "from accelerate.utils import load_checkpoint_in_model\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "print(os.environ.get(\"PYTORCH_CUDA_ALLOC_CONF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath2 = \"./datasets_ready/Task_Achievement.csv\"\n",
    "df2 = pd.read_csv(fpath2)\n",
    "df2['score'] = df2['score'].round(1)\n",
    "df_filtered2 = df2[(df2['score'] > 1.5) & (df2['score'] < 12.0)]\n",
    "\n",
    "reverse_mapping_3 = {\n",
    "    3.5: 0, 4.0: 0,\n",
    "    4.5: 1, 5.0: 1,\n",
    "    5.5: 2, 6.0: 2,\n",
    "    6.5: 3, 7.0: 3,\n",
    "    7.5: 4, 8.0: 4,\n",
    "    8.5: 5, 9.0: 5\n",
    "}\n",
    "\n",
    "df_filtered2['score'] = df_filtered2['score'].map(reverse_mapping_3)\n",
    "\n",
    "df_sampled2 = df_filtered2.groupby('score').sample(\n",
    "    n=290, \n",
    "    random_state=42\n",
    ").reset_index(drop=True)\n",
    "\n",
    "df_sampled2['score'] = df_sampled2['score'].astype(int)\n",
    "\n",
    "dataset2 = Dataset.from_pandas(df_sampled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4292d1681226446e8ca8dc2a5dbd5469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\26597\\miniconda3\\envs\\ece1786\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\26597\\.cache\\huggingface\\hub\\models--openai-community--gpt2-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9eb721845d4034bd155d435360113b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842a1ab8b4e5472ca3385fc4146e38f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3585c7524c3045148a28fc28baa08dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0295362a33c438bb2d39ed4a05b5180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a69b0e891894f0b843451acb757aa18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2-large and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\26597\\miniconda3\\envs\\ece1786\\lib\\site-packages\\torch\\nn\\modules\\module.py:1160: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8986b0599045689fa44d796f0357d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1740 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\26597\\miniconda3\\envs\\ece1786\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/522 [00:00<?, ?it/s]c:\\Users\\26597\\miniconda3\\envs\\ece1786\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:545: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      " 33%|███▎      | 174/522 [3:26:54<7:10:16, 74.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: train loss 1.8396, val loss 1.7863, val accuracy 0.2085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 348/522 [7:54:40<3:39:38, 75.74s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: train loss 1.8050, val loss 1.7706, val accuracy 0.2232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [12:26:11<00:00, 76.39s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: train loss 1.8063, val loss 1.7665, val accuracy 0.2389\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADNI0lEQVR4nOzdd3gUZcPF4d9m0yuhh947hB6CIqJUEUVEIr2EpigiVkSaDcGuCCgCoYYAAvq+IgoKgtJCCV2k14ROEhJSd74/eNnPEEoCIZNy7uvaCzL7zMzZJQsPJ1MshmEYiIiIiIiIiIiIZCMHswOIiIiIiIiIiEj+o1JKRERERERERESynUopERERERERERHJdiqlREREREREREQk26mUEhERERERERGRbKdSSkREREREREREsp1KKRERERERERERyXYqpUREREREREREJNuplBIRERERERERkWynUkoki1gslgw91qxZc0/7GTt2LBaL5a7WXbNmTZZkyOn69OlDuXLlbvn8uXPncHZ25tlnn73lmJiYGNzd3XniiScyvN+QkBAsFgtHjx7NcJZ/s1gsjB07NsP7u+706dOMHTuWiIiIdM/dy/fLvSpXrhyPP/64KfsWERHJbZ566inc3Ny4fPnyLcd0794dJycnzpw5k+Ht3ji/yMx8MDPzmBtNnjyZkJCQdMuPHj2KxWK56XP32/V50c0ekyZNso+bPXs2zz77LFWrVsXBweGu3wMRuTNHswOI5BUbNmxI8/W7777L6tWr+f3339Msr1Gjxj3tp3///rRt2/au1q1fvz4bNmy45wy5XZEiRXjiiSdYtmwZly5dwtfXN92YBQsWcPXqVYKDg+9pX6NGjeKll166p23cyenTpxk3bhzlypWjbt26aZ67l+8XERERyT7BwcEsW7aM+fPn8/zzz6d7Pjo6mqVLl/L4449TrFixu95Pds0HJ0+eTOHChenTp0+a5X5+fmzYsIGKFSve1/3fzooVK/Dx8UmzrHz58vbfz5kzh6ioKBo3bozNZiM5OTm7I4rkGyqlRLJIkyZN0nxdpEgRHBwc0i2/UXx8PO7u7hneT6lSpShVqtRdZfT29r5jnvwiODiY77//nnnz5vHCCy+ke37GjBkUK1aM9u3b39N+zJxwwb19v4iIiEj2adeuHSVKlGDGjBk3LaVCQ0Oz5AdmZs8HXVxcTJ+PNmjQgMKFC9/y+V9++QUHh2snFT3++OPs3r07u6KJ5Ds6fU8kGz388MPUqlWLtWvX0rRpU9zd3enXrx8AYWFhtG7dGj8/P9zc3KhevTpvvvkmcXFxabZxs9Oxrp8mtWLFCurXr4+bmxvVqlVjxowZacbd7HDtPn364OnpycGDB3nsscfw9PSkdOnSvPLKKyQmJqZZ/+TJk3Tu3BkvLy8KFChA9+7dCQ8Pz9Ah2OfOneP555+nRo0aeHp6UrRoUR555BHWrVuXZtz1Q7o//vhjPv30U8qXL4+npyeBgYFs3Lgx3XZDQkKoWrUqLi4uVK9endmzZ982x3Vt2rShVKlSzJw5M91z+/btY9OmTfTq1QtHR0dWrlzJk08+SalSpXB1daVSpUoMGjSI8+fP33E/NzvsPSYmhgEDBlCoUCE8PT1p27Yt//zzT7p1Dx48SN++falcuTLu7u6ULFmSDh06sGvXLvuYNWvW0KhRIwD69u1rPwT9+mH6N/t+sdlsTJw4kWrVquHi4kLRokXp1asXJ0+eTDPu+vdreHg4zZo1w93dnQoVKvDhhx9is9nu+NozIiEhgREjRlC+fHmcnZ0pWbIkQ4YMSXfqwu+//87DDz9MoUKFcHNzo0yZMjz99NPEx8fbx0yZMgV/f388PT3x8vKiWrVqvPXWW1mSU0RE5H6zWq307t2brVu3pvm3/rqZM2fi5+dHu3btMjyvuplbnb6X0TnVuHHjCAgIoGDBgnh7e1O/fn2mT5+OYRj2MeXKlWPPnj388ccf9rnJ9fnQrU7f+/PPP3n00Ufx8vLC3d2dpk2b8tNPP6XLaLFYWL16Nc899xyFCxemUKFCdOrUidOnT9/xtWfU9UJKRO4/fdpEsllkZCQ9evSgW7duLF++3P6TsAMHDvDYY48xffp0VqxYwbBhw1i4cCEdOnTI0HZ37NjBK6+8wssvv8wPP/xAnTp1CA4OZu3atXdcNzk5mSeeeIJHH32UH374gX79+vHZZ58xYcIE+5i4uDhatGjB6tWrmTBhAgsXLqRYsWIEBQVlKN/FixcBGDNmDD/99BMzZ86kQoUKPPzwwze9psHXX3/NypUr+fzzz5k3bx5xcXE89thjREdH28eEhITQt29fqlevzvfff8/bb7/Nu+++m+6UyZtxcHCgT58+bNu2jR07dqR57npRdb0wPHToEIGBgUyZMoVff/2V0aNHs2nTJh588MFMH85tGAYdO3Zkzpw5vPLKKyxdupQmTZrQrl27dGNPnz5NoUKF+PDDD1mxYgVff/01jo6OBAQEsH//fuDaIfjX87799tts2LCBDRs20L9//1tmeO6553jjjTdo1aoVP/74I++++y4rVqygadOm6Yq2qKgounfvTo8ePfjxxx9p164dI0aMYO7cuZl63bd7Lz7++GN69uzJTz/9xPDhw5k1axaPPPKIvRQ9evQo7du3x9nZmRkzZrBixQo+/PBDPDw8SEpKAq6dbvn888/TvHlzli5dyrJly3j55ZfTlboiIiI5Wb9+/bBYLOl+sLh37142b95M7969sVqtmZ5X3Ulm5lRHjx5l0KBBLFy4kCVLltCpUydefPFF3n33XfuYpUuXUqFCBerVq2efmyxduvSW+//jjz945JFHiI6OZvr06YSGhuLl5UWHDh0ICwtLN75///44OTkxf/58Jk6cyJo1a+jRo0eGX29qaiopKSn2R2pqaobXFZEsZojIfdG7d2/Dw8MjzbLmzZsbgPHbb7/ddl2bzWYkJycbf/zxhwEYO3bssD83ZswY48aPbtmyZQ1XV1fj2LFj9mVXr141ChYsaAwaNMi+bPXq1QZgrF69Ok1OwFi4cGGabT722GNG1apV7V9//fXXBmD8/PPPacYNGjTIAIyZM2fe9jXdKCUlxUhOTjYeffRR46mnnrIvP3LkiAEYtWvXNlJSUuzLN2/ebABGaGioYRiGkZqaapQoUcKoX7++YbPZ7OOOHj1qODk5GWXLlr1jhsOHDxsWi8UYOnSofVlycrJRvHhx44EHHrjpOtf/bI4dO2YAxg8//GB/bubMmQZgHDlyxL6sd+/eabL8/PPPBmB88cUXabb7/vvvG4AxZsyYW+ZNSUkxkpKSjMqVKxsvv/yyfXl4ePgt/wxu/H7Zt2+fARjPP/98mnGbNm0yAOOtt96yL7v+/bpp06Y0Y2vUqGG0adPmljmvK1u2rNG+fftbPr9ixQoDMCZOnJhmeVhYmAEY3377rWEYhrF48WIDMCIiIm65rRdeeMEoUKDAHTOJiIjkdM2bNzcKFy5sJCUl2Ze98sorBmD8888/N13nVvMqwzDSzS9unA/ey5wqNTXVSE5ONt555x2jUKFCadavWbOm0bx583TrXJ/r/Xve0qRJE6No0aJGbGxsmtdUq1Yto1SpUvbtXp9r3TiPmThxogEYkZGRt8xqGP8/L7rxUbJkyVuu0759+wzNK0Xk7uhIKZFs5uvryyOPPJJu+eHDh+nWrRvFixfHarXi5ORE8+bNgWunk91J3bp1KVOmjP1rV1dXqlSpwrFjx+64rsViSXdEVp06ddKs+8cff+Dl5ZXuotldu3a94/avmzp1KvXr18fV1RVHR0ecnJz47bffbvr62rdvj9VqTZMHsGfav38/p0+fplu3bmlOTytbtixNmzbNUJ7y5cvTokUL5s2bZz/i5ueffyYqKsp+lBTA2bNnGTx4MKVLl7bnLlu2LJCxP5t/W716NXDt7jn/1q1bt3RjU1JS+OCDD6hRowbOzs44Ojri7OzMgQMHMr3fG/d/40VHGzduTPXq1fntt9/SLC9evDiNGzdOs+zG7427df2nrzdmeeaZZ/Dw8LBnqVu3Ls7OzgwcOJBZs2Zx+PDhdNtq3Lgxly9fpmvXrvzwww8ZOrVSREQkJwoODub8+fP8+OOPwLX5wNy5c2nWrBmVK1e2j8vMvOp2Mjun+v3332nZsiU+Pj72Oevo0aO5cOECZ8+ezfTrjYuLY9OmTXTu3BlPT0/7cqvVSs+ePTl58qT9CPHrbrw78o3zxDtZtWoV4eHh9sfy5csznVtEsoZKKZFs5ufnl27ZlStXaNasGZs2beK9995jzZo1hIeHs2TJEgCuXr16x+0WKlQo3TIXF5cMrevu7o6rq2u6dRMSEuxfX7hw4aZ3esno3V8+/fRTnnvuOQICAvj+++/ZuHEj4eHhtG3b9qYZb3w9Li4uwP+/FxcuXACulSY3utmyWwkODubChQv2id/MmTPx9PSkS5cuwLXrL7Vu3ZolS5bw+uuv89tvv7F582b79a0y8v7+24ULF3B0dEz3+m6Wefjw4YwaNYqOHTvyn//8h02bNhEeHo6/v3+m9/vv/cPNvw9LlChhf/66e/m+ykgWR0dHihQpkma5xWKhePHi9iwVK1Zk1apVFC1alCFDhlCxYkUqVqzIF198YV+nZ8+ezJgxg2PHjvH0009TtGhRAgICWLly5T3nFBERyU6dO3fGx8fHfnr+8uXLOXPmTJoLnGd2XnU7mZlTbd68mdatWwMwbdo0/vrrL8LDwxk5ciSQ+XkRwKVLlzAM45Zzk39nvO5O88Q78ff3p2HDhvbH9VJLRLKf7r4nks1uvOg0XPuJ0+nTp1mzZo396Cgg3cWezVSoUCE2b96cbnlUVFSG1p87dy4PP/wwU6ZMSbM8Njb2rvPcav8ZzQTQqVMnfH19mTFjBs2bN+e///0vvXr1sv+kbvfu3ezYsYOQkBB69+5tX+/gwYN3nTslJYULFy6kmVDdLPPcuXPp1asXH3zwQZrl58+fp0CBAne9f7h2bbMb78p3+vTp296JJqtdfy/OnTuXppgyDIOoqCj7BdwBmjVrRrNmzUhNTWXLli189dVXDBs2jGLFivHss88C1y703rdvX+Li4li7di1jxozh8ccf559//rEf2SYiIpLTubm50bVrV6ZNm0ZkZCQzZszAy8uLZ555xj4mK+dVmZlTLViwACcnJ/773/+m+YHmsmXLMr3f63x9fXFwcCAyMjLdc9cvXp6d8xMRyV46UkokB7heVF3/Kc9133zzjRlxbqp58+bExsby888/p1m+YMGCDK1vsVjSvb6dO3eyYcOGu8pTtWpV/Pz8CA0NTXO3l2PHjrF+/foMb8fV1ZVu3brx66+/MmHCBJKTk9OcupfVfzYtWrQAYN68eWmWz58/P93Ym71nP/30E6dOnUqzLDM/Hbx+6uiNFyoPDw9n3759PProo3fcRla5vq8bs3z//ffExcXdNIvVaiUgIICvv/4agG3btqUb4+HhQbt27Rg5ciRJSUns2bPnPqQXERG5f4KDg0lNTeWjjz5i+fLlPPvss7i7u9ufz8p5VWbmVBaLBUdHxzSXWLh69Spz5sxJt92MHlnt4eFBQEAAS5YsSTPeZrMxd+5cSpUqRZUqVTL9ukQkd9CRUiI5QNOmTfH19WXw4MGMGTMGJycn5s2bl+6ucGbq3bs3n332GT169OC9996jUqVK/Pzzz/zyyy/AnW+d+/jjj/Puu+8yZswYmjdvzv79+3nnnXcoX748KSkpmc7j4ODAu+++S//+/XnqqacYMGAAly9fZuzYsZk6fQ+uTfy+/vprPv30U6pVq5bm+gnVqlWjYsWKvPnmmxiGQcGCBfnPf/5z16eFtW7dmoceeojXX3+duLg4GjZsyF9//XXTydzjjz9OSEgI1apVo06dOmzdupWPPvoo3RFOFStWxM3NjXnz5lG9enU8PT0pUaKE/ZD3f6tatSoDBw7kq6++wsHBgXbt2nH06FFGjRpF6dKlefnll+/qdd1KVFQUixcvTre8XLlytGrVijZt2vDGG28QExPDAw88wM6dOxkzZgz16tWjZ8+ewLVrZvz++++0b9+eMmXKkJCQYL8rUcuWLQEYMGAAbm5uPPDAA/j5+REVFcX48ePx8fFJc8SViIhIbnD9lLLPP/8cwzDSnLoHWTuvysycqn379nz66ad069aNgQMHcuHCBT7++ON0BRlA7dq1WbBgAWFhYVSoUAFXV1dq16590wzjx4+nVatWtGjRgldffRVnZ2cmT57M7t27CQ0NvemZBvfT3r172bt3L3BtLhMfH2+fz9SoUYMaNWpkax6RvEyllEgOUKhQIX766SdeeeUVevTogYeHB08++SRhYWHUr1/f7HjAtZ9i/f777wwbNozXX38di8VC69atmTx5Mo899tgdTycbOXIk8fHxTJ8+nYkTJ1KjRg2mTp3K0qVL7+rWxYB9gjZhwgQ6depEuXLleOutt/jjjz8ytc169epRr149tm/fnuYoKQAnJyf+85//8NJLLzFo0CAcHR1p2bIlq1atSnNh+YxycHDgxx9/ZPjw4UycOJGkpCQeeOABli9fTrVq1dKM/eKLL3BycmL8+PFcuXKF+vXrs2TJEt5+++0049zd3ZkxYwbjxo2jdevWJCcnM2bMGMaOHXvTDFOmTKFixYpMnz6dr7/+Gh8fH9q2bcv48eNveg2pe7F169Y0pxtc17t3b0JCQli2bBljx45l5syZvP/++xQuXJiePXvywQcf2Ce4devW5ddff2XMmDFERUXh6elJrVq1+PHHH+3XtWjWrBkhISEsXLiQS5cuUbhwYR588EFmz56d7ppVIiIiuUFwcDAvvfQSNWrUICAgIM1zWT2vyuic6pFHHmHGjBlMmDCBDh06ULJkSQYMGEDRokXTFWfjxo0jMjKSAQMGEBsbS9myZTl69OhN99+8eXN+//13xowZQ58+fbDZbPj7+/Pjjz/y+OOPZ/r13KuFCxcybty4NMuuz2duN8cSkcyzGP8+RlNEJJM++OAD3n77bY4fP57uCB4RERERERGRW9GRUiKSYZMmTQKundKWnJzM77//zpdffkmPHj1USImIiIiIiEimqJQSkQxzd3fns88+4+jRoyQmJlKmTBneeOONdKeTiYiIiIiIiNyJTt8TEREREREREZFsd/vbZYmIiIiIiIiIiNwHKqVERERERERERCTbqZQSEREREREREZFspwud34TNZuP06dN4eXlhsVjMjiMiIiLZxDAMYmNjKVGiBA4O+tndvdKcSkREJH/K6JxKpdRNnD59mtKlS5sdQ0RERExy4sQJSpUqZXaMXE9zKhERkfztTnMqlVI34eXlBVx787y9vU1OIyIiItklJiaG0qVL2+cCcm80pxIREcmfMjqnUil1E9cPL/f29tYESkREJB/KaaeaTZ48mY8++ojIyEhq1qzJ559/TrNmzW46dsmSJUyZMoWIiAgSExOpWbMmY8eOpU2bNjcdv2DBArp27cqTTz7JsmXL7nq/N6M5lYiISP52pzmVLpYgIiIikoOFhYUxbNgwRo4cyfbt22nWrBnt2rXj+PHjNx2/du1aWrVqxfLly9m6dSstWrSgQ4cObN++Pd3YY8eO8eqrr960aMrsfkVEREQyy2IYhmF2iJwmJiYGHx8foqOj9VM9ERGRfCQnzgECAgKoX78+U6ZMsS+rXr06HTt2ZPz48RnaRs2aNQkKCmL06NH2ZampqTRv3py+ffuybt06Ll++nOZIqazYb058P0VEROT+y+gcQEdKiYiIiORQSUlJbN26ldatW6dZ3rp1a9avX5+hbdhsNmJjYylYsGCa5e+88w5FihQhODg4y/abmJhITExMmoeIiIjIreiaUiIikiPZbDaSkpLMjiF5jJOTE1ar1ewYGXb+/HlSU1MpVqxYmuXFihUjKioqQ9v45JNPiIuLo0uXLvZlf/31F9OnTyciIiJL9zt+/HjGjRuXoVz/lpqaSnJycqbXk/zD2dn5trcUFxGR3EmllIiI5DhJSUkcOXIEm81mdhTJgwoUKEDx4sVz3MXMb+fGrIZhZCh/aGgoY8eO5YcffqBo0aIAxMbG0qNHD6ZNm0bhwoWzdL8jRoxg+PDh9q+v33nnVgzDICoqisuXL9/xtUj+5uDgQPny5XF2djY7ioiIZCGVUiIikqMYhkFkZCRWq5XSpUvrJ+OSZQzDID4+nrNnzwLg5+dncqI7K1y4MFarNd3RSWfPnk13FNONwsLCCA4OZtGiRbRs2dK+/NChQxw9epQOHTrYl10vgB0dHdm/fz+lS5e+q/26uLjg4uKS4dd3vZAqWrQo7u7uuaoolOxjs9k4ffo0kZGRlClTRt8nIiJ5iEopERHJUVJSUoiPj6dEiRK4u7ubHUfyGDc3N+BauVK0aNEcfyqfs7MzDRo0YOXKlTz11FP25StXruTJJ5+85XqhoaH069eP0NBQ2rdvn+a5atWqsWvXrjTL3n77bWJjY/niiy8oXbr0Xe83M1JTU+2FVKFChbJkm5J3FSlShNOnT5OSkoKTk5PZcUREJIuolBIRkRwlNTUVQKdoyH1zvexMTk7O8aUUwPDhw+nZsycNGzYkMDCQb7/9luPHjzN48GDg2ilzp06dYvbs2cC1QqpXr1588cUXNGnSxH60k5ubGz4+Pri6ulKrVq00+yhQoABAmuV32u+9un4NKZXPkhHX/01ITU1VKSUikoeolBIRkRxJp2fI/ZLbvreCgoK4cOEC77zzDpGRkdSqVYvly5dTtmxZACIjIzl+/Lh9/DfffENKSgpDhgxhyJAh9uW9e/cmJCQky/abVXLbn4eYQ98nIiJ5k8UwDMPsEDlNTEwMPj4+REdH4+3tbXYcEZF8JSEhgSNHjlC+fHlcXV3NjiN50O2+xzQHyFq3ez/1WZfM0PeLiEjuktE5la4eKyIikkM9/PDDDBs2LMPjjx49isViISIi4r5lEpGscePnu1y5cnz++ee3XcdisbBs2bJ73ndWbUdEROReqZQSERG5RxaL5baPPn363NV2lyxZwrvvvpvh8aVLl7afZnU/qfyS/KxDhw5p7mb4bxs2bMBisbBt27ZMbzc8PJyBAwfea7w0xo4dS926ddMtj4yMpF27dlm6rxuFhITc9O/D7777zp6hW7duVK1aFQcHh0wV8CIiknfomlIiIiL3KDIy0v77sLAwRo8ezf79++3Lrt/x7brk5OQMXai3YMGCmcphtVopXrx4ptYRkcwJDg6mU6dOHDt2LN31tWbMmEHdunWpX79+prdbpEiRrIp4R9n194S3t3eavwsBfHx8AEhMTKRIkSKMHDmSzz77LFvyiIhIzmPqkVJr166lQ4cOlChRIsOHEc+bNw9/f3/c3d3x8/Ojb9++XLhw4aZjFyxYgMVioWPHjlkbXERE5F+KFy9uf/j4+GCxWOxfJyQkUKBAARYuXMjDDz+Mq6src+fO5cKFC3Tt2pVSpUrh7u5O7dq1CQ0NTbPdm53e88EHH9CvXz+8vLwoU6YM3377rf35G49gWrNmDRaLhd9++42GDRvi7u5O06ZN0/0n8b333qNo0aJ4eXnRv39/3nzzzZseXZFRiYmJDB06lKJFi+Lq6sqDDz5IeHi4/flLly7RvXt3ihQpgpubG5UrV2bmzJkAJCUl8cILL+Dn54erqyvlypVj/Pjxd51FJKs9/vjjFC1aNN1F4+Pj4wkLCyM4ODhDn+8b3Xj63oEDB3jooYdwdXWlRo0arFy5Mt06b7zxBlWqVMHd3Z0KFSowatQo+10NQ0JCGDduHDt27LAfpXQ9843z7l27dvHII4/g5uZGoUKFGDhwIFeuXLE/36dPHzp27MjHH3+Mn58fhQoVYsiQIfZ93cq//y68/rhe0pcrV44vvviCXr162YsqERHJf0wtpeLi4vD392fSpEkZGv/nn3/Sq1cvgoOD2bNnD4sWLSI8PJz+/funG3vs2DFeffVVmjVrltWxRUQkGxmGQXxSiimPrLwXyBtvvMHQoUPZt28fbdq0ISEhgQYNGvDf//6X3bt3M3DgQHr27MmmTZtuu51PPvmEhg0bsn37dp5//nmee+45/v7779uuM3LkSD755BO2bNmCo6Mj/fr1sz83b9483n//fSZMmMDWrVspU6YMU6ZMuafX+vrrr/P9998za9Ystm3bRqVKlWjTpg0XL14EYNSoUezdu5eff/6Zffv2MWXKFAoXLgzAl19+yY8//sjChQvZv38/c+fOpVy5cveUR3IPsz7vmfmsOzo60qtXL0JCQtKst2jRIpKSkujevftdf76vs9lsdOrUCavVysaNG5k6dSpvvPFGunFeXl6EhISwd+9evvjiC6ZNm2Y/6igoKIhXXnmFmjVrEhkZSWRkJEFBQem2ER8fT9u2bfH19SU8PJxFixaxatUqXnjhhTTjVq9ezaFDh1i9ejWzZs0iJCQkU3dzFBERuRlTT99r165dps5n37hxI+XKlWPo0KEAlC9fnkGDBjFx4sQ041JTU+nevTvjxo1j3bp1XL58OStji4hINrqanEqN0b+Ysu+977TB3Tlr/qkcNmwYnTp1SrPs1Vdftf/+xRdfZMWKFSxatIiAgIBbbuexxx7j+eefB64VXZ999hlr1qyhWrVqt1zn/fffp3nz5gC8+eabtG/fnoSEBFxdXfnqq68IDg6mb9++AIwePZpff/01zVESmREXF8eUKVMICQmx/xs/bdo0Vq5cyfTp03nttdc4fvw49erVo2HDhgBpSqfjx49TuXJlHnzwQSwWS7rToyRvM+vzntnPer9+/fjoo49Ys2YNLVq0AK6dutepUyd8fX3x9fW9q8/3datWrWLfvn0cPXqUUqVKAfDBBx+kmze//fbb9t+XK1eOV155hbCwMF5//XXc3Nzw9PTE0dHxtqfrzZs3j6tXrzJ79mw8PDwAmDRpEh06dGDChAkUK1YMAF9fXyZNmoTVaqVatWq0b9+e3377jQEDBtxy29HR0Xh6etq/9vT0JCoq6o6vX0RE8o9cdaHzpk2bcvLkSZYvX45hGJw5c4bFixfTvn37NOPeeecdihQpQnBwsElJRURE0rpewFyXmprK+++/T506dShUqBCenp78+uuvHD9+/LbbqVOnjv3310+NOXv2bIbX8fPzA7Cvs3//fho3bpxm/I1fZ8ahQ4dITk7mgQcesC9zcnKicePG7Nu3D4DnnnuOBQsWULduXV5//XXWr19vH9unTx8iIiKoWrUqQ4cO5ddff73rLCL3S7Vq1WjatCkzZswArn3fr1u3zn4U4t1+vq/bt28fZcqUsRdSAIGBgenGLV68mAcffJDixYvj6enJqFGjMryPf+/L39/fXkgBPPDAA9hstjSn+tasWROr1Wr/2s/P745/93h5eREREWF//PuzLiIiArnsQudNmzZl3rx5BAUFkZCQQEpKCk888QRfffWVfcxff/3F9OnTM3VHoMTERBITE+1fx8TEZGVsERG5B25OVva+08a0fWeVf/+HD66dhvfZZ5/x+eefU7t2bTw8PBg2bBhJSUm33c6NF0i3WCzYbLYMr2OxWADSrHN92XX3ctri9XVvts3ry9q1a8exY8f46aefWLVqFY8++ihDhgzh448/pn79+hw5coSff/6ZVatW0aVLF1q2bMnixYvvOpPkHmZ93u/msx4cHMwLL7zA119/zcyZMylbtiyPPvoocPef7+tu9hm88TO1ceNGnn32WcaNG0ebNm3w8fFhwYIFfPLJJ5l6Hf/+bN5un3fzd4+DgwOVKlXKVB4REclfctWRUnv37mXo0KGMHj2arVu3smLFCo4cOcLgwYMBiI2NpUePHkybNs1+bYqMGD9+PD4+PvZH6dKl79dLACAl9fb/gIuIyP+zWCy4Ozua8rjVf9Sywrp163jyySfp0aMH/v7+VKhQgQMHDty3/d1K1apV2bx5c5plW7ZsuevtVapUCWdnZ/7880/7suTkZLZs2UL16tXty4oUKUKfPn2YO3cun3/+eZoLtnt7exMUFMS0adMICwvj+++/t1+PSvI2sz7vd/NZ79KlC1arlfnz5zNr1iz69u1r3869fr5r1KjB8ePHOX36tH3Zhg0b0oz566+/KFu2LCNHjqRhw4ZUrlyZY8eOpRnj7OxMamrqHfcVERFBXFxcmm07ODhQpUqVDGcWEZHcJyd0E7nqSKnx48fzwAMP8NprrwHXTkfw8PCgWbNmvPfee5w5c4ajR4/SoUMH+zrXf4Lj6OjI/v37qVixYrrtjhgxguHDh9u/jomJuW/F1JHzcfSduZkPOtWmacWMF2ciIpK3VKpUie+//57169fj6+vLp59+SlRUVJriJju8+OKLDBgwgIYNG9K0aVPCwsLYuXMnFSpUuOO6N97FD679B/e5557jtddeo2DBgpQpU4aJEycSHx9vP61+9OjRNGjQgJo1a5KYmMh///tf++v+7LPP8PPzo27dujg4OLBo0SKKFy9OgQIFsvR1i9wrT09PgoKCeOutt4iOjqZPnz725+71892yZUuqVq1Kr169+OSTT4iJiWHkyJFpxlSqVInjx4+zYMECGjVqxE8//cTSpUvTjClXrhxHjhwhIiKCUqVK4eXlhYuLS5ox3bt3Z8yYMfTu3ZuxY8dy7tw5XnzxRXr27Gm/ntT9cv3MhitXrnDu3DkiIiJwdnamRo0a93W/IiICZ2MT6PndZoY+Wpn2dfxMy5GrSqn4+HgcHdNGvn5uu2EYVKtWjV27dqV5/u233yY2NpYvvvjilkWTi4tLun+g75evVx/k6IV4+swM5+tu9WlV4/7+Yy8iIjnTqFGjOHLkCG3atMHd3Z2BAwfSsWNHoqOjszVH9+7dOXz4MK+++ioJCQl06dKFPn36pDt66maeffbZdMuOHDnChx9+iM1mo2fPnsTGxtKwYUN++eUXfH19gWtHb4wYMYKjR4/i5uZGs2bNWLBgAXDtP/oTJkzgwIEDWK1WGjVqxPLly3FwyFUHd0s+ERwczPTp02ndujVlypSxL7/Xz7eDgwNLly4lODiYxo0bU65cOb788kvatm1rH/Pkk0/y8ssv88ILL5CYmEj79u0ZNWoUY8eOtY95+umnWbJkCS1atODy5cvMnDkzTXkG4O7uzi+//MJLL71Eo0aNcHd35+mnn+bTTz+9p/cmI+rVq2f//datW5k/fz5ly5bl6NGj933fIiL52fkriXSbtomDZ68wYcXftKxRFBfHrLtsRWZYjKy833UmXblyhYMHDwLX/lH69NNPadGihf0nqyNGjODUqVPMnj0bgJCQEAYMGMCXX35JmzZtiIyMZNiwYTg4ONzyFrt9+vTh8uXLLFu2LMO5YmJi8PHxITo6Gm9v73t+nf+WkJzK0NDt/Lr3DFYHCx8/U4en6pW684oiIvlEQkICR44coXz58ri6upodJ19q1aoVxYsXZ86cOWZHuS9u9z12P+cA+dHt3k991iUz9P0iIpI1LsYl0fXbjew/E4ufjysLBjahbCGPO6+YSRmdU5l6pNSWLVvst9EF7KfQ9e7dm5CQECIjI9PcQaRPnz7ExsYyadIkXnnlFQoUKMAjjzzChAkTsj373XJ1sjK5e31e/34nS7ad4uWwHcRcTaF303JmRxMRkXwoPj6eqVOn0qZNG6xWK6GhoaxatYqVK1eaHU1EREREstCluCS6f7eJ/WdiKerlwvwB96eQygxTS6mHH374tnf4CQkJSbfsxRdf5MUXX8zwPm62DbM5Wh34uLM/3q5OhKw/ypgf9xBzNZkXHql0Xy+qKyIiciOLxcLy5ct57733SExMpGrVqnz//fe0bNnS7GgiIiIikkWi45PpMX0T+yJjKOzpQujAJpQvbG4hBbnsmlJ5iYODhTEdauDj5sQXvx3gk5X/cPlqMm+3r65iSkREso2bmxurVq0yO4aIiIiI3CfRV5PpOWMTe07HUNjTmdABAVQs4ml2LAB01VATWSwWXm5VhdGPX7vDyPQ/j/D64p054raMIiIiIiIiIpK7xSQk02vGZnaejKaghzPz+jehcjEvs2PZqZTKAfo9WJ6POtfBwQKLtp7khfnbSUxJNTuWiIiIiIiIiORSVxJT6DNjMztOXKaAuxPz+gdQtXjOKaRApVSO8UzD0kzu3gBnqwMr9kTRf9YW4pNSzI4lIiIicl/ZbDpCXO7MxBuGi4jkSnGJKfSduZltxy/j7erI3OAAqvvlvDsL65pSOUjbWsWZ0acRA+dsYd2B8/T4bhMz+zTGx93J7GgiIiIiWcrZ2RkHBwdOnz5NkSJFcHZ21nU15aYMw+DcuXNYLBacnDQvFhG5k/ikFPqFhBN+9BJero7M7R9ArZI+Zse6KZVSOcyDlQszt38AfWeGs+34ZYK+3cDs4MYU9XI1O5qIiIhIlnFwcKB8+fJERkZy+vRps+NIDmexWChVqhRWq9XsKCIiOdrVpFT6z9rCpiMX8XJxZE5wAHVKFTA71i2plMqB6pfxJWxQE3pO38zfUbE8M3UDc4MDKF3Q3exoIiIiIlnG2dmZMmXKkJKSQmqqrqcpt+bk5KRCSkTkDhKSUxk4ZwvrD13Aw9lKSL/G1C1dwOxYt6VSKoeqVtybxYMD6TF9E8cuxNN56nrmBgfkqKvki4hI1nr44YepW7cun3/+OQDlypVj2LBhDBs27JbrWCwWli5dSseOHe9p31m1HZHMun5Klk7LEhERuXuJKakMmrOVdQfO4/6/QqpBWV+zY92RLnSeg5Ut5MGiQU2pXNSTMzGJdPlmAztPXjY7loiI3KBDhw60bNnyps9t2LABi8XCtm3bMr3d8PBwBg4ceK/x0hg7dix169ZNtzwyMpJ27dpl6b5uFBISQoECBe7rPkRERETym8SUVJ6bu40//jmHm5OVmX0a0ahcQbNjZYhKqRyuuI8rCwcF4l/Kh0vxyXSbtokNhy6YHUtERP4lODiY33//nWPHjqV7bsaMGdStW5f69etnertFihTB3T17Tt0uXrw4Li4u2bIvEREREckayak2Xpi/nd//PouLowPTezckoEIhs2NlmEqpXMDXw5l5A5oQWKEQVxJT6D1zM6v2njE7loiI/M/jjz9O0aJFCQkJSbM8Pj6esLAwgoODuXDhAl27dqVUqVK4u7tTu3ZtQkNDb7vdcuXK2U/lAzhw4AAPPfQQrq6u1KhRg5UrV6Zb54033qBKlSq4u7tToUIFRo0aRXJyMnDtSKVx48axY8cOLBYLFovFntlisbBs2TL7dnbt2sUjjzyCm5sbhQoVYuDAgVy5csX+fJ8+fejYsSMff/wxfn5+FCpUiCFDhtj3dTeOHz/Ok08+iaenJ97e3nTp0oUzZ/7/37sdO3bQokULvLy88Pb2pkGDBmzZsgWAY8eO0aFDB3x9ffHw8KBmzZosX778rrOIiIiI5HTJqTaGhm5n5d4zODs68F3vhjStVNjsWJmia0rlEp4ujszs24gX//cNN2juVj55xp+O9UqaHU1E5P4yDEiON2ffTu6QgVvUOzo60qtXL0JCQhg9erT9tvaLFi0iKSmJ7t27Ex8fT4MGDXjjjTfw9vbmp59+omfPnlSoUIGAgIA77sNms9GpUycKFy7Mxo0biYmJuem1pry8vAgJCaFEiRLs2rWLAQMG4OXlxeuvv05QUBC7d+9mxYoVrFq1CgAfn/S3B46Pj6dt27Y0adKE8PBwzp49S//+/XnhhRfSFG+rV6/Gz8+P1atXc/DgQYKCgqhbty4DBgy44+u5kWEYdOzYEQ8PD/744w9SUlJ4/vnnCQoKYs2aNQB0796devXqMWXKFKxWKxEREfbrEA0ZMoSkpCTWrl2Lh4cHe/fuxdPTM9M5RERERHKDlFQbw8Ii+Hl3FM5WB77t2YBmlYuYHSvTVErlIq5OVqZ0r8/ri3eyZPsphoVFEJOQTK/AcmZHExG5f5Lj4YMS5uz7rdPg7JGhof369eOjjz5izZo1tGjRArh26l6nTp3w9fXF19eXV1991T7+xRdfZMWKFSxatChDpdSqVavYt28fR48epVSpUgB88MEH6a4D9fbbb9t/X65cOV555RXCwsJ4/fXXcXNzw9PTE0dHR4oXL37Lfc2bN4+rV68ye/ZsPDyuvf5JkybRoUMHJkyYQLFixQDw9fVl0qRJWK1WqlWrRvv27fntt9/uqpRatWoVO3fu5MiRI5QuXRqAOXPmULNmTcLDw2nUqBHHjx/ntddeo1q1agBUrlzZvv7x48d5+umnqV27NgAVKlTIdAYRERGR3CDVZjB84Q5+2hmJk9XC1J71ebhqUbNj3RWdvpfLOFod+PgZf3oHlgVg9A97mPT7AQzDMDmZiEj+Vq1aNZo2bcqMGTMAOHToEOvWraNfv34ApKam8v7771OnTh0KFSqEp6cnv/76K8ePH8/Q9vft20eZMmXshRRAYGBgunGLFy/mwQcfpHjx4nh6ejJq1KgM7+Pf+/L397cXUgAPPPAANpuN/fv325fVrFkzzS3a/fz8OHv2bKb29e99li5d2l5IAdSoUYMCBQqwb98+AIYPH07//v1p2bIlH374IYcOHbKPHTp0KO+99x4PPPAAY8aMYefOnXeVQ0RERCQnS7UZvLZoBz/uOI2jg4XJ3RvwSLViZse6azpSKhdycLAw9oma+Lg78+VvB/j413+IvprMW49Vt58yIiKSZzi5Xztiyax9Z0JwcDAvvPACX3/9NTNnzqRs2bI8+uijAHzyySd89tlnfP7559SuXRsPDw+GDRtGUlJShrZ9sx8+3Ph3/saNG3n22WcZN24cbdq0wcfHhwULFvDJJ59k6nUYhnHLf0/+vfz6qXP/fs5ms2VqX3fa57+Xjx07lm7duvHTTz/x888/M2bMGBYsWMBTTz1F//79adOmDT/99BO//vor48eP55NPPuHFF1+8qzwiIiIiOY3NZvDG99fOnLI6WJjUrR6tauTeQgp0pFSuZbFYGN6qCqMerwHAtHVHePP7XaTadMSUiOQxFsu1U+jMeGSy6O/SpQtWq5X58+cza9Ys+vbtay9U1q1bx5NPPkmPHj3w9/enQoUKHDhwIMPbrlGjBsePH+f06f8v6DZs2JBmzF9//UXZsmUZOXIkDRs2pHLlyunuCOjs7Exqauod9xUREUFcXFyabTs4OFClSpUMZ86M66/vxIkT9mV79+4lOjqa6tWr25dVqVKFl19+mV9//ZVOnToxc+ZM+3OlS5dm8ODBLFmyhFdeeYVp06bdl6wiIiIi2c1mM3hr6S4Wbz2J1cHCl8/Wo20tP7Nj3TOVUrlc8IPlmdi5Dg4WCNtyghdDt5GYcvv/bIiIyP3h6elJUFAQb731FqdPn6ZPnz725ypVqsTKlStZv349+/btY9CgQURFRWV42y1btqRq1ar06tWLHTt2sG7dOkaOHJlmTKVKlTh+/DgLFizg0KFDfPnllyxdujTNmHLlynHkyBEiIiI4f/48iYmJ6fbVvXt3XF1d6d27N7t372b16tW8+OKL9OzZ0349qbuVmppKREREmsfevXtp2bIlderUoXv37mzbto3NmzfTq1cvmjdvTsOGDbl69SovvPACa9as4dixY/z111+Eh4fbC6thw4bxyy+/cOTIEbZt28bvv/+epswSERERya0Mw2DUD7tZEH4CBwt82sWf9nVyfyEFKqXyhC4NSzO5e32crQ4s3xVF/1lbiE9KMTuWiEi+FBwczKVLl2jZsiVlypSxLx81ahT169enTZs2PPzwwxQvXpyOHTtmeLsODg4sXbqUxMREGjduTP/+/Xn//ffTjHnyySd5+eWXeeGFF6hbty7r169n1KhRacY8/fTTtG3blhYtWlCkSBFCQ0PT7cvd3Z1ffvmFixcv0qhRIzp37syjjz7KpEmTMvdm3MSVK1eoV69emsdjjz2GxWJh2bJl+Pr68tBDD9GyZUsqVKhAWFgYAFarlQsXLtCrVy+qVKlCly5daNeuHePGjQOulV1DhgyhevXqtG3blqpVqzJ58uR7zisiIiJiJsMwGPvjHuZtOo7FAp908efJuiXNjpVlLIaukJ1OTEwMPj4+REdH4+3tbXacDFt34BwDZ2/lanIqDcr6MqN3I3zcne68oohIDpKQkMCRI0coX748rq6uZseRPOh232O5dQ6QU+n9FBERuXuGYfDOf/cy86+jWCzwUWd/OjcodecVc4CMzgF0pFQe0qxyEeb2D8Db1ZGtxy4R9O0GzsWmPy1DRERERERERHIuwzD4YPk+Zv51FIAPO9XONYVUZqiUymMalPUlbFAghT1d+DsqlmemrufkpXizY4mIiIiIiIhIBhiGwcRf9jNt3REA3n+qFkGNytxhrdxJpVQeVN3Pm8WDAynl68bRC/F0nrKBg2djzY4lIiIiIiIiInfw2cp/mLLmEADvPFmT7gFlTU50/6iUyqPKFfZg8eCmVCrqSVRMAl2+2ciuk9FmxxIRERERERGRW/hi1QG+/P0gAKMfr0GvwHLmBrrPVErlYcV9XFk4KJA6pXy4GJdE12kb2Xj4gtmxREREREREROQGk34/wGer/gHg7fbV6fdgeZMT3X8qpfK4gh7OzOsfQJMKBbmSmELvGZv5bd8Zs2OJiNyRbg4r94vNZjM7goiIiEgaU9Yc4uNfrxVSb7arRv9mFUxOlD0czQ4g95+XqxMhfRvzwvxtrNp3lkFztvJJF3+erFvS7GgiIuk4OTlhsVg4d+4cRYoUwWKxmB1J8gjDMEhKSuLcuXM4ODjg7OxsdiQRERERvlt3mAkr/gbg1dZVGNy8osmJso9KqXzC1cnKlB4NeH3xTpZuP8WwsAhiElLo2STvXjBNRHInq9VKqVKlOHnyJEePHjU7juRB7u7ulClTBgcHHTAuIiIi5pr51xHe+2kfAMNaVuaFRyqbnCh7qZTKR5ysDnzyjD9ero7M3nCMUct2E3M1mecfrqgjEUQkR/H09KRy5cokJyebHUXyGKvViqOjo/7dExEREdPN3nCUcf/ZC8CLj1TipUfzVyEFKqXyHQcHC+OeqImPmxNf/X6Qj37ZT8zVZN5sV00TdBHJUaxWK1ar1ewYIiIiIiJZbt6mY4z+YQ8Azz1ckeGtquTL/5PruPV8yGKx8ErrqrzdvjoA36w9zIglu0i16aLCIiIiIiIiIvdTWPhxRi7dDcDAhyrwepuq+bKQApVS+Vr/ZhWY+HQdHCywIPwEQ0O3k5SiOxKJiIiIiIiI3A+LtpzgzSW7AOj3QHlG5POzllRK5XNdGpVmUrf6OFkt/LQrkv6ztxCflGJ2LBEREREREZE8Zen2k7z+/U4MA3oHlmXU49XzdSEFKqUEeKy2H9N7N8LNycraf87Ra/pmoq/q4sIiIiIiIiIiWeHHHad5ZeEODAO6B5Rh7BM1830hBSql5H8eqlKEuf0b4+3qyJZjl3j2242ci000O5aIiIiIiIhIrvbTzkheDovAZsCzjUrz7pO1VEj9j0opsWtQtiBhgwIp7OnCvsgYunyzgZOX4s2OJSIiIiIiIpIrrdgdydAF20m1GXRuUIoPnqqNg4MKqetUSkka1f28WTQ4kJIF3DhyPo5npm7g4NkrZscSERERERERyVV+3RPFC/OvFVKd6pVkwtN1VEjdQKWUpFO+sAeLnwukYhEPIqMT6PLNBnafijY7loiIiIiIiEiu8Nu+MwyZv40Um8ET/iX46Bl/rCqk0lEpJTfl5+PGosFNqV3Sh4txSXT9diObDl8wO5aIiIiIiIhIjrZm/1mem7uN5FSD9rX9+LSLCqlbUSklt1TQw5n5AwIIKF+Q2MQUes3YzOq/z5odS0RERERERCRH+vPAeQbO2UpSqo22NYvz+bN1cbSqerkVvTNyW16uTszq15hHqxUlMcXGgNlb+CHilNmxRERERERERHKU9QfPEzwrnKQUG61qFOPLrvVwUiF1W3p35I5cnaxM7dmAJ+uWIMVmMCwsgrkbj5kdS0RERERERCRH2Hj4AsGztpCYYuPRakX5ult9nB1VudyJ3iHJECerA591qUvPJmUxDHh72W4mrzlodiwRERERERERU4UfvUi/kHCuJqfycNUiTO6hQiqj9C5Jhjk4WHjnyZq80KISABNX7Gf8z/swDMPkZCIiIiIiIiLZb+uxS/SZsZn4pFSaVS7M1B4NcHG0mh0r11ApJZlisVh4tU1VRj5WHYBv/jjMW0t3k2pTMSUiIiIiIiL5R8SJy/SZsZm4pFSaVizEtz0b4uqkQiozVErJXRnwUAUmPF0bBwuEbj7OSwu2k5RiMzuWiIiIiIiIyH2362Q0PadvIjYxhYDyBfmud0PcnFVIZZZKKblrQY3KMKlbfZysFv67M5KBc7ZwNSnV7FgiIiIiIiIi983uU9H0mL6J2IQUGpXzZUafRrg7O5odK1dSKSX35LHafnzXuxGuTg6s2X+OntM3EX012exYIiIiIiIiIllu7+kYevzv/731yxRgZt/GeLiokLpbKqXknjWvUoS5wQF4uTqy5dglun67kfNXEs2OJSIiIiIiIpJl9kfF0mP6Ji7HJ+NfugCz+jXGU4XUPVEpJVmiYbmChA0MpLCnM3sjY+gydQOnLl81O5aIiIiIiIjIPTt4Npbu323kYlwStUv6MLtfY7xcncyOleuplJIsU6OEN4sGN6VkATcOn4/jmSnrOXTuitmxRERERERERO7aoXNX6DptE+evJFGzhDdzghvj46ZCKiuolJIsVb6wB4ufC6RiEQ9ORyfQZeoGdp+KNjuWiIiIiIiISKYdOR9H1283ci42kWrFvZgbHEABd2ezY+UZKqUky/n5uLFwUCC1SnpzIS6Jrt9uZPORi2bHEhERybUmT55M+fLlcXV1pUGDBqxbt+6WY5csWUKrVq0oUqQI3t7eBAYG8ssvv6Qb07BhQwoUKICHhwd169Zlzpw5acaMHTsWi8WS5lG8ePH78vpERERyomMXrhVSZ2MTqVrMi3n9A/D1UCGVlUwtpdauXUuHDh0oUaIEFouFZcuW3XGdefPm4e/vj7u7O35+fvTt25cLFy7Yn8/IJEvuv0KeLswf0ITG5QsSm5hCz+mbWP33WbNjiYiI5DphYWEMGzaMkSNHsn37dpo1a0a7du04fvz4TcevXbuWVq1asXz5crZu3UqLFi3o0KED27dvt48pWLAgI0eOZMOGDezcuZO+ffvSt2/fdOVVzZo1iYyMtD927dp1X1+riIhITnHiYjxdv91IVEwClYt6Mm9AAIU8XcyOledYDMMwzNr5zz//zF9//UX9+vV5+umnWbp0KR07drzl+D///JPmzZvz2Wef0aFDB06dOsXgwYOpXLkyS5cuBWDNmjVcunSJatWq4ezszH//+19eeeUVfvrpJ9q0aZOhXDExMfj4+BAdHY23t3dWvNR8KyE5lefnbeP3v8/i6GDhs6C6dPAvYXYsERGRm8qJc4CAgADq16/PlClT7MuqV69Ox44dGT9+fIa2UbNmTYKCghg9evQtx9SvX5/27dvz7rvvAteOlFq2bBkRERF3nT0nvp8iIiJ3cvJSPM9+u5GTl65SoYgHCwY2oaiXq9mxcpWMzgFMPVKqXbt2vPfee3Tq1ClD4zdu3Ei5cuUYOnQo5cuX58EHH2TQoEFs2bLFPubhhx/mqaeeonr16lSsWJGXXnqJOnXq8Oeff96vlyG34epk5ZueDXjCvwQpNoOhC7Yzf9PNf7IrIiIiaSUlJbF161Zat26dZnnr1q1Zv359hrZhs9mIjY2lYMGCN33eMAx+++039u/fz0MPPZTmuQMHDlCiRAnKly/Ps88+y+HDh2+7r8TERGJiYtI8REREcpPI6Kt0m7aJk5euUr6wB6EDVEjdT7nqmlJNmzbl5MmTLF++HMMwOHPmDIsXL6Z9+/Y3HX+7SZZkHyerA58H1aVHkzIYBry1dBdT1hwyO5aIiEiOd/78eVJTUylWrFia5cWKFSMqKipD2/jkk0+Ii4ujS5cuaZZHR0fj6emJs7Mz7du356uvvqJVq1b25wMCApg9eza//PIL06ZNIyoqiqZNm6a5bMKNxo8fj4+Pj/1RunTpTLxaERERc52JSaDrtxs5fjGeMgXdmT8ggGLeKqTuJ0ezA2RG06ZNmTdvHkFBQSQkJJCSksITTzzBV199lWZcdHQ0JUuWJDExEavVyuTJk9NMsm6UmJhIYmKi/Wv9VC/rOThYePfJWni7OjF5zSEmrPib6KvJvNG2KhaLxex4IiIiOdqN/1YahpGhfz9DQ0MZO3YsP/zwA0WLFk3znJeXFxEREVy5coXffvuN4cOHU6FCBR5++GHg2hHt19WuXZvAwEAqVqzIrFmzGD58+E33N2LEiDTPxcTEqJgSEZFc4ez/CqmjF+Ip5etG6MAm+Pm4mR0rz8tVR0rt3buXoUOHMnr0aLZu3cqKFSs4cuQIgwcPTjPu+iQrPDyc999/n+HDh7NmzZpbblc/1cseFouF19tWY0S7agBM/eMQI5ftJtVm2mXNREREcrTChQtjtVrTHRV19uzZdEdP3SgsLIzg4GAWLlxIy5Yt0z3v4OBApUqVqFu3Lq+88gqdO3e+7TWqPDw8qF27NgcOHLjlGBcXF7y9vdM8REREcrpzsYl0+24Th8/HUbKAG6EDmlCygAqp7JCrSqnx48fzwAMP8Nprr1GnTh3atGnD5MmTmTFjBpGRkfZxmZ1kjRgxgujoaPvjxIkT2fFy8q1BzSsyvlNtLBaYv+k4Ly3YTlKKzexYIiIiOY6zszMNGjRg5cqVaZavXLmSpk2b3nK90NBQ+vTpw/z58295mYMbGYaR5sjxGyUmJrJv3z78/PwyFl5ERCQXuHAlke7fbeTg2Sv4+bgSOqAJpQu6mx0r38hVp+/Fx8fj6Jg2stVqBa5NpG7lTpMsFxcXXFx0a8fs1LVxGbxcHXk5LIL/7ozkSmIKU7o3wM3ZanY0ERGRHGX48OH07NmThg0bEhgYyLfffsvx48ftR4qPGDGCU6dOMXv2bOBaIdWrVy+++OILmjRpYj/Kys3NDR8fH+DaD/oaNmxIxYoVSUpKYvny5cyePTvNHf5effVVOnToQJkyZTh79izvvfceMTEx9O7dO5vfARERkfvjUlwS3b/bxD9nrlDM24X5A5pQppAKqexkail15coVDh48aP/6yJEjREREULBgQcqUKZNuktWhQwcGDBjAlClTaNOmDZGRkQwbNozGjRtTokQJIGOTLMkZHq9TAk8XRwbP3cqa/efoPWMz3/VpiLerk9nRREREcoygoCAuXLjAO++8Q2RkJLVq1WL58uWULVsWgMjISI4f//87237zzTekpKQwZMgQhgwZYl/eu3dvQkJCAIiLi+P555/n5MmTuLm5Ua1aNebOnUtQUJB9/MmTJ+natSvnz5+nSJEiNGnShI0bN9r3KyIikptdjr9WSP0dFUsRr2uFVPnCHmbHyncsxu0OMbrP1qxZQ4sWLdItvz5p6tOnD0ePHk1zPaivvvqKqVOncuTIEQoUKMAjjzzChAkTKFmyJABvv/02YWFhaSZZL730UppJ1p3ExMTg4+NDdHS0roWQDcKPXqRfSDixCSnULOHN7H6NKeSpI9dERCT7aQ6QtfR+iohIThR9NZke321i16loCns6s2BgEyoV9TI7Vp6S0TmAqaVUTqUJVPbbczqaXtM3cyEuiQpFPJgTHKALy4mISLbTHCBr6f0UEZGcJiYhmZ7TN7PjxGUKelwrpKoUUyGV1TI6B8hVFzqXvKtmCR8WDQ6khI8rh8/F8cyU9Rw+d8XsWCIiIiIiIpJHxCYk03vGtULK192Jef0DVEiZTKWU5BgViniy+LmmVCjiwenoBJ6ZuoHdp6LNjiUiIiIiIiK5XFxiCn1nhrP9+GV83JyY2z+A6n46itdsKqUkRylRwI2FgwKpWcKbC3FJdP12I+FHL5odS0RERERERHKp+KQU+oaEs+XYJbxcHZkbHEDNEj5mxxJUSkkOVNjThdCBTWhcriCxiSn0nL6JNfvPmh1LREREREREcpmrSakEh2xh85GLeLk4Mic4gNqlVEjlFCqlJEfydnViVr/GtKhahIRkGwNmb+G/O0+bHUtERERERERyiYTkVAbM3sKGwxfwdHFkVnBj6pYuYHYs+ReVUpJjuTlb+aZnQzr4lyA51eDF0O2Ebj5udiwRERERERHJ4RKSUxk0Zyt/HjyPu7OVkL6NqF/G1+xYcgOVUpKjOTs68HlQXboFlMEwYMSSXUz945DZsURERERERCSHSkxJ5fl52/jjn3O4OVmZ2acRDcsVNDuW3IRKKcnxrA4W3u9Yi+cergjAhz//zYQVf2MYhsnJREREREREJCdJSrExZN52fv/7LK5ODkzv05CACoXMjiW3oFJKcgWLxcIbbavxZrtqAExZc4i3l+3GZlMxJSIiIiIiIpCcamNo6HZW7TuDi6MD3/VqRNOKhc2OJbehUkpylcHNK/LBU7WxWGDepuMMC4sgOdVmdiwRERERERExUUqqjWELIlixJwpnqwPf9mrIg5VVSOV0KqUk1+kWUIYvn62Ho4OFH3ecZtCcrSQkp5odS0REREREREyQkmrj5YU7+GlXJE5WC9/0bEDzKkXMjiUZoFJKcqUO/iWY1rshrk4O/P73WXrN2ExMQrLZsURERERERCQbpdoMXlu8k//sOI2T1cKU7g1oUa2o2bEkg1RKSa7VompRZvcLwMvFkc1HLtJt2kYuXEk0O5aIiIiIiIhkA5vN4PXFO1m6/RRWBwtfda1PyxrFzI4lmaBSSnK1xuULEjqwCYU8nNl9KoYu32zg9OWrZscSERERERGR+8hmMxixZBffbzuJ1cHCl8/Wo22t4mbHkkxSKSW5Xq2SPiwcHEgJH1cOnYvjmakbOHI+zuxYIiIiIiIich8YhsHbP+wmbMsJHCzwWVBd2tfxMzuW3AWVUpInVCziyaLnmlKhsAenLl/lmanr2Xs6xuxYIiIiIiIikoUMw2DMj3uYv+k4Fgt82qUuT/iXMDuW3CWVUpJnlCzgxsLBgdTw8+b8lSSCvt3AlqMXzY4lIiIiIiIiWcAwDN75715mbziGxQIfdfanY72SZseSe6BSSvKUwp4uhA5sQqNyvsQmpNBj+ibW7D9rdiwRERERERG5B4Zh8P5P+5j511EAJnSqQ+cGpcwNJfdMpZTkOT5uTszuF0DzKkVISLYxYPYWftoZaXYsERERERERuQuGYfDhir/57s8jAHzwVG26NCptcirJCiqlJE9yc7YyrVdDHq/jR3KqwYuh21iw+bjZsURERERERCQTDMPgk1//4Zs/DgPw7pM16RZQxuRUklVUSkme5ezowBfP1qNr4zLYDHhzyS6+XXvI7FgiIiIiIiKSQV/8doBJqw8CMKZDDXoGljM3kGQplVKSp1kdLHzwVC0GN68IwAfL/+ajX/7GMAyTk4mIiIiIiMjtfPXbAT5fdQCAt9tXp+8D5U1OJFlNpZTkeRaLhTfbVeP1tlUB+Hr1IUb/sAebTcWUiIiIiIhITjR5zUE+WfkPACPaVaN/swomJ5L7QaWU5BvPP1yJ9zrWwmKBORuP8fLCCJJTbWbHEhERERERkX/5du0hJq7YD8Brbaoy6H9nvkjeo1JK8pUeTcryxbP1cHSw8EPEaQbP2UpCcqrZsURERERERASY/ucRPlj+NwAvt6zCkBaVTE4k95NKKcl3nvAvwbReDXFxdOC3v8/Se8ZmYhOSzY4lIiIiIiKSr83ecJR3/7sXgKGPVOKllpVNTiT3m0opyZdaVCvKnOAAvFwc2XTkIt2mbeJiXJLZsURERERERPKluRuPMfqHPQA8/3BFXm5VxeREkh1USkm+1bh8QUIHNqGghzO7TkXT5ZsNREZfNTuWiIiIiIhIvrJg83HeXrYbgEEPVeC1NlWxWCwmp5LsoFJK8rVaJX1YOCgQPx9XDp69QucpGzhyPs7sWCIiIiIiIvnCwi0nGLF0FwD9HijPm+2qqZDKR1RKSb5XqagniwYHUr6wB6cuX+WZqRvYezrG7FgiIiIiIiJ52pJtJ3nj+50YBvQOLMuox6urkMpnVEqJAKV83Vk4KJAaft6cv5LIs99uYOuxi2bHEhERERERyZN+iDjFq4t2YBjQo0kZxj5RU4VUPqRSSuR/ini5EDqwCQ3L+hKTkEKP7zaz9p9zZscSERERERHJU/678zQvh0VgM6Br49K880QtFVL5lEopkX/xcXNiTnAAzasU4WpyKsGzwlm+K9LsWCIiIiIiInnCz7sieWnBtULqmQaleL9jbRwcVEjlVyqlRG7g5mxlWq+GtK/tR3KqwQvzt7Ew/ITZsURERERERHK1X/dE8WLodlJtBp3ql+TDp+uokMrnVEqJ3ISzowNfdq3Hs41KYzPg9e93Mm3tYbNjiYiIiIiI5Eq/7TvDkPnbSLEZPFm3BB919seqQirfUyklcgtWBwvjO9Vm0EMVAHh/+T4+/mU/hmGYnExERERERCT3WL3/LM/N3UZyqkH7On588owKKblGpZTIbVgsFt5sV43X2lQFYNLqg4z5cQ82m4opERERERGRO1n7zzkGzdlKUqqNdrWK83lQXRytqiLkGn0niNyBxWJhSItKvNuxFhYLzN5wjFcW7SA51WZ2NBERERERkRxr/cHzDJi9haQUG61rFOPLrvVwUiEl/6LvBpEM6tmk7LVW38HC0u2neG7uVhKSU82OJSIiIiIikuNsPHyBfrPCSUyx0bJ6USZ1q69CStLRd4RIJjxZtyTf9mqAi6MDq/adpc/MzcQmJJsdS0REREREJMfYfOQi/ULCSUi28XDVInzdvT7OjqofJD19V4hk0iPVijGrX2M8XRzZePgi3b/bxMW4JLNjiYiIiIiImG7rsYv0nbmZ+KRUmlUuzNQeDXBxtJodS3IolVIid6FJhUKEDmhCQQ9ndp6Mpss3G4iKTjA7loiIiIiIiGm2H79E7xnhxCWl0rRiIab1aoirkwopuTWVUiJ3qXYpHxYOCsTPx5WDZ6/Qeep6jp6PMzuWiIiIiIhIttt58jK9ZmzmSmIKTSoUZHrvRiqk5I5USoncg0pFPVk0OJByhdw5eekqnaduYF9kjNmxREREREREss3uU9H0+G4TsQkpNC53rZByc1YhJXemUkrkHpXydWfR4KZU9/Pm/JVEgr7ZwNZjl8yOJSIiIiIict/tPR1Dj+mbiElIoUFZX2b0bYSHi6PZsSSXUCklkgWKeLmwYGATGpT1JSYhhR7fbWLdgXNmxxIREREREblv/o6Koft3G7kcn0zd0gUI6dsITxVSkgkqpUSyiI+bE3OCG9OscmGuJqfSLyScn3dFmh1LREREREQkyx04E0v3aZu4FJ9MnVI+zOrXGC9XJ7NjSS6jUkokC7k7O/Jd74a0r+1HcqrBkPnbWLjlhNmxREREREREsszBs1foOm0TF+KSqFnCmzn9AvBxUyElmadSSiSLuTha+bJrPYIalsZmwOuLd/LdusNmxxIREREREblnR87H0W3aRs5fSaS6nzdzgwPwcVchJXdHpZTIfWB1sPDh07UZ+FAFAN77aR+f/rofwzBMTiYiIiIiInJ3jl2Io+u3Gzkbm0i14l7M6x+Ar4ez2bEkF1MpJXKfWCwWRrSrxmttqgLw5e8HGfefvdhsKqZERERERCR3OXExnq7fbiQqJoHKRT2Z2z+Agiqk5B6plBK5jywWC0NaVOLdJ2sCELL+KK8u2kFyqs3kZCIiIiIiIhlz8lI8z367kdPRCVQo4sG8AQEU9nQxO5bkAaaWUmvXrqVDhw6UKFECi8XCsmXL7rjOvHnz8Pf3x93dHT8/P/r27cuFCxfsz0+bNo1mzZrh6+uLr68vLVu2ZPPmzffxVYjcWc/AcnweVBerg4Ul20/x3NxtJCSnmh1LRERERETktk5fvkrXaRs5dfkq5Qt7EDqgCUW9XM2OJXmEqaVUXFwc/v7+TJo0KUPj//zzT3r16kVwcDB79uxh0aJFhIeH079/f/uYNWvW0LVrV1avXs2GDRsoU6YMrVu35tSpU/frZYhkSMd6Jfm2ZwNcHB1Yte8MfWeGcyUxxexYIiIiIiIiNxUVnUC3aRs5cfEqZQu5EzqgCcW8VUhJ1rEYOeTKyxaLhaVLl9KxY8dbjvn444+ZMmUKhw4dsi/76quvmDhxIidOnLjpOqmpqfj6+jJp0iR69eqVoSwxMTH4+PgQHR2Nt7d3pl6HyJ1sPHyB/rO2cCUxBf9SPoT0bayLA4qI5BCaA2QtvZ8iIrnX2ZgEnv12I4fPx1G6oBthAwMpUcDN7FiSS2R0DpCrrinVtGlTTp48yfLlyzEMgzNnzrB48WLat29/y3Xi4+NJTk6mYMGC2ZhU5NaaVCjE/AEB+Lo7seNkNF2+2UBUdILZsURERERERAA4F5tI12nXCqmSBdwIHdBEhZTcF7mulJo3bx5BQUE4OztTvHhxChQowFdffXXLdd58801KlixJy5YtbzkmMTGRmJiYNA+R+6lOqQIsHBRIcW9XDpy9Quep6zl2Ic7sWCIiIiIiks+dv5JIt2kbOXQuDj8fV0IHNKGUr7vZsSSPylWl1N69exk6dCijR49m69atrFixgiNHjjB48OCbjp84cSKhoaEsWbIEV9dbn/c6fvx4fHx87I/SpUvfr5cgYle5mBeLBgdStpA7Jy9dpfPUDfwdpUJURERERETMcTEuiR7fbeLA2SsU83YhdEATyhRSISX3T666plTPnj1JSEhg0aJF9mV//vknzZo14/Tp0/j5+dmXf/zxx7z33nusWrWKhg0b3nbfiYmJJCYm2r+OiYmhdOnSuv6BZIuzsQn0mr6Zv6Ni8XFzYmbfRtQv42t2LBGRfEnXQMpaej9FRHKPy/FJdJu2ib2RMRTxciFsYBMqFPE0O5bkUnnymlLx8fE4OKSNbLVaAfh3t/bRRx/x7rvvsmLFijsWUgAuLi54e3uneYhkl6JeroQNDKR+mQJEX02mx3eb+PPAebNjiYiIiIhIPhEdn0yP6dcKqcKe146QUiEl2cHUUurKlStEREQQEREBwJEjR4iIiOD48eMAjBgxIs0d8zp06MCSJUuYMmUKhw8f5q+//mLo0KE0btyYEiVKANdO2Xv77beZMWMG5cqVIyoqiqioKK5cuZLtr08ko3zcnZjbP4BmlQsTn5RKv5BwVuyOMjuWiIiIiIjkcTEJyfSasYndp2Io5OHM/AEBVCqqQkqyh6ml1JYtW6hXrx716tUDYPjw4dSrV4/Ro0cDEBkZaS+oAPr06cOnn37KpEmTqFWrFs888wxVq1ZlyZIl9jGTJ08mKSmJzp074+fnZ398/PHH2fviRDLJ3dmR73o3pF2t4iSl2nh+3lYWbTlhdiwREREREcmjYhOS6T1jMztORuPr7sS8AQFUKeZldizJR3LMNaVyEl3/QMyUkmrjraW7WLjlJACjH69BvwfLm5xKRCR/0Bwga+n9FBHJua4kptB7xma2HruEj5sT8wcEULOEj9mxJI/Ik9eUEskPHK0OTHi6Dv3/V0S989+9fLryH9Qfi4jkX5MnT6Z8+fK4urrSoEED1q1bd8uxS5YsoVWrVhQpUgRvb28CAwP55Zdf0o1p2LAhBQoUwMPDg7p16zJnzpx72q+IiOQe8Ukp9JsZztZjl/B2dWRefxVSYg6VUiI5kMViYWT76rzaugoAX/52gHH/2YvNpmJKRCS/CQsLY9iwYYwcOZLt27fTrFkz2rVrl+YSB/+2du1aWrVqxfLly9m6dSstWrSgQ4cObN++3T6mYMGCjBw5kg0bNrBz50769u1L375905RXmd2viIjkDlf/dw3bzUcv4uXiyJzgAGqVVCEl5tDpezehQ80lJ5m94Sijf9gDQKf6JZn4dB0creqTRUTuh5w4BwgICKB+/fpMmTLFvqx69ep07NiR8ePHZ2gbNWvWJCgoyH7dzpupX78+7du35913382y/ebE91NEJD9LSE6l/6wt/HnwPJ4ujswObkz9Mr5mx5I8SKfvieQRvQLL8VmQP1YHC0u2neL5edtISE41O5aIiGSDpKQktm7dSuvWrdMsb926NevXr8/QNmw2G7GxsRQsWPCmzxuGwW+//cb+/ft56KGHsmy/IiKSsyQkpzJwzlb+PHgeD2crs/o1UiElpnM0O4CI3NlT9Urh6eLEkPnb+HXvGfqFhPNtr4Z4uugjLCKSl50/f57U1FSKFSuWZnmxYsWIiorK0DY++eQT4uLi6NKlS5rl0dHRlCxZksTERKxWK5MnT6ZVq1b3tN/ExEQSExPtX8fExGQoo4iI3F+JKak8N3cra/85h5uTlZl9G9Og7M1/WCGSnXSklEgu0apGMUL6NsLD2cr6Qxfo/t0mLsUlmR1LRESygcViSfO1YRjplt1MaGgoY8eOJSwsjKJFi6Z5zsvLi4iICMLDw3n//fcZPnw4a9asuaf9jh8/Hh8fH/ujdOnSd8woIiL3V1KKjSHztrF6/zlcnRyY0acRjcurkJKcQaWUSC7StGJh5g9ogq+7EztOXCbo2w2ciUkwO5aIiNwnhQsXxmq1pjs66ezZs+mOYrpRWFgYwcHBLFy4kJYtW6Z73sHBgUqVKlG3bl1eeeUVOnfubL9W1N3ud8SIEURHR9sfJ06cyOhLFRGR+yA51caLodtYte8sLo4OTO/diMCKhcyOJWKnUkokl/EvXYCFgwIp5u3CP2eu0Hnqeo5fiDc7loiI3AfOzs40aNCAlStXplm+cuVKmjZtesv1QkND6dOnD/Pnz6d9+/YZ2pdhGPZT7+52vy4uLnh7e6d5iIiIOVJSbby0YDu/7DmDs6MD03o15IFKhc2OJZKGLkgjkgtVLubF4sFN6TF9E8cuxNN56nrmBAdQtbiX2dFERCSLDR8+nJ49e9KwYUMCAwP59ttvOX78OIMHDwauHZ106tQpZs+eDVwrpHr16sUXX3xBkyZN7Ec7ubm54eNz7Zbf48ePp2HDhlSsWJGkpCSWL1/O7Nmz09xp7077FRGRnCsl1cbLC3ewfFcUzlYHvunRgIeqFDE7lkg6KqVEcqnSBd1ZNCiQXjM283dULF2+2UBI30bU0x00RETylKCgIC5cuMA777xDZGQktWrVYvny5ZQtWxaAyMhIjh8/bh//zTffkJKSwpAhQxgyZIh9ee/evQkJCQEgLi6O559/npMnT+Lm5ka1atWYO3cuQUFBGd6viIjkTKk2g1cX7eA/O07jZLUwuXt9WlQreucVRUxgMQzDMDtEThMTE4OPjw/R0dE67FxyvMvxSfQNCWf78cu4O1t1WK6IyD3QHCBr6f0UEcleqTaD1xbvYMm2Uzg6WJjUrT5taxU3O5bkQxmdA+iaUiK5XAF3Z+YGB/BgpcLEJ6XSd2Y4K3Zn7DbhIiIiIiKSN9hsBiOW7GTJtlNYHSx82bWeCinJ8VRKieQBHi6OTO/TkLY1i5OUauP5eVtZvPWk2bFERERERCQb2GwGI5ftZuGWkzhY4POgujxW28/sWCJ3pFJKJI9wcbQyqVs9nmlQCpsBry7awcy/jpgdS0RERERE7iPDMBjz4x5CNx/HwQKfBdWlg38Js2OJZIhKKZE8xNHqwISn6xD8YHkAxv1nL5+v+gddOk5EREREJO8xDINx/9nLnI3HsFjgo87+PFm3pNmxRDJMpZRIHuPgYOHt9tUZ3qoKAJ+vOsA7/92LzaZiSkREREQkrzAMg/d+2kfI+qMATOhUh6cblDI3lEgmqZQSyYMsFgtDH63M2A41AJj511Fe/34nKak2k5OJiIiIiMi9MgyDD3/+m+l/XrtcxwdP1aZLo9ImpxLJPJVSInlYnwfK88kz/lgdLCzeepLn520jITnV7FgiIiIiInKXDMPg41/3883awwC827EW3QLKmJxK5O6olBLJ455uUIop3evj7OjAr3vPEDwrnLjEFLNjiYiIiIjIXfh81QG+Xn0IgLEdatCzSVmTE4ncPZVSIvlA65rFCenbCA9nK38dvED37zZxOT7J7FgiIiIiIpIJX/52gC9+OwDA2+2r0+eB8iYnErk3KqVE8ommFQszb0ATCrg7EXHiMkHfbORsTILZsUREREREJAO+Xn2QT1f+A8CIdtXo36yCyYlE7p1KKZF8pG7pAiwcFEhRLxf2n4ml89QNnLgYb3YsERERERG5jW/+OMRHv+wH4LU2VRnUvKLJiUSyhkopkXymSjEvFg9uSpmC7hy/GM/TU9bzz5lYs2OJiIiIiMhNfLfuMON//huA4a2qMKRFJZMTiWQdlVIi+VCZQu4sHhxI1WJenI1NpMs3G4g4cdnsWCIiIiIi8i8hfx3hvZ/2ATD00coMfbSyyYlEspZKKZF8qqi3K2GDmlC3dAEuxyfTfdpG1h88b3YsEREREREB5mw8xtj/7AVgSIuKvNxShZTkPSqlRPKxAu7OzOsfwAOVChGXlEqfkHB+3RNldiwRERERkXwtdPNxRi3bDcCg5hV4tXVVLBaLyalEsp5KKZF8zsPFkRl9GtGmZjGSUmw8N28bS7adNDuWiIiIiEi+tDD8BCOW7AIg+MHyvNm2mgopybNUSokILo5Wvu5Wn6frlyLVZjB84Q5C/jpidiwRERERkXzl+60neWPJTgD6NC3H2+2rq5CSPE2llIgA4Gh14KPOdej7QDkAxv5nL1/+dgDDMMwNJiIiIiKSDyzbfopXF+/AMKBHkzKM6VBDhZTkeSqlRMTOwcHC6Mdr8HLLKgB8uvIf3v3vPmw2FVMiIiIiIvfLf3acZvjCCAwDujYuwztP1FIhJfmCSikRScNisfBSy8qM6VADgBl/HeH173eSkmozOZmIiIiISN7z865IhoVFYDOgS8NSvN+xFg4OKqQkf1ApJSI31feB8nzyjD9WBwuLt57khfnbSUxJNTuWiIiIiEie8cueKF4M3U6qzaBT/ZJ82KmOCinJV1RKicgtPd2gFJO718fZ6sCKPVH0n7WFuMQUs2OJiIiIiOR6q/ae4YX520ixGTxZtwQfdfZXISX5jkopEbmtNjWLM7NvI9ydraw7cJ4e0zdxOT7J7FgiIiIiIrnW6r/P8vy8bSSnGjxex89+hoJIfqNSSkTu6IFKhZnXPwAfNye2H79M0DcbORuTYHYsEREREZFcZ+0/5xg0dytJqTYeq12cz4Pq4mjVf80lf9J3vohkSL0yviwcFEhRLxf2n4nlmW82cOJivNmxRERERERyjb8OnmfA7C0kpdhoU7MYXzxbT4WU5Gv67heRDKta3IvFg5tSuqAbxy7E03nqeg6ciTU7loiIiIhIjrfh0AWCZ4WTmGKjZfWifNW1Pk4qpCSf0ydARDKlTCF3Fg9uSpVinpyJSaTLNxvYceKy2bFERERERHKszUcu0i8knIRkGy2qFuHr7vVxdtR/x0X0KRCRTCvm7UrYwED8SxfgUnwy3aZtZMOhC2bHEhERERHJcbYcvUifmZu5mpxKs8qFmdKjAS6OVrNjieQIKqVE5K74ejgzr38ATSsWIi4pld4zN7Ny7xmzY4mIiIiI5Bjbjl+iz8xw4pNSeaBSIab1aoirkwopketUSonIXfN0cWRGn0a0rlGMpBQbg+duZen2k2bHEhEREREx3Y4Tl+k9fTNXElNoUqEg3/VqpEJK5AYqpUTknrg6WZncvT6d6pck1WbwctgOZq0/anYsERERERHT7D4VTc/pm4hNTKFxuYLM6NMIN2cVUiI3UiklIvfM0erAx5396dO0HABjftzDV78dwDAMc4OJiIiIiGSzPaej6f7dJmISUmhY1pcZfRvh7uxodiyRHEmllIhkCQcHC2M61OClRysD8MnKf3j/p30qpkREREQk3/g7KoYe320i+moy9coUYGbfRni6qJASuRWVUiKSZSwWCy+3qsLox2sA8N2fR3jj+52k2lRMiYiIiEje9s+ZWLpP28Sl+GT8S/kwq19jvFydzI4lkqOplBKRLNfvwfJ81LkODhZYuOUkL8zfRmJKqtmxRERERETui4NnY+k2bSMX4pKoVdKb2f0C8FYhJXJHKqVE5L54pmFpJndvgLPVgZ93R9F/1hbik1LMjiUiIiIikqUOn7tC12mbOH8liRp+3swNDsDHXYWUSEaolBKR+6ZtreLM6NMId2cr6w6cv3Z+fXyy2bFERERERLLE0fNxdJ22kXOxiVQr7sXc/gEUcHc2O5ZIrqFSSkTuqwcrF2Zu/wB83JzYdvwyQd9u4GxsgtmxRERERETuyfEL8XSdtpEzMYlULurJ3P4BFPRQISWSGSqlROS+q1/Gl7BBTSji5cLfUbF0mbqBExfjzY4lIiIiInJXTly8VkhFRidQsYgH8wc0obCni9mxRHIdlVIiki2qFfdm8eBAShd04+iFeJ6ZuoGDZ2PNjiUiIiIikimnLl+l23cbOXX5KhUKexA64NoPX0Uk81RKiUi2KVvIg0WDmlK5qCdRMQk8M3UDO09eNjuWiIiIiEiGREUn0G3aRk5cvErZQu7MH9CEot6uZscSybVMLaXWrl1Lhw4dKFGiBBaLhWXLlt1xnXnz5uHv74+7uzt+fn707duXCxcu2J/fs2cPTz/9NOXKlcNisfD555/fvxcgIplW3MeVhYMC8S/lw6X4ZLpN28SGQxfuvKKIiIiIiInOxiTQddpGjl2Ip3RBN0IHNKG4jwopkXthaikVFxeHv78/kyZNytD4P//8k169ehEcHMyePXtYtGgR4eHh9O/f3z4mPj6eChUq8OGHH1K8ePH7FV1E7oGvhzPzBjQhsEIhriSm0HvmZlbtPWN2LBERERGRmzobe62QOnI+jpIFrhVSJQq4mR1LJNdzNHPn7dq1o127dhkev3HjRsqVK8fQoUMBKF++PIMGDWLixIn2MY0aNaJRo0YAvPnmm1kbWESyjKeLIzP7NuLF0O2s3HuGQXO38skz/nSsV9LsaCIiIiIiduevJNJ92iYOnYujhI8rCwY2oZSvu9mxRPKEXHVNqaZNm3Ly5EmWL1+OYRicOXOGxYsX0759e7OjichdcHWyMqV7fTrVK0mqzeDlhRHM2XDU7FgiIiIiIgBcjEui+7RNHDh7heLerswf0ITSBVVIiWSVXFdKzZs3j6CgIJydnSlevDgFChTgq6++uqftJiYmEhMTk+YhItnD0erAx8/40zuwLIYBo37Yw6TfD2AYhtnRRERERCQfuxSXRPfvNrH/TCxFvVyYPyCAcoU9zI4lkqfkqlJq7969DB06lNGjR7N161ZWrFjBkSNHGDx48D1td/z48fj4+NgfpUuXzqLEIpIRDg4Wxj5Rk6GPVgbg41//4YPl+1RMiYiIiIgpouOT6TF9E/siYyjs6cL8AU2oUMTT7FgieU6uKqXGjx/PAw88wGuvvUadOnVo06YNkydPZsaMGURGRt71dkeMGEF0dLT9ceLEiSxMLSIZYbFYGN6qCqMerwHAtHVHePP7XaTaVEyJiIiISPaJvppMzxmb2HM6hkIezoQOCKBSURVSIveDqRc6z6z4+HgcHdNGtlqtAPd0RIWLiwsuLi73lE1Eskbwg+XxcnXkze93ErblBLGJyXwWVBcXR6vZ0UREREQkj4tNSKb3jM3sPBmNr7sT8wc0oXIxL7NjieRZppZSV65c4eDBg/avjxw5QkREBAULFqRMmTKMGDGCU6dOMXv2bAA6dOjAgAEDmDJlCm3atCEyMpJhw4bRuHFjSpQoAUBSUhJ79+61//7UqVNERETg6elJpUqVsv9FikimdWlYGm9XR4aGRrB8VxSxCVv4pmcD3J1zVY8uIiIiIrnIlcQU+swMJ+LEZQq4OzGvfxOqFlchJXI/WQwTL9qyZs0aWrRokW557969CQkJoU+fPhw9epQ1a9bYn/vqq6+YOnUqR44coUCBAjzyyCNMmDCBkiWv3Ub+6NGjlC9fPt02mzdvnmY7txMTE4OPjw/R0dF4e3vf1WsTkXu37sA5Bs7eytXkVBqU9WVGn0b4uDmZHUtE8jDNAbKW3k8RyS3iElPoM3Mz4Ucv4e3qyPwBTahV0sfsWCK5VkbnAKaWUjmVJlAiOcfWY5foO3MzMQkpVPfzZna/xhTx0um2InJ/aA6QtfR+ikhucDUplb4hm9l4+CJero7M6x9AnVIFzI4lkqtldA6Qqy50LiL5T4OyvoQNCqSwpwv7ImN4Zup6Tl6KNzuWiIiIiOQBCcmp9J8dzsbDF/F0cWR2v8YqpESykUopEcnxqvt5s3hwIKV83Th6IZ7OUzZw8Gys2bFEREREJBdLSE5lwOwt/HXwAh7OVmb1a0S9Mr5mxxLJV1RKiUiuUK6wB4sHN6VSUU+iYhLo8s1Gdp2MNjuWiIiIiORCiSmpDJ67lXUHzuPmZGVm38Y0KFvQ7Fgi+Y5KKRHJNYr7uLJwUCB1SvlwMS6JrtM2sunwBbNjiYiIiEgukpRi4/m521iz/xyuTg7M6NOIxuVVSImYQaWUiOQqBT2cmdc/gCYVCnIlMYVeMzbz+99nzI4lIiIiIrlAcqqNIfO38dvfZ3FxdGB670YEVixkdiyRfEullIjkOl6uToT0bUzL6kVJTLExcPZWfog4ZXYsEREREcnBklNtDA3dzsq9Z3B2dGBar4Y8UKmw2bFE8jWVUiKSK7k6WZnSowFP1StJis1gWFgEczYeMzuWiIiIiORAKak2Xg6L4OfdUThbHfimZwMeqlLE7Fgi+Z5KKRHJtZysDnzyjD+9AstiGDBq2W6+Xn0QwzDMjiYiIiIiOUSqzeCVRTv4785InKwWpvSoT4uqRc2OJSKolBKRXM7BwcK4J2ry4iOVAPjol/18+PPfKqZEREREhFSbwWuLdvBDxGkcHSxM6lafR6sXMzuWiPyPSikRyfUsFguvtK7K2+2rA/DN2sO8tXQXqTYVUyIiIiL5lc1m8Ob3O1my/RRWBwtfda1Hm5rFzY4lIv+iUkpE8oz+zSow8ek6OFggdPMJhoZuJynFZnYsEREREclmNpvBW0t3sWjrSRws8MWzdWlX28/sWCJyA5VSIpKndGlUmknd6uNktfDTrkj6z95CfFKK2bFEREREJJsYhsHoH3ezIPwEDhb4LKguj9cpYXYsEbkJlVIikuc8VtuP6b0b4eZkZe0/5+g1fTPRV5PNjiUiIiIi95lhGIz7z17mbjyOxQIfP+PPk3VLmh1LRG5BpZSI5EkPVSnC3P6N8XZ1ZMuxS3T9diPnYhPNjiUiclcmT55M+fLlcXV1pUGDBqxbt+6WY5csWUKrVq0oUqQI3t7eBAYG8ssvv6QZM23aNJo1a4avry++vr60bNmSzZs3pxkzduxYLBZLmkfx4roWi4jkXIZh8O5/9xGy/igAE56uQ6f6pcwNJSK3pVJKRPKsBmULEjYokMKeLuyNjKHLNxs4dfmq2bFERDIlLCyMYcOGMXLkSLZv306zZs1o164dx48fv+n4tWvX0qpVK5YvX87WrVtp0aIFHTp0YPv27fYxa9asoWvXrqxevZoNGzZQpkwZWrduzalTp9Jsq2bNmkRGRtofu3btuq+vVUTkbhmGwfif/2bGX0cAGN+pNl0aljY5lYjcicXQfdPTiYmJwcfHh+joaLy9vc2OIyL36Mj5OHp8t4lTl6/i5+PKnOAAKhX1NDuWiORAOXEOEBAQQP369ZkyZYp9WfXq1enYsSPjx4/P0DZq1qxJUFAQo0ePvunzqamp+Pr6MmnSJHr16gVcO1Jq2bJlRERE3HX2nPh+ikjeYxgGE3/Zz5Q1hwB4r2MtejQpa3Iqkfwto3MAx2zMJCJiivKFPVj8XCA9p2/m4NkrdPlmA7P7NaZWSR+zo4nkaSmpNhJSbCQmp9p/TUyxkXCLX68/n+65ZBsJKWl/LVfYg/Gdapv9Eu+7pKQktm7dyptvvplmeevWrVm/fn2GtmGz2YiNjaVgwYK3HBMfH09ycnK6MQcOHKBEiRK4uLgQEBDABx98QIUKFTL/QkRE7qPPVv5jL6TGPVFThZRILqJSSkTyBT8fNxYOCqT3jM3sOhVN12838l3vhgRUKGR2NJH7yjAMklJtaQqexJRUEv7367Wvb10U2Qsj+zq3KZP+VT4lpNhItd2/g7FjE/PHzQvOnz9PamoqxYoVS7O8WLFiREVFZWgbn3zyCXFxcXTp0uWWY958801KlixJy5Yt7csCAgKYPXs2VapU4cyZM7z33ns0bdqUPXv2UKjQzf/uTExMJDHx/6/fFxMTk6GMIiJ364tVB/jy94MAjHq8Br2bljM3kIhkikopEck3Cno4M39AAP1nbWHTkYv0mrGZqT0a0KJaUbOjST5gs10rh25b/mSiILqxXLrx13+Pzwkn6js7OuDi6ICLoxVXp2u/d3Wy3vRX+xgnK66O1351cUz7dWEPZ7NfUrayWCxpvjYMI92ymwkNDWXs2LH88MMPFC1687/rJk6cSGhoKGvWrMHV1dW+vF27dvbf165dm8DAQCpWrMisWbMYPnz4Tbc1fvx4xo0bl5GXJCJyz75efZDPVv0DwFuPVSP4wfImJxKRzFIpJSL5iperE7P6NWbIvG389vdZBszewqdBdXnCv4TZ0SSbpPzvqKGMlD+3PRLoNiXQ///6/wVSUqrN7JcOgKvTTcqfm/zqcv3X25RHaX69TdHkbHXAweHOBYqkV7hwYaxWa7qjos6ePZvu6KkbhYWFERwczKJFi9IcAfVvH3/8MR988AGrVq2iTp06t92eh4cHtWvX5sCBA7ccM2LEiDSFVUxMDKVL60LDIpL1pv5xiI9+2Q/A622rMvChiiYnEpG7oVJKRPIdVycrU3s24NVFO/gh4jQvLdhObEIy3QN0/YHsYhgGyanG/18nKN0pYrc+Euhm1xe61XWLkm5SFKXcx1PKMsrqYLEf8XPjkUA3L3YyXhC53LjOv0ooZ6tDho6ukZzD2dmZBg0asHLlSp566in78pUrV/Lkk0/ecr3Q0FD69etHaGgo7du3v+mYjz76iPfee49ffvmFhg0b3jFLYmIi+/bto1mzZrcc4+LigouLyx23JSJyL75bd5gPf/4bgFdaVeH5hyuZnEhE7pZKKRHJl5ysDnzWpS7erk7M2XiMkUt3E301Od9NagzD+N8RQOmLntudGna7o4NuvJj1zUuk1JxxSpnV4dZFzq1+tR9ldLMi6NZF0b9LKEerg9kvXXKR4cOH07NnTxo2bEhgYCDffvstx48fZ/DgwcC1o5NOnTrF7NmzgWuFVK9evfjiiy9o0qSJ/SgrNzc3fHyu3eBh4sSJjBo1ivnz51OuXDn7GE9PTzw9r92d9NVXX6VDhw6UKVOGs2fP8t577xETE0Pv3r2z+y0QEbGb+dcR3vtpHwAvPVqZFx+tbHIiEbkXKqVEJN9ycLDwzpM18XFzYtLqg0xcsZ/oq8m82bZath9Nkmozbl3+ZPDUsv8/2ihjp6MlpNhISskZp5TdvtBJXwzdWBzd7jS0dKelXT+lzNEBq04pk1wgKCiICxcu8M477xAZGUmtWrVYvnw5ZcteO7ozMjKS48eP28d/8803pKSkMGTIEIYMGWJf3rt3b0JCQgCYPHkySUlJdO7cOc2+xowZw9ixYwE4efIkXbt25fz58xQpUoQmTZqwceNG+35FRLLbnA1HGfefvQC80KISw1qqkBLJ7SyGkRN+Vp2zxMTE4OPjQ3R0NN7e3mbHEZFsMG3tYd5ffu2nbl0bl2F4qyp3PBIozZE/d7xj2f/fuSx9iZRKcqr5fxU7WLjjKWF3Ln3+dzRQBoohl38dcaRTyiSn0Bwga+n9FJGsMn/Tcd5auguAwc0r8kbbqpo/iORgGZ0D6EgpERFgwEMV8HZzZMSSXYRuPk7o5uN3Xuk+cbJabnrB6RvvWJaho4JudzraDaehOTpYNLkTERGRHGdh+Al7IdX/wfIqpETyEJVSIiL/E9SoDF6uTry1dBeX45NxdnT4/+sA3eFUsIxcX+hmdyu72WlpOqVMRERE5JrFW0/yxpKdAPRpWo6R7aurkBLJQ+6qlDpx4gQWi4VSpUoBsHnzZubPn0+NGjUYOHBglgYUEclOj9X2o23N4gC6hb2IiIiIiZZuP8lri3dgGNCzSVnGdKihQkokj7mr2/9069aN1atXAxAVFUWrVq3YvHkzb731Fu+8806WBhQRyW4ODhYVUiIiIiIm+nHHaV5ZeK2Q6hZQhnFP1FQhJZIH3VUptXv3bho3bgzAwoULqVWrFuvXr2f+/Pn2u7qIiIiIiIiIZNZPOyN5OSwCmwFBDUvz3pO19ANDkTzqrkqp5ORkXFxcAFi1ahVPPPEEANWqVSMyMjLr0omIiIiIiEi+sWJ3FC8t2E6qzeDp+qUY36m2CimRPOyuSqmaNWsydepU1q1bx8qVK2nbti0Ap0+fplChQlkaUERERERERPK+lXvP8ML8baTYDDrWLcHEznVUSInkcXdVSk2YMIFvvvmGhx9+mK5du+Lv7w/Ajz/+aD+tT0RERERERCQjfv/7DM/P20qKzaCDfwk+fsZfdyQWyQfu6u57Dz/8MOfPnycmJgZfX1/78oEDB+Lu7p5l4URERERERCRv++Ofcwyes43kVIP2tf34rIs/jta7On5CRHKZu/qkX716lcTERHshdezYMT7//HP2799P0aJFszSgiIiISF5y4sQJ+vXrZ3YMEZEc4c8D5xkwewtJqTba1CzG58/WVSElko/c1af9ySefZPbs2QBcvnyZgIAAPvnkEzp27MiUKVOyNKCIiIhIXnLx4kVmzZpldgwREdOtP3Se/rPDSUqx0bJ6Mb7qWh8nFVIi+cpdnb63bds2PvvsMwAWL15MsWLF2L59O99//z2jR4/mueeey9KQIiIiIrnFjz/+eNvnDx8+nE1JRERyrk2HLxAcsoWEZBstqhbh6+71cHZUISWS39xVKRUfH4+XlxcAv/76K506dcLBwYEmTZpw7NixLA0oIiIikpt07NgRi8WCYRi3HGOx6OK9IpJ/bTl6kb4h4VxNTuWhKkWY0qMBLo5Ws2OJiAnuqoquVKkSy5Yt48SJE/zyyy+0bt0agLNnz+Lt7Z2lAUVERERyEz8/P77//ntsNttNH9u2bTM7ooiIabYeu0TvGZuJT0rlwUqF+bZnA1ydVEiJ5Fd3VUqNHj2aV199lXLlytG4cWMCAwOBa0dN1atXL0sDioiIiOQmDRo0uG3xdKejqERE8qqIE5fpM2MzcUmpBFYoxLReDVVIieRzd3X6XufOnXnwwQeJjIzE39/fvvzRRx/lqaeeyrJwIiIiIrnNa6+9Rlxc3C2fr1SpEqtXr87GRCIi5tt1Mpqe0zcRm5hC4/IFmd6nIW7OKqRE8ru7KqUAihcvTvHixTl58iQWi4WSJUvSuHHjrMwmIiIikuuULFmS8uXL3/J5Dw8Pmjdvno2JRETMted0ND2mbyI2IYWGZX2Z2acR7s53/V9REclD7ur0PZvNxjvvvIOPjw9ly5alTJkyFChQgHfffRebzZbVGUVERERyjcqVK3Pu3Dn710FBQZw5c8bERCIi5tkXGUOP7zYRfTWZemUKMLNvIzxcVEiJyDV3VUqNHDmSSZMm8eGHH7J9+3a2bdvGBx98wFdffcWoUaOyOqOIiIhIrnHj9aKWL19+29P5RETyqv1RsXT/bhOX4pPxL+XDrH6N8XJ1MjuWiOQgd1VRz5o1i++++44nnnjCvszf35+SJUvy/PPP8/7772dZQBEREREREcldDpyJpft3G7kYl0Ttkj7MDg7AW4WUiNzgrkqpixcvUq1atXTLq1WrxsWLF+85lIiIiEhuZbFYsFgs6ZaJiOQXu09F02vGZi7GJVHDz5s5wY3xcVMhJSLp3VUp5e/vz6RJk/jyyy/TLJ80aRJ16tTJkmAiIiIiuZFhGPTp0wcXFxcAEhISGDx4MB4eHmnGLVmyxIx4IiL31bbjl+gzYzMxCSnXjpDq15gC7s5mxxKRHOquSqmJEyfSvn17Vq1aRWBgIBaLhfXr13PixAmWL1+e1RlFREREco3evXun+bpHjx4mJRERyV4bD18gOCScuKRUGpb1ZUbfRjplT0Ru665KqebNm/PPP//w9ddf8/fff2MYBp06dWLgwIGMHTuWZs2aZXVOERERkVxh5syZZkcQEcl2f/xzjoGzt5CYYqNpxUJ817sh7s66y56I3J7FuPEWMfdgx44d1K9fn9TU1KzapCliYmLw8fEhOjoab29vs+OIiIhINtEcIGvp/RTJH37dE8UL87eTlGqjRdUiTOnRAFcnq9mxRMREGZ0DqLoWERERERGRu/LjjtO8HBZBqs2gXa3ifPFsPZwdHcyOJSK5hEopERERERERybSFW07wxvc7MQx4ql5JPupcB0erCikRyTiVUiIiIiIiIpIpszccZfQPewDo2rgM73eshYODxeRUIpLbZKqU6tSp022fv3z5cqZ2vnbtWj766CO2bt1KZGQkS5cupWPHjrddZ968eUycOJEDBw7g4+ND27Zt+fjjjylUqJB9zPfff8+oUaM4dOgQFStW5P333+epp57KVDYRERERERFJ75s/DjH+578B6PdAeUY9Xh2LRYWUiGRepo6t9PHxue2jbNmy9OrVK8Pbi4uLw9/fn0mTJmVo/J9//kmvXr0IDg5mz549LFq0iPDwcPr3728fs2HDBoKCgujZsyc7duygZ8+edOnShU2bNmXmpYqIiIiIiMi/GIbB56v+sRdSL7SopEJKRO5Jlt59715YLJY7Hin18ccfM2XKFA4dOmRf9tVXXzFx4kROnDgBQFBQEDExMfz888/2MW3btsXX15fQ0NAMZdGdYkRERPInzQGylt5PkbzDMAw+/Plvvll7GIDX2lRlSItKJqcSkZwqo3OAXHUVuqZNm3Ly5EmWL1+OYRicOXOGxYsX0759e/uYDRs20Lp16zTrtWnThvXr12d3XBERERERkVzPZjMY8+MeeyE16vEaKqREJEvkqgudN23alHnz5hEUFERCQgIpKSk88cQTfPXVV/YxUVFRFCtWLM16xYoVIyoq6pbbTUxMJDEx0f51TExM1ocXERERERHJZVJtBm98v5PFW09iscD7HWvTLaCM2bFEJI/IVUdK7d27l6FDhzJ69Gi2bt3KihUrOHLkCIMHD04z7sZzmg3DuO15zuPHj09zbazSpUvfl/wiIiIiIiK5RXKqjZcWbGfx1pM4WODTLv4qpEQkS+WqI6XGjx/PAw88wGuvvQZAnTp18PDwoFmzZrz33nv4+flRvHjxdEdFnT17Nt3RU/82YsQIhg8fbv86JiZGxZSIiIiIiORbiSmpvDB/Oyv3nsHRwcKXXevxWG0/s2OJSB6Tq46Uio+Px8EhbWSr1QpcOxoKIDAwkJX/196dh1dR3v8bv08SEtaEHUEQcEMBZSegoqKAolKxKqLIJqhYlyL1169rRW2LtW7UBUU2UUC0CtqKIlYBN0AQEAUXCghCkEVJIEBCkvn9cTQ1bAaETE5yv65rLnLmPGfm8+RkTh7emXlmxowCbd566y1OOeWUfW43KSmJ5OTkAoskSZIklUY7snMZ+Ox8Ziz9jsSEOEb2aWUgJemwCPVMqW3btrF8+fL8xytXrmTRokVUrVqVo446ittuu421a9cyfvx4ALp168bVV1/NiBEjOOecc0hLS2Pw4MG0bduWOnXqAPD73/+e008/nb/97W9ceOGFvPrqq7z99tu8//77ofRRkiRJkmLFtqwcrhr3MfNWfk+5MvGM6tuaU4+tHnZZkkqoUEOp+fPn07Fjx/zHP11C17dvX8aNG0daWhqrV6/Of75fv35s3bqVxx9/nD/84Q9UrlyZs846i7/97W/5bU455RReeOEF7rzzTu666y6OOeYYJk+eTGpqatF1TJIkSZJiTPr2XfQdO49Fa7ZQKSmBsf3b0LpB1bDLklSCRYKfrntTvoyMDFJSUkhPT/dSPkmSShHHAIeW308pdmzelkXv0fNYmpZB5fJlGH9VW06uWznssiTFqMKOAWJqonNJkiRJ0qG1IWMnvUbN5esN26heMZHnB6ZywhEGyZIOP0MpSZIkSSql1m7ZQa9n5rBq83aOSC7LhKtTOaZGxbDLklRKGEpJkiRJUim0alMmvUbNZe2WHdStUo5JV7ejXtXyYZclqRQxlJIkSZKkUubr77bSa9RcNmzN4ujqFZhwdSq1U8qFXZakUsZQSpIkSZJKkc/WptNnzDy+z8ymUa1KPD8wlRqVksIuS1IpZCglSZIkSaXEwtU/0HfMPDJ25nDSkSmMv6otVSokhl2WpFLKUEqSJEmSSoE5KzYzYNzHZGbn0qp+Fcb2b0Ny2TJhlyWpFDOUkiRJkqQSbtZXG7n2ufns3JXHKcdU45k+ramQ5H8HJYXLTyFJkiRJKsHe+nw9N0xcSHZuHh0b1WDEla0oWyY+7LIkyVBKkiRJkkqqfy1ex+DJi8jNC+ja9AiG92xBYkJc2GVJEmAoJUmSJEkl0kvz1/B/L39KXgAXtTiSv19yMgnxBlKSig9DKUmSJEkqYZ77aBV3vfo5AJe3rcdfup9EXFwk5KokqSBDKUmSJEkqQUbO/i9/nfYFAP1PbcCfLmhMJGIgJan4MZSSJEmSpBIgCAKG/+drHn37awCu73gMt3RpZCAlqdgylJIkSZKkGBcEAfe/8QVPz14BwC1djueGs44LuSpJ2j9DKUmSJEmKYXl5AUP/9TnjP/oGgLsuaMyA0xqGXJUk/TJDKUmSJEmKUbl5Abe+/CkvLfiWSAT+0v0krkg9KuyyJKlQDKUkSZIkKQbtys1jyIuL+dfidcRF4KEezbioRd2wy5KkQjOUkiRJkqQYk5WTyw0TFzJj6XckxEX4x+UtOO+k2mGXJUkHxFBKkiRJkmLIjuxcrn1+AbO/2khiQhxPXdmSs06oFXZZknTADKUkSZIkKUZsy8phwLiPmbvye8qViWdU39acemz1sMuSpINiKCVJkiRJMSB9xy76jZ3HwtVbqJiUwNj+bWjToGrYZUnSQTOUkiRJkqRi7vvMbHqPnsvn6zJIKVeG8Ve1pVm9ymGXJUm/iqGUJEmSJBVjGzJ20mvUXL7esI3qFRN5bkAqJ9ZODrssSfrVDKUkSZIkqZhau2UHvZ6Zw6rN26mVnMSEge04tmbFsMuSpEPCUEqSJEmSiqFVmzLpNWoua7fsoG6Vckwc2I6jqpUPuyxJOmTiwi5AkiRJ+/fkk0/SsGFDypYtS6tWrXjvvff22faVV16hc+fO1KhRg+TkZNq3b8/06dMLtHnmmWfo0KEDVapUoUqVKnTq1Il58+b9qv1KOrS+/m4rPZ7+iLVbdnB09Qq8eG17AylJJY6hlCRJUjE2efJkBg8ezB133MHChQvp0KEDXbt2ZfXq1XttP3v2bDp37sy0adNYsGABHTt2pFu3bixcuDC/zcyZM7n88st59913+eijjzjqqKPo0qULa9euPej9Sjp0Pl+XzmUj57BhaxaNalVi8rXtqVO5XNhlSdIhFwmCIAi7iOImIyODlJQU0tPTSU52AkFJkkqL4jgGSE1NpWXLlowYMSJ/3Yknnkj37t0ZNmxYobbRpEkTLrvsMv70pz/t9fnc3FyqVKnC448/Tp8+fQ7Zfovj91Mq7hau/oG+Y+aRsTOHk45MYfxVbalSITHssiTpgBR2DOCZUpIkScVUdnY2CxYsoEuXLgXWd+nShQ8//LBQ28jLy2Pr1q1UrVp1n222b9/Orl278tsc7H6zsrLIyMgosEgqvLkrNnPlqLlk7MyhVf0qTLg61UBKUolmKCVJklRMbdq0idzcXGrVqlVgfa1atVi/fn2htvHQQw+RmZlJjx499tnm1ltv5cgjj6RTp06/ar/Dhg0jJSUlf6lXr16hapQEs7/aSN+x88jMzuWUY6ox/qq2JJctE3ZZknRYGUpJkiQVc5FIpMDjIAj2WLc3kyZNYujQoUyePJmaNWvutc0DDzzApEmTeOWVVyhbtuyv2u9tt91Genp6/rJmzZpfrFESzFj6HQOfnc/OXXl0bFSDMf3aUCHJG6VLKvn8pJMkSSqmqlevTnx8/B5nJ23YsGGPs5h2N3nyZAYMGMBLL72UfwbU7h588EH++te/8vbbb3PyySf/6v0mJSWRlJT0S92S9DP/WryOmycvIicv4NwmR/CPy1uQmOC5A5JKBz/tJEmSiqnExERatWrFjBkzCqyfMWMGp5xyyj5fN2nSJPr168fEiRM5//zz99rm73//O/fddx9vvvkmrVu3PiT7lXRgXpq/ht+/sJCcvIDuzevw+BUGUpJKF8+UkiRJKsaGDBlC7969ad26Ne3bt2fkyJGsXr2aQYMGAdFL5tauXcv48eOBaCDVp08fhg8fTrt27fLPdipXrhwpKSlA9JK9u+66i4kTJ9KgQYP8NhUrVqRixYqF2q+kX+e5j1Zx16ufA9CzTT3+ctFJxMf98mW5klSSGEpJkiQVY5dddhmbN2/m3nvvJS0tjaZNmzJt2jTq168PQFpaGqtXr85v//TTT5OTk8P111/P9ddfn7++b9++jBs3DoAnn3yS7OxsLrnkkgL7uvvuuxk6dGih9ivp4I2c/V/+Ou0LAPqd0oC7uzUu1DxxklTSRIIgCMIuorjJyMggJSWF9PR0kpOTwy5HkiQVEccAh5bfT6mgIAj4x3+W88jbXwHwuzOP4f+d08hASlKJU9gxgGdKSZIkSdJhFgQB97/5BU/PWgHALV2O54azjgu5KkkKl6GUJEmSJB1GeXkB9/zrc5796BsA7rqgMQNOaxhyVZIUPkMpSZIkSTpMcvMCbnvlU16c/y2RCPy5e1N6pTo3mySBoZQkSZIkHRa7cvP4w4uLeW3xOuIi8OClzfhty7phlyVJxYahlCRJkiQdYlk5udw4cSFvLf2OhLgIw3u24PyTa4ddliQVK4ZSkiRJknQI7cjOZdDzC5j11UYSE+IY0aslZ59YK+yyJKnYMZSSJEmSpENkW1YOA5/9mDkrvqdcmXie6dOa046rHnZZklQsGUpJkiRJ0iGQvmMX/cbOY+HqLVRMSmBs/za0aVA17LIkqdgylJIkSZKkX+n7zGx6j57L5+sySClXhvFXtaVZvcphlyVJxZqhlCRJkiT9ChsydtJr1Fy+3rCN6hUTeW5AKifWTg67LEkq9gylJEmSJOkgrd2yg17PzGHV5u3USk5iwsB2HFuzYthlSVJMMJSSJEmSpIPwzeZMrnhmLmu37KBulXJMHNiOo6qVD7ssSYoZhlKSJEmSdICWb9jKFc/MZcPWLI6uXoHnB6ZSp3K5sMuSpJhiKCVJkiRJB2Dpugx6j57L5sxsGtWqxHMD21KzUtmwy5KkmGMoJUmSJEmFtGjNFvqMnkvGzhyaHpnMc1elUqVCYthlSVJMigtz57Nnz6Zbt27UqVOHSCTC1KlT99u+X79+RCKRPZYmTZrkt9m1axf33nsvxxxzDGXLlqVZs2a8+eabh7knkiRJkkq6eSu/58pR0UCq5VGVmTCwnYGUJP0KoYZSmZmZNGvWjMcff7xQ7YcPH05aWlr+smbNGqpWrcqll16a3+bOO+/k6aef5rHHHmPp0qUMGjSIiy66iIULFx6ubkiSJEkq4d77eiN9xsxlW1YO7Y+uxnMDUkkpVybssiQppoV6+V7Xrl3p2rVrodunpKSQkpKS/3jq1Kn88MMP9O/fP3/dc889xx133MF5550HwHXXXcf06dN56KGHeP755w9d8ZIkSZJKhbeXfsfvJnxCdm4eZzaqwVNXtqJsmfiwy5KkmBfTc0qNHj2aTp06Ub9+/fx1WVlZlC1bcJLBcuXK8f777xd1eZIkSZJi3L8Wr+PmyYvIyQs4p0kt/nF5C5ISDKQk6VCI2VAqLS2NN954g4kTJxZYf8455/Dwww9z+umnc8wxx/Cf//yHV199ldzc3H1uKysri6ysrPzHGRkZh61uSZIkSbHhnwu+5Y//XExeAN2b1+HBS5uREB/qDCiSVKLE7CfquHHjqFy5Mt27dy+wfvjw4Rx33HGccMIJJCYmcsMNN9C/f3/i4/f914xhw4blXxqYkpJCvXr1DnP1kiRJkoqz5+Z8wy0vRQOpnm3q8VCP5gZSknSIxeSnahAEjBkzht69e5OYWPBuFzVq1GDq1KlkZmbyzTff8MUXX1CxYkUaNmy4z+3ddtttpKen5y9r1qw53F2QJEmSVEw9M3sFd039DIB+pzRg2G9PIj4uEnJVklTyxOTle7NmzWL58uUMGDBgn23Kli3LkUceya5du3j55Zfp0aPHPtsmJSWRlJR0OEqVJEmSFCOCIOCxd5bz8IyvAPjdmcfw/85pRCRiICVJh0OoodS2bdtYvnx5/uOVK1eyaNEiqlatylFHHcVtt93G2rVrGT9+fIHXjR49mtTUVJo2bbrHNufOncvatWtp3rw5a9euZejQoeTl5fHHP/7xsPdHkiRJUmwKgoC/vfklT836LwC3dDmeG846LuSqJKlkCzWUmj9/Ph07dsx/PGTIEAD69u3LuHHjSEtLY/Xq1QVek56ezssvv8zw4cP3us2dO3dy5513smLFCipWrMh5553Hc889R+XKlQ9bPyRJkiTFrry8gHv/vZRxH64C4M7zT2Rgh6PDLUqSSoFIEARB2EUUNxkZGaSkpJCenk5ycnLY5UiSpCLiGODQ8vupWJCbF3D7K0uYPD86r+yfuzflynb1Q65KkmJbYccAMTmnlCRJkiT9Wrty87jlpcW8umgdcRH4+yXNuLhV3bDLkqRSw1BKkiRJUqmTlZPLTZMWMv3z70iIizC8ZwvOP7l22GVJUqliKCVJkiSpVNmRncug5xcw66uNJMbH8WSvlnRqXCvssiSp1DGUkiRJklRqbMvKYeCzHzNnxfeUKxPPM31ac9px1cMuS5JKJUMpSZIkSaVC+o5d9Bs7j4Wrt1AxKYGx/dvQpkHVsMuSpFLLUEqSJElSifd9Zja9R8/l83UZpJQrw/ir2tKsXuWwy5KkUs1QSpIkSVKJtiFjJ1eOnstX322jWoVEnh+Yyom1932LcklS0TCUkiRJklRirduyg16j5rJyUya1kpOYMLAdx9asGHZZkiQMpSRJkiSVUN9szuSKZ+aydssOjqxcjolXp1K/WoWwy5Ik/chQSpIkSVKJs3zDNnqNmsN3GVk0rF6BCQNTqVO5XNhlSZJ+xlBKkiRJUomydF0GvUfPZXNmNsfXqsjzA1OpWals2GVJknZjKCVJkiSpxFi0Zgt9x8wjfccumh6ZzPirUqlaITHssiRJe2EoJUmSJKlEmLfye64a9zHbsnJoeVRlxvZvS0q5MmGXJUnaB0MpSZIkSTHvva83cvX4+ezclUf7o6sxqm9rKiT53x1JKs78lJYkSZIU095e+h2/m/AJ2bl5nNmoBk9d2YqyZeLDLkuS9Aviwi6g1Nm1E1bMgiAIuxJJkiQp5v3703UMen4B2bl5nNOkFk/3NpCSpFhhKFXUPnsZxv8GnkiFec9A1rawK5IkSZJi0j8XfMtNkxaSkxdwYfM6PHFFS5ISDKQkKVYYShW1HT9AmQqw6UuYdgs8fCK8cSts/m/YlUmSJEkx4/k533DLS4vJC6Bnm3o83KM5CfH+90aSYomf2kXtlBvgD8vg3L9B1WMgKwPmjoDHWsLzF8NXb0FeXthVSpIkScXWqPdWcOfUzwDod0oD/nrRScTHRUKuSpJ0oJzoPAxlU6DdIGh7Dfz3HZg3Er5+C5a/HV2qNIS2V0PzXlCuctjVSpIkScVCEAQ8/s5yHprxFQDXnXkMfzynEZGIgZQkxSLPlApTXBwc1wl6vQg3LoB210NSCvywEqbfDg83hn/fDBuWhV2pJEmSFKogCHhg+pf5gdQfOh9vICVJMc5Qqriodgyc+9fopX0XPAI1ToRdmTB/DDzZDsZdAMv+Bbk5YVcqSZIkFam8vIB7/rWUETOj87Deef6J3Hj2cQZSkhTjvHyvuEmsAK2vglb9YdX7MO9p+OJ1WPVedEmpF32+ZV+oUC3saiVJkqTDKjcv4I4pS3jh4zUA3Ne9Kb3b1Q+5KknSoWAoVVxFItCwQ3TZsiZ6xtSCcZC+Bv5zD8y8H066NDr3VJ3mYVcrSZIkHXK7cvO45aXFvLpoHXEReOCSZlzSqm7YZUmSDhEv34sFletBp7thyDK48Emo3Qxys2DR8zDyDBjdBZb8E3Kyw65UkiRJOiSycnK5YeInvLpoHQlxER67vKWBlCSVMJ4pFUvKlIUWvaD5FfDtxzD3aVg6FdbMjS4Vj4DW/aOX/lWqFXa1kiRJ0kHZuSuXa59bwKyvNpIYH8eTvVrSqbHjW0kqaTxTKhZFIlCvLVwyGm7+HM64FSrWgm3rYeYweKQJ/HMArJkHQRB2tZIkSVKhZWbl0H/sx8z6aiNly8Qxul9rAylJKqEMpWJdpSOg420w+DO4eDTUbQt5u+Czf8LozjDyTFg0EXbtDLtSSZIkab/Sd+yi9+i5fLRiMxWTEhh/VSodjqsRdlmSpMPEUKqkSEiEky6BgTPgmpnQvBfEJ0HaIph6HTzSGN6+B9K/DbtSSZIkaQ/fZ2bTa9QcPlm9heSyCTw/MJW2DauGXZYk6TAylCqJ6rSA7k/CkKVw9t2QXBe2b4b3H4ZHT4bJvWHle17aJ0mSpGJhw9ad9Bz5EZ+tzaBahUReuKY9zetVDrssSdJhZihVklWoDh2GwO8XQ4/noEEHCHJh2Wvw7AUw4lSYPxayM8OuVJIkSaXUui07uOzpOXz13TZqJScx+dp2NK6THHZZkqQiYChVGsQnQOPfQL9/w3UfRe/OV6Y8bPgc/j0YHj4Rpt8B368Mu1JJkiSVIqs3b+fSpz5i5aZMjqxcjhevbc+xNSuFXZYkqYgYSpU2tRpDt0ejl/ad81eo0hB2psNHj8M/WsCEHrD8bcjLC7tSSZIklWDLN2zj0qc/ZO2WHTSoVp4XB7WnfrUKYZclSSpChlKlVbkq0P56uPETuOJFOOZsIICvp8PzF8MTbWDOU7AzI+xKJUmSVMIsXZfBZU9/xHcZWRxfqyIvXtueIyuXC7ssSVIRM5Qq7eLi4PhzoPcrcMMCSB0EiZVg83J48/+il/a9fgts/CrsSiVJklQCLFqzhcufmcPmzGyaHpnMC9e0p2Zy2bDLkiSFwFBK/1P9WOj6N/jDMjjvQajeCLK3wcfPRM+cGt8dvpgGeblhVypJkqQYNG/l91w5ai7pO3bR8qjKTBjYjqoVEsMuS5IUkoSwC1AxlFQJ2l4NbQbCipkw7xn4chqseDe6VK4ffa7FlVC+atjVSpIkKQa8//UmBo7/mJ278mh3dFVG921DhST/OyJJpZlnSmnfIhE4piNcPhF+vxhOuQnKVoYt38CMu+DhxvDajbD+s7ArlSRJUjH2n2XfcdWz0UDqjONrMK5/WwMpSZKhlAqpSn3och8MWQa/eQxqnQQ5O+CT8fDUqTCmK3w+BXJ3hV2pJEklzpNPPknDhg0pW7YsrVq14r333ttn21deeYXOnTtTo0YNkpOTad++PdOnTy/Q5vPPP+fiiy+mQYMGRCIRHn300T22M3ToUCKRSIHliCOOONRdUynw+qdpXPvcArJz8jinSS1G9mlF2TLxYZclSSoGDKV0YBLLQ8s+MOg96P8GNLkIIvGw+kN4qR88ejLM+jts2xh2pZIklQiTJ09m8ODB3HHHHSxcuJAOHTrQtWtXVq9evdf2s2fPpnPnzkybNo0FCxbQsWNHunXrxsKFC/PbbN++naOPPpr7779/v0FTkyZNSEtLy1+WLFlyyPunku3lBd9y46RPyMkL+E2zOjx+RUuSEgykJElRkSAIgrCLKG4yMjJISUkhPT2d5OTksMsp/jLWwfwxsGAcZP4YRsUnQpPfQuo1cGSrUMuTJKmwiuMYIDU1lZYtWzJixIj8dSeeeCLdu3dn2LBhhdpGkyZNuOyyy/jTn/60x3MNGjRg8ODBDB48uMD6oUOHMnXqVBYtWnTQtRfH76eKzoS533DHlOg0D5e1rsdff3sS8XGRkKuSJBWFwo4BPFNKv15yHTjrTrj5c7hoZDSEys2GT1+AZ86KLosnQ05W2JVKkhRTsrOzWbBgAV26dCmwvkuXLnz44YeF2kZeXh5bt26latUDvznJ119/TZ06dWjYsCE9e/ZkxYoVB7wNlU6j3luRH0j1O6UBwwykJEl7YSilQychCZpdBle/AwPfgZN7Rs+YWrsAplwDjzSBd/4SPbNKkiT9ok2bNpGbm0utWrUKrK9Vqxbr168v1DYeeughMjMz6dGjxwHtOzU1lfHjxzN9+nSeeeYZ1q9fzymnnMLmzZv3+ZqsrCwyMjIKLCpdgiDgsf98zZ9fXwbAoDOO4e5ujYkzkJIk7YWhlA6Puq3gt09Hz57qeCdUqh29tG/2A/DoSdH5p775CLx6VJKkXxSJFPwPfRAEe6zbm0mTJjF06FAmT55MzZo1D2ifXbt25eKLL+akk06iU6dOvP766wA8++yz+3zNsGHDSElJyV/q1at3QPtUbAuCgAemf8lDM74CYEjn4/m/cxsV6mdVklQ6GUrp8KpYE874fzB4CVw6Do46BfJyonfqG3suPN0hege/XTvCrlSSpGKnevXqxMfH73FW1IYNG/Y4e2p3kydPZsCAAbz44ot06tTpV9dSoUIFTjrpJL7++ut9trnttttIT0/PX9asWfOr96vYkJcXcM+/ljJi5n8BuPP8E7np7OMMpCRJ+2UopaIRXyZ6p76r3oBB70fv4JdQDtYvgdduhIdPhLfugh++CbtSSZKKjcTERFq1asWMGTMKrJ8xYwannHLKPl83adIk+vXrx8SJEzn//PMPSS1ZWVksW7aM2rVr77NNUlISycnJBRaVfLl5AbdPWcK4D1cBcF/3pgzscHS4RUmSYkJC2AWoFDriJPjNY9DpHlj4HHw8Crashg//AR89Dsd3jd61r+EZ4F/XJEml3JAhQ+jduzetW7emffv2jBw5ktWrVzNo0CAgenbS2rVrGT9+PBANpPr06cPw4cNp165d/llW5cqVIyUlBYhOoL506dL8r9euXcuiRYuoWLEixx57LAC33HIL3bp146ijjmLDhg38+c9/JiMjg759+xb1t0DFWE5uHn94aTGvLlpHXAQeuKQZl7SqG3ZZkqQYEQkCJ/XZnbcvLmJ5ufDVdJj3NKyY+b/11RtB26uh2eWQVDG08iRJpUdxHQM8+eSTPPDAA6SlpdG0aVMeeeQRTj/9dAD69evHqlWrmDlzJgBnnnkms2bN2mMbffv2Zdy4cQCsWrWKhg0b7tHmjDPOyN9Oz549mT17Nps2baJGjRq0a9eO++67j8aNGxe67uL6/dShkZ2Tx02TFvLm5+tJiIvwaM/mXHBynbDLkiQVA4UdAxhK7YUDqBBt/BLmPQOLJ0H2tui6pGRofgW0uRqqHxtufZKkEs0xwKHl97Pk2rkrl0HPL2DmlxtJjI/jyV4t6dR4//OcSZJKj8KOAZxTSsVLjUZw/oMwZCmc+zeoegxkZcDcp+DxVvD8xfDVW5CXF3alkiRJpVJmVg79x37MzC83UrZMHKP7tTaQkiQdFEMpFU9lU6DdILhhPlz5Mhx3DhCB5W/DxEvhsZbw0ROwY0vYlUqSJJUaGTt30WfMPD5asZkKifE8278tHY6rEXZZkqQYZSil4i0uDo7tBL1ehJs+gfY3QFIK/LASpt8evWvfvwbDd0vDrlSSJKlE+yEzm17PzGXBNz+QXDaBCVe3I/XoamGXJUmKYaGGUrNnz6Zbt27UqVOHSCTC1KlT99u+X79+RCKRPZYmTZoUaPfoo4/SqFEjypUrR7169bj55pvZuXPnYeyJikTVo+Gcv8AflsEFj0DNxrBrOywYCyPaw7gLYOlrkJsTdqWSJEklyoatO+k5cg5L1qZTtUIik65pR/N6lcMuS5IU40INpTIzM2nWrBmPP/54odoPHz6ctLS0/GXNmjVUrVqVSy+9NL/NhAkTuPXWW7n77rtZtmwZo0ePZvLkydx2222HqxsqaokVoPVVcN2H0PffcGI3iMTBqvfgxd7wj+bw3sOQuTnsSiVJkmLeui076Pn0HL78bis1KyXx4rXtaFInJeyyJEklQEKYO+/atStdu3YtdPuUlBRSUv73C3Dq1Kn88MMP9O/fP3/dRx99xKmnnsoVV1wBQIMGDbj88suZN2/eoStcxUMkAg07RJcta2D+GPjkWUhfA/+5B2beDyddAm2vgTrNw65WkiQp5qzevJ3Ln5nD2i07OLJyOSZenUr9ahXCLkuSVELE9JxSo0ePplOnTtSvXz9/3WmnncaCBQvyQ6gVK1Ywbdo0zj///LDKVFGoXA863Q03L4XuI6B2c8jNgkUTYOQZMLoLLPkn5GSHXakkSVJMWL5hG5c+/SFrt+ygQbXyvDiovYGUJOmQCvVMqV8jLS2NN954g4kTJxZY37NnTzZu3Mhpp51GEATk5ORw3XXXceutt+5zW1lZWWRlZeU/zsjIOGx16zArUxaaXwHNLodvP4a5T8PSqbBmbnSpWCt66V+r/lDJWxdLkiTtzbK0DK4cNZfNmdkcV7MiEwamUjO5bNhlSZJKmJg9U2rcuHFUrlyZ7t27F1g/c+ZM/vKXv/Dkk0/yySef8Morr/Dvf/+b++67b5/bGjZsWP6lgSkpKdSrV+8wV6/DLhKBem3hktFw8+dw5m3RQGrbdzBzGDzSBP45ANbMgyAIu1pJkqRiY/GaLfQcOYfNmdk0qZPM5GvbG0hJkg6LSBAUj/+RRyIRpkyZskfItDdBEHD88cdzwQUX8MgjjxR4rkOHDrRr146///3v+euef/55rrnmGrZt20Zc3J453N7OlKpXrx7p6ekkJycffKdUvORkw7LXYN7I6FlTP6ndPDrvVNOLo2daSZJKrYyMDFJSUhwDHCJ+P2PPx6u+p//Yj9mWlUOLoyozrn9bUsqVCbssSVKMKewYICYv35s1axbLly9nwIABezy3ffv2PYKn+Ph4giBgX/lbUlISSUlJh6VWFSMJidGJz0+6BNYtioZTS/4JaYvg1d/BjLugZV9oMwBS6oZdrSRJUpF6/+tNXD1+Pjt25dLu6KqM6tuGikkx+d8FSVKMCPXyvW3btrFo0SIWLVoEwMqVK1m0aBGrV68G4LbbbqNPnz57vG706NGkpqbStGnTPZ7r1q0bI0aM4IUXXmDlypXMmDGDu+66i9/85jfEx8cf1v4ohtRpDt2fhCHL4Oy7IbkubN8M7z8Mj54Ek6+Ele95aZ8kSSoV3vniO6569mN27Mrl9ONrMLZfWwMpSdJhF+pvmvnz59OxY8f8x0OGDAGgb9++jBs3jrS0tPyA6ifp6em8/PLLDB8+fK/bvPPOO4lEItx5552sXbuWGjVq0K1bN/7yl78cvo4odlWoBh2GwCk3wVdvRCdGX/UeLPtXdKnZGNpeDSdfBonebUaSJJU805akcdOkheTkBXRpXIvHrmhBUoJ/zJUkHX7FZk6p4sT5D0q575bCx8/A4hdg1/bourIp0KJ39NK+qkeHW58k6bBxDHBo+f0s/l755FtueWkxeQF0a1aHh3s0o0x8zN4LSZJUTBR2DOBvHGl3tRrDBY9EL+07569QpSHsTIePHod/tIQJPWD525CXF3alkiRJB23C3G/4w4+BVI/WdXn0suYGUpKkIuVvHWlfylWG9tfDjZ/AFS/BsZ2AAL6eDs9fDE+0gTlPwc6MsCuVJEk6IKPeW8EdUz4jCKDfKQ24/7cnEx8XCbssSVIpYygl/ZK4ODi+C1z5MtywAFIHQWIl2Lwc3vw/ePhEeP0W2PhV2JVKkiT9osff+Zo/v74MgEFnHMPd3RoTZyAlSQqBoZR0IKofC13/Bn9YBuc9CNUbQfa26BxUT7SB8RfCF9MgLzfsSiVJkgoIgoAH3vyCB9+K/iFtSOfj+b9zGxGJGEhJksLhfV6lg5FUKXpXvjYDYeUsmDsyeve+FTOjS+Wjos+16A3lq4ZdrSRJKuWCIOCefy1l3IerALjjvBO5+nRv3iJJCpdnSkm/RiQCR58Jl0+EmxbBqb+HclVgy2qY8Sd4uDG8diOsXxJ2pZIkqZTKzQu4fcqS/EDqvgubGEhJkooFQynpUKlSHzrfCzcvhd88BrVOgpwd8Ml4eOo0GNMVPp8CubvCrlSSJJUSObl5/OHFRUyat4a4CPz9kpPp3b5B2GVJkgR4+Z506CWWh5Z9opfurZ4D856Gpa/B6g+jS6U60PoqaNUPKtYIu1pJklRCZefk8fsXFvLGZ+tJiIvwyGXN6dasTthlSZKUz1BKOlwiEajfPrpkrIP5Y2HBWNi6Dt79M8x+AJpcBG2vhbqtwq5WkiSVIDt35XLd8wt498uNJMbH8USvlnRuXCvssiRJKsDL96SikFwHzroDbv4cLhoJR7aC3Gz4dDKMOgueOQsWT4acrLArlSRJMS4zK4erxn3Mu19upGyZOEb1bW0gJUkqlgylpKKUkATNLoOr34GB78DJPSE+EdYugCnXwCNN4J0/R8+skiRJOkAZO3fRZ8w8PvzvZiokxvNs/7acfrzTBUiSiidDKSksdVvBb5+OTox+1p3RuaYyN8Lsv8OjJ8FL/eCbDyEIwq5UkiTFgB8ys+n1zFwWfPMDyWUTmHB1O1KPrhZ2WZIk7ZOhlBS2ijXg9P8Hgz+FS8dB/VMhLyd6p76xXeGpDtE7+GVvD7tSSZJUTG3YupOeI+ewZG06VSskMumadjSvVznssiRJ2i9DKam4iC8Tnfi8/zQY9H70Dn4J5eC7JfDajfBIY3jrLvjhm7ArlSRJxUha+g56Pj2HL7/bSs1KSbx4bTua1EkJuyxJkn6RoZRUHB1xEvzmMRiyFDrfB5WPgh0/wIf/gOHNYNLl8N93vbRPkqRSbvXm7Vz61Ees2JTJkZXL8eK17Tm2ZqWwy5IkqVAMpaTirHxVOPUmuGkR9JwER3cEAvhyGjzXHZ5IhXnPQNbWkAuVJElFbfmGbfR4+iO+/WEHDaqV58VB7WlQvULYZUmSVGiGUlIsiIuHE86DPlPh+o+hzdWQWBE2fQnTboGHG8Mb/webloddqSRJKgLL0jLoOfIj1mfs5LiaFXnx2vYcWblc2GVJknRADKWkWFPjeDj/QRiyDLo+ANWOhawMmPsUPN4Knr8YvpoOeXlhVypJkg6DT7/dQs+Rc9i0LZvGtZN54Zp21EwuG3ZZkiQdMEMpKVaVTYbUa6NnTl35Mhx/LhCB5W/DxB7wWEv46AnYsSXsSiVJ0iEyf9X39HpmLuk7dtG8XmUmXd2OahWTwi5LkqSDYiglxbq4ODi2E1wxGW76BNrfAGVT4IeVMP12ePhE+Ndg+G5p2JVKkqRf4YPlm+g9eh5bs3JIbViV5wemklK+TNhlSZJ00AylpJKk6tFwzl+il/Zd8CjUbAy7tsOCsTCiPYy7AJa+Brk5YVcqSZIOwDtffEf/cR+zY1cupx9fg3H921IxKSHssiRJ+lX8TSaVRIkVoHV/aNUPVr0P80bCF6/DqveiS3JdaHMVtOwHFaqFXa0kSdqPaUvSuGnSQnLyAro0rsVjV7QgKSE+7LIkSfrVPFNKKskiEWjYAS57DgZ/CqcNgfLVIONb+M+90Uv7pv4O1i0Mu1JJkrQXr3zyLTdM/IScvIBuzerwRK+WBlKSpBLDUEoqLVLqQqe74eal0H0E1G4OuVmwaAKMPBNGdYYl/4Sc7LArlSRJwMS5q/nDS4vJC6BH67o8ellzysQ7fJcklRxevieVNmXKQvMroNnl8O18mPc0fD4Vvp0XXSrWgtZXRS/9q3RE2NVKklQqjX5/Jff9O3qTkr7t63N3tybExUVCrkqSpEPLP7VIpVUkAvXawMWj4ObP4MzbooHUtu9g5jB4pCn8cwCsmQdBEHa1kiSVGo+/83V+IHXtGUcz9DcGUpKkkslQSlL0jKgzb4XBn8HFo6FeKuTtgs/+CaM7w8gzYOEE2LUz7EolSSqxgiDg79O/4MG3vgLg5k7Hc+u5JxCJGEhJkkomQylJ/5OQCCddAgPegmtmQfMrIT4J0hbDq7+LToz+9lDYsibsSiVJKlGCIODefy/liXf/C8Dt553A7zsdZyAlSSrRDKUk7V2d5tD9CRiyDM6+G5Lrwo7v4f1HYPjJMPlKWDnbS/skSfqV8vICbp/yGWM/WAXAfRc24ZrTjwm3KEmSioChlKT9q1ANOgyB3y+Gy56HBh0gyINl/4Jnu8GIU2D+GMjODLtSSZJiTk5uHn94aTGT5q0mLgJ/v+RkerdvEHZZkiQVCUMpSYUTnwAndoN+/4bfzYneoa9MediwFP59Mzx0Irx5O3y/IuxKJUmKCdk5edw4aSFTFq4lIS7C8J4tuLR1vbDLkiSpyBhKSTpwNU+ECx6JXtp3zjCo0hCy0mHOE/CPljChByx/G/Lywq5UkqRiaeeuXK59bj5vfLaexPg4RlzZim7N6oRdliRJRcpQStLBK1cZ2v8ObvwErngJju0EBPD1dHj+YniiDcx5CnZmhF2pJEnFRmZWDleN+5h3v9xI2TJxjOrbms6Na4VdliRJRc5QStKvFxcHx3eBK1+GGxZA6nWQlAybl8Ob/xe9a9/rf4CNX4ZdqSRJocrYuYs+Y+bx4X83UyExnmf7t+X042uEXZYkSaEwlJJ0aFU/FrreD0OWwnkPQvVGkL0NPh4FT7SF8RfCF69DXm7YlUqSVKR+yMym1zNzWfDNDySXTeD5gamkHl0t7LIkSQpNQtgFSCqhkipB26uhzUBYOQvmjoSv3oAVM6NL5aOiz7XoDeWrhl2tJEmH1catWVw5ai5ffreVqhUSeW5AW5rUSQm7LEmSQuWZUpIOr0gEjj4TLp8INy2CU38P5arAltUw40/RS/tevQHWLwm7UkmSDou09B1c9vRHfPndVmpWSmLyNe0MpCRJwlBKUlGqUh863xu9a99vHocjToKcnbDwOXjqNBjTFT57BXJ3hV2pJEmHxJrvt9Pj6Y9YsSmTIyuX48Vr23NcrUphlyVJUrHg5XuSil6ZctCyN7S4ElbPgXkjYdlrsPrD6FKpDrS+Clr1g4pO/ipJik3/3biNXs/MZX3GTupXK8+EganUrVI+7LIkSSo2DKUkhScSgfrto0vGOpg/FhaMha3r4N0/w+wHoMlF0PZaqNsq7GolSSq0L9ZncOWouWzals1xNSsyYWAqNZPLhl2WJEnFipfvSSoekuvAWXfAzZ/Db5+BI1tDbjZ8OhlGnQXPnAWLX4CcrLArlSRpvz79dgs9R85h07ZsGtdO5oVr2hlISZK0F4ZSkoqXhCQ4uQdc/R+4+h04uSfEJ8LaBTDlWnikCbzz5+iZVZIkFTPzV31Pr2fmsmX7LprXq8ykq9tRrWJS2GVJklQsGUpJKr6ObAW/fRpuXgpn3RmdaypzI8z+OzzSFF7sC998CEEQdqWSJPHB8k30Hj2PrVk5pDasyvMDU0kpXybssiRJKrYMpSQVfxVrwOn/DwZ/Cpc+C/VPhSAXlk6FsV3hqQ6w4FnI3h52pZKkUuqdL76j/7iP2bErlw7HVWdc/7ZUTHL6VkmS9sdQSlLsiC8DTbpD/2kw6H1o2RcSysF3S+BfN8HDJ8Jbd8EPq8KuVJJUiryxJI1rn1tAdk4enRvXYlTf1pRLjA+7LEmSij1DKUmx6YiT4Df/gCFLofN9UPko2LkFPvwHDG8Oky6H/77rpX2SpMNqysJvuX7iJ+zKDejWrA5P9mpJUoKBlCRJhWEoJSm2la8Kp94ENy2Cy1+AozsCAXw5DZ7rDk+0hXnPQNbWkAuVJJU0E+euZsiLi8kL4NJWdXn0suaUiXd4LUlSYflbU1LJEBcPjbpCn6lw/cfQ9hpIrAibvoJpt8DDjeGN/4NNy8OuVJJUAox5fyW3T1lCEECf9vX528UnEx8XCbssSZJiiqGUpJKnxvFw3t9hyDLo+gBUOxayMmDuU/B4K3jut/DVdMjLC7tSSVIMeuLd5dz776UAXHv60dzzmybEGUhJknTAvCWIpJKrbDKkXgttroYV78K8kdEw6r//iS5VGkSfa3EllKscdrWSpGIuCAIeeusrHn83etbt4E7H8fuzjyMSMZCSJOlgeKaUpJIvLg6OPRuumAw3fQLtb4CyKdG79L11R/Suff8aDN8tDbtSSVIxFQQB9/17WX4gdft5JzC40/EGUpIk/QqGUpJKl6pHwzl/iV7ad8GjULMx7NoOC8bCiPYw7gJY+hps/94790kqNp588kkaNmxI2bJladWqFe+9994+277yyit07tyZGjVqkJycTPv27Zk+fXqBNp9//jkXX3wxDRo0IBKJ8Oijj/7q/ZZkeXkBt0/5jDEfrATgvgubcM3px4RclSRJsS/UUGr27Nl069aNOnXqEIlEmDp16n7b9+vXj0gkssfSpEmT/DZnnnnmXtucf/75h7k3kmJKYgVo3R+u+xD6vQ4n/gYi8bDqPXixNzzQEP5SG/7RMhpUTRkE/7kXPh4NX74JaZ8aXEkqEpMnT2bw4MHccccdLFy4kA4dOtC1a1dWr1691/azZ8+mc+fOTJs2jQULFtCxY0e6devGwoUL89ts376do48+mvvvv58jjjjikOy3pMrJzeMPLy1m0rzVxEXggUtOpnf7BmGXJUlSiRAJgvD+R/XGG2/wwQcf0LJlSy6++GKmTJlC9+7d99k+PT2dHTt25D/OycmhWbNm3HjjjQwdOhSA77//nuzs7Pw2mzdvplmzZowaNYp+/foVqq6MjAxSUlJIT08nOTn5YLomKRalfwvzx8DiFyBjbeFek1AWkutA8pE/LnUg5WdfJ9eF8lXByzukmFAcxwCpqam0bNmSESNG5K878cQT6d69O8OGDSvUNpo0acJll13Gn/70pz2ea9CgAYMHD2bw4MGHfL/F8ft5ILJz8vj9Cwt547P1xMdFeOSy5vymWZ2wy5Ikqdgr7Bgg1InOu3btSteuXQvdPiUlhZSUlPzHU6dO5YcffqB///7566pWrVrgNS+88ALly5fn0ksv/fUFSyrZUurC2X+KLrt2wtZ1kLEO0tdGQ6qMdT/+++PXmRshZyd8vyK67EuB4Gq3f38KsMpXM7iStIfs7GwWLFjArbfeWmB9ly5d+PDDDwu1jby8PLZu3brHGOlw7zfW7dyVy+8mfMI7X2wgMT6Ox69oQZcmez+rTJIkHZyYvvve6NGj6dSpE/Xr199vm549e1KhQoUirExSzCtTNjr/VNWj991m107YmlYwrErfLbwqbHAVn1QwsMo/2+pnAVaF6gZXUimzadMmcnNzqVWrVoH1tWrVYv369YXaxkMPPURmZiY9evQ47PvNysoiKysr/3FGRkah91mcbM/O4erx8/lg+WaSEuIY2ac1ZxxfI+yyJEkqcWI2lEpLS+ONN95g4sSJ+2wzb948PvvsM0aPHr3fbZWUAZSkIlamLFRtGF32JScrGlztHlZlrIteLpixDjI3QG4W/LAyuuxLfOKelwrmn23149flq0fvNiipRNn9Dm9BEBTqrm+TJk1i6NChvPrqq9SsWfOw73fYsGHcc889B7yf4iRj5y6uGvsx87/5gQqJ8Yzu14Z2R1cLuyxJkkqkmA2lxo0bR+XKlfc7B9Xo0aNp2rQpbdu23e+2SsIASlIxlZAEVRpEl33Jyf7fpYI/D6t+HmBt2wC52fDDquiyL/GJUKl29FLE5Dr/m9fqp69T6hpcSTGkevXqxMfH73F20oYNG/Y4i2l3kydPZsCAAbz00kt06tSpSPZ72223MWTIkPzHGRkZ1KtX74D2HaYt27PpM2Yen36bTnLZBMZd1ZaWR1UJuyxJkkqsmAylgiBgzJgx9O7dm8TExL222b59Oy+88AL33nvvL24v1gdQkmJcQmIhg6u0fZ9tlbEOtn0XDa62fBNd9iWuDCTX/l9YlbLbmVfJR0KFGgZXUjGQmJhIq1atmDFjBhdddFH++hkzZnDhhRfu83WTJk3iqquuYtKkSQd1B+KD3W9SUhJJSUkHvL/iYOPWLHqPnssX67dStUIi469qS9MjU375hZIk6aDFZCg1a9Ysli9fzoABA/bZ5sUXXyQrK4srr7zyF7cXywMoSaVEQiJUqR9d9iUnG7at3zOsyvjZ11vXQ94u2LI6uuxLfnB15J6XDP4UYlWoaXAlFYEhQ4bQu3dvWrduTfv27Rk5ciSrV69m0KBBQPSPa2vXrmX8+PFANJDq06cPw4cPp127dvlnO5UrVy7/hjHZ2dksXbo0/+u1a9eyaNEiKlasyLHHHluo/ZYkaek76DVqLis2ZlKzUhITBqZyXK1KYZclSVKJF2ootW3bNpYvX57/eOXKlSxatIiqVaty1FFH7THI+sno0aNJTU2ladOm+9z26NGj6d69O9WqOQeApFIiIREqHxVd9iV3VzSYKnC21W53Fyx0cJUAler8LKj6eXj14+OKNSEu/tD3VSpFLrvsMjZv3sy9995LWloaTZs2Zdq0afk3eklLS2P16v8dq08//TQ5OTlcf/31XH/99fnr+/bty7hx4wBYt24dLVq0yH/uwQcf5MEHH+SMM85g5syZhdpvSbHm++1cMWoOa77fwZGVyzFhYCoNqnuDHEmSikIkCIIgrJ3PnDmTjh077rH+p0FTv379WLVqVf7gCCA9PZ3atWszfPhwrr766r1u96uvvqJRo0a89dZbdO7c+YDrysjIICUlhfT0dJKTkw/49ZIU03J3RS8F3D2s+vndBbethyDvl7cVlxCd46rAnQXrFgywDK5UjDgGOLSK+/dzxcZt9Bo1l7T0ndSvVp4JA1OpW6V82GVJkhTzCjsGCDWUKq6K+wBKkkKXm/O/SwV/Hlb9/AysrWmFC64i8T9Ozr6XSwV/urtgxVoGVyoSjgEOreL8/fxifQZXjprHpm1ZHFuzIhMGplIruWzYZUmSVCIUdgwQk3NKSZJCFp8QPeMppe6+2+TmRM+42n1eq5/Pd7U1DYLcH5//dt/b+im4+vldBHe/u2DFWtG6JOkXfPrtFvqMmceW7btoXDuZ5wa0pVpF5xeVJKmoOXqXJB0e8QnRs5xSjgTa7L1Nbg5kbtgtrNptvqsDCq6O2PfE7Ml1oOIRBldSKTd/1ff0H/sxW7NyaF6vMs/2b0tK+TJhlyVJUqnkyFySFJ74hP+d8VS39d7b5OXCtg27hVU/v7vgj8FVXs7/2vDx3rcViYsGU7uHVT+FWClHGlxJJdiHyzcx4Nn57NiVS9uGVRnTrw0VkzzeJUkKi7+FJUnFW1w8JNeOLuwnuMrc+LPJ2Xe/u+A62LouGlxt/fHrtfP3vq1IXPRSwN3ntfp5eFXpCIj3zAoplrz7xQaufX4B2Tl5dDiuOiN7t6ZconPVSZIUJkMpSVLsi/vx0r1KRwCt9t4mL+/HSwV/HlbtfofBNMjbFT3zamsarN3XDiPR4Co/rKq753xXlWobXEnFxBtL0rjphYXsyg3odGItnujVgqQEAylJksJmKCVJKh3i4v4XXB25v+Bq455hVYG7C66LBlfb1keXtQv2scMfg6s9Jmf/2WWDlWpDQuJh67IkmLpwLX94aTG5eQEXnFybRy5rTpn4uLDLkiRJGEpJkvQ/cXFQqVZ0ObLl3tvk5cH2TbuFVbvdXXBrGuRm/y+4WvfJPnYYgYo19zI5+88CLIMr6aBNmrea26csIQjgklZ1+dvFJxMfFwm7LEmS9CNDKUmSDkRcXDRIqlgT6rTYe5u8PNi+ec+wKn9y9h+/zs2Gbd9Fl3UL973PCjX3PjH7TxO2V6oNCd7OXvq5Me+v5N5/LwWgT/v6DO3WhDgDKUmSihVDKUmSDrW4OKhYI7rsK7gKAsjctNucVrvPd7UOcrOic2FlbviF4KpGwbsI7h5eJdcxuFKp8cS7y/n79C8BuPb0o7m16wlEIgZSkiQVN4ZSkiSFIRL5WXDVfO9tguDHM67W7na21W5zXOXsjM6FlbkR0hbte58VauwlrPpZiFWpDpQpezh6KxWJIAh46K2vePzd5QAM7nQcvz/7OAMpSZKKKUMpSZKKq0gEKlSPLrWb7b1NEMD27392ptVezrbKWLtbcLV43/ssX323ea12u7tg8pEGVyqWgiDgvn8vY8wHKwG4resJXHvGMSFXJUmS9sdQSpKkWBaJQIVq0aX2yXtvEwSw44fdzrTay90Fc3ZEJ3HfvgnWf7rvfZavtue8VgXmu6oDZcodnv5Ke5GXF3Dnq58xce5qAO69sAl92jcItyhJkvSLDKUkSSrpIhEoXzW6/FJwtbew6qeJ2dPX/hhcbY4u+wuuylXd++TsP62rVBsSyx+e/qpUycnN44///JRXFq4lEoG//fZkerSpF3ZZkiSpEAylJElSweDqiJP23iY/uNrtLoK7z3e1azvs+D66rF+y732Wq7rb2VY/n+/qx8cGV9qP7Jw8Bk9eyLQl64mPi/Bwj2Zc2PzIsMuSJEmFZCglSZIKp0Bw1XTvbYIAdm7Z+7xWP5/valfm/4Kr7/YXXFXZ+8TsVRpA/VMORy8VI3buyuV3Ez7hnS82kBgfx2NXtOCcJkeEXZYkSToAhlKSJOnQiUSiQVK5KlCryd7bBAHsTC8YVqWv3fPxrszomVk7foDvPiu4jZpN4HcfHv7+qNj6w4uLeeeLDSQlxDGyT2vOOL5G2CVJkqQDZCglSZKKViQC5SpHl1qN994mCCArY8+w6qezrSrXL8qKVQwN7NCQ+d98z/CeLWh3dLWwy5EkSQfBUEqSJBU/kQiUTYku+wquVKq1OKoKs/5fR8qWiQ+7FEmSdJDiwi5AkiRJOhgGUpIkxTZDKUmSJEmSJBU5QylJkiRJkiQVOUMpSZIkSZIkFTlDKUmSJEmSJBU5QylJkiRJkiQVOUMpSZIkSZIkFTlDKUmSJEmSJBU5QylJkiRJkiQVOUMpSZIkSZIkFTlDKUmSJEmSJBU5QylJkiRJkiQVOUMpSZIkSZIkFTlDKUmSJEmSJBU5QylJkiRJkiQVOUMpSZIkSZIkFTlDKUmSJEmSJBU5QylJkiRJkiQVOUMpSZIkSZIkFTlDKUmSJEmSJBW5hLALKI6CIAAgIyMj5EokSVJR+ul3/09jAf06jqkkSSqdCjumMpTai61btwJQr169kCuRJElh2Lp1KykpKWGXEfMcU0mSVLr90pgqEvinwD3k5eWxbt06KlWqRCQSOeTbz8jIoF69eqxZs4bk5ORDvv3iwn6WLKWln1B6+mo/S5bS0k84vH0NgoCtW7dSp04d4uKc5eDXckx1aNjPkqW09BNKT1/tZ8lSWvoJxWNM5ZlSexEXF0fdunUP+36Sk5NL/A852M+SprT0E0pPX+1nyVJa+gmHr6+eIXXoOKY6tOxnyVJa+gmlp6/2s2QpLf2EcMdU/glQkiRJkiRJRc5QSpIkSZIkSUXOUCoESUlJ3H333SQlJYVdymFlP0uW0tJPKD19tZ8lS2npJ5Suvmr/SsvPgv0sWUpLP6H09NV+liylpZ9QPPrqROeSJEmSJEkqcp4pJUmSJEmSpCJnKCVJkiRJkqQiZyglSZIkSZKkImco9SvNnj2bbt26UadOHSKRCFOnTv3F18yaNYtWrVpRtmxZjj76aJ566qk92rz88ss0btyYpKQkGjduzJQpUw5D9YV3oP185ZVX6Ny5MzVq1CA5OZn27dszffr0Am3GjRtHJBLZY9m5c+dh7Mn+HWg/Z86cudc+fPHFFwXaxfr72a9fv732s0mTJvltiuP7OWzYMNq0aUOlSpWoWbMm3bt358svv/zF18XaMXow/YzVY/Rg+hqLx+nB9DMWj9MRI0Zw8sknk5ycnP9z+MYbb+z3NbF2fKrwHFPtXax+Xjum2rtY/KwGx1T7E6vHqGOqfYvF4zSWx1SGUr9SZmYmzZo14/HHHy9U+5UrV3LeeefRoUMHFi5cyO23385NN93Eyy+/nN/mo48+4rLLLqN3794sXryY3r1706NHD+bOnXu4uvGLDrSfs2fPpnPnzkybNo0FCxbQsWNHunXrxsKFCwu0S05OJi0trcBStmzZw9GFQjnQfv7kyy+/LNCH4447Lv+5kvB+Dh8+vED/1qxZQ9WqVbn00ksLtCtu7+esWbO4/vrrmTNnDjNmzCAnJ4cuXbqQmZm5z9fE4jF6MP2M1WP0YPr6k1g6Tg+mn7F4nNatW5f777+f+fPnM3/+fM466ywuvPBCPv/88722j8XjU4XnmGrvYvXz2jHV3sXiZzU4pnJMVVAsHaeOqWJgTBXokAGCKVOm7LfNH//4x+CEE04osO7aa68N2rVrl/+4R48ewbnnnlugzTnnnBP07NnzkNX6axSmn3vTuHHj4J577sl/PHbs2CAlJeXQFXaIFaaf7777bgAEP/zwwz7blMT3c8qUKUEkEglWrVqVv664v59BEAQbNmwIgGDWrFn7bFMSjtHC9HNvYu0YDYLC9bUkHKcH857G6nFapUqVYNSoUXt9riQcnyocx1T7F2uf146p9i1WP6sdU+1frB2jQeCYan9i9TiNlTGVZ0oVsY8++oguXboUWHfOOecwf/58du3atd82H374YZHVeajl5eWxdetWqlatWmD9tm3bqF+/PnXr1uWCCy7Y4y8KsaJFixbUrl2bs88+m3fffbfAcyXx/Rw9ejSdOnWifv36BdYX9/czPT0dYI+fw58rCcdoYfq5u1g9Rg+kr7F8nB7Mexprx2lubi4vvPACmZmZtG/ffq9tSsLxqUOntP48xOrndWHF8mf1wYi1z+qfOKbat1g9Rh1T7VusHaexNqYylCpi69evp1atWgXW1apVi5ycHDZt2rTfNuvXry+yOg+1hx56iMzMTHr06JG/7oQTTmDcuHG89tprTJo0ibJly3Lqqafy9ddfh1jpgalduzYjR47k5Zdf5pVXXqFRo0acffbZzJ49O79NSXs/09LSeOONNxg4cGCB9cX9/QyCgCFDhnDaaafRtGnTfbaL9WO0sP3cXSweo4Xta6wfpwfznsbScbpkyRIqVqxIUlISgwYNYsqUKTRu3HivbWP9+NShVVp/HmLx87owYv2z+mDE0mf1zzmm2r9YPEYdU+1bLB2nsTqmSjikW1OhRCKRAo+DINhj/d7a7L4uVkyaNImhQ4fy6quvUrNmzfz17dq1o127dvmPTz31VFq2bMljjz3GP/7xjzBKPWCNGjWiUaNG+Y/bt2/PmjVrePDBBzn99NPz15ek93PcuHFUrlyZ7t27F1hf3N/PG264gU8//ZT333//F9vG8jF6IP38Saweo4Xta6wfpwfznsbScdqoUSMWLVrEli1bePnll+nbty+zZs3a5yAqlo9PHXql7echVj+vCyPWP6sPRix9Vv+cY6p9i9Vj1DHVvsXScRqrYyrPlCpiRxxxxB7J4oYNG0hISKBatWr7bbN7ShkLJk+ezIABA3jxxRfp1KnTftvGxcXRpk2bYvMXg4PVrl27An0oSe9nEASMGTOG3r17k5iYuN+2xen9vPHGG3nttdd49913qVu37n7bxvIxeiD9/EmsHqMH09efi5Xj9GD6GWvHaWJiIsceeyytW7dm2LBhNGvWjOHDh++1bSwfnzr0StvPQ6x+Xv8asfJZfTBi7bP6J46p9i1Wj1HHVPsWa8dprI6pDKWKWPv27ZkxY0aBdW+99RatW7emTJky+21zyimnFFmdh8KkSZPo168fEydO5Pzzz//F9kEQsGjRImrXrl0E1R0+CxcuLNCHkvJ+QvTuFcuXL2fAgAG/2LY4vJ9BEHDDDTfwyiuv8M4779CwYcNffE0sHqMH00+IzWP0YPu6u+J+nP6afsbacbq7IAjIysra63OxeHzq8ClNPw+x+Hl9KBT3z+pfI9Y+qx1T7V8sHqOOqX5ZrB2nu4uZMdUhnTa9FNq6dWuwcOHCYOHChQEQPPzww8HChQuDb775JgiCILj11luD3r1757dfsWJFUL58+eDmm28Oli5dGowePTooU6ZM8M9//jO/zQcffBDEx8cH999/f7Bs2bLg/vvvDxISEoI5c+YUef9+cqD9nDhxYpCQkBA88cQTQVpaWv6yZcuW/DZDhw4N3nzzzeC///1vsHDhwqB///5BQkJCMHfu3CLv308OtJ+PPPJIMGXKlOCrr74KPvvss+DWW28NgODll1/Ob1MS3s+fXHnllUFqaupet1kc38/rrrsuSElJCWbOnFng53D79u35bUrCMXow/YzVY/Rg+hqLx+nB9PMnsXSc3nbbbcHs2bODlStXBp9++mlw++23B3FxccFbb70VBEHJOD5VeI6pHFPF2md1EDimckwVu8eoYyrHVMXl+DSU+pV+ui3m7kvfvn2DIAiCvn37BmeccUaB18ycOTNo0aJFkJiYGDRo0CAYMWLEHtt96aWXgkaNGgVlypQJTjjhhAIHehgOtJ9nnHHGftsHQRAMHjw4OOqoo4LExMSgRo0aQZcuXYIPP/ywaDu2mwPt59/+9rfgmGOOCcqWLRtUqVIlOO2004LXX399j+3G+vsZBEGwZcuWoFy5csHIkSP3us3i+H7urY9AMHbs2Pw2JeEYPZh+xuoxejB9jcXj9GB/dmPtOL3qqquC+vXr59dz9tln5w+egqBkHJ8qPMdUfYMgKDmf146p+gZBUDI+q4PAMZVjqqhYPE4dU0UV5+MzEgQ/zmYlSZIkSZIkFRHnlJIkSZIkSVKRM5SSJEmSJElSkTOUkiRJkiRJUpEzlJIkSZIkSVKRM5SSJEmSJElSkTOUkiRJkiRJUpEzlJIkSZIkSVKRM5SSJEmSJElSkTOUkqRDJBKJMHXq1LDLkCRJimmOqaTSw1BKUonQr18/IpHIHsu5554bdmmSJEkxwzGVpKKUEHYBknSonHvuuYwdO7bAuqSkpJCqkSRJik2OqSQVFc+UklRiJCUlccQRRxRYqlSpAkRPAx8xYgRdu3alXLlyNGzYkJdeeqnA65csWcJZZ51FuXLlqFatGtdccw3btm0r0GbMmDE0adKEpKQkateuzQ033FDg+U2bNnHRRRdRvnx5jjvuOF577bXD22lJkqRDzDGVpKJiKCWp1Ljrrru4+OKLWbx4MVdeeSWXX345y5YtA2D79u2ce+65VKlShY8//piXXnqJt99+u8AAacSIEVx//fVcc801LFmyhNdee41jjz22wD7uueceevTowaeffsp5551Hr169+P7774u0n5IkSYeTYypJh0wgSSVA3759g/j4+KBChQoFlnvvvTcIgiAAgkGDBhV4TWpqanDdddcFQRAEI0eODKpUqRJs27Yt//nXX389iIuLC9avXx8EQRDUqVMnuOOOO/ZZAxDceeed+Y+3bdsWRCKR4I033jhk/ZQkSTqcHFNJKkrOKSWpxOjYsSMjRowosK5q1ar5X7dv377Ac+3bt2fRokUALFu2jGbNmlGhQoX850899VTy8vL48ssviUQirFu3jrPPPnu/NZx88sn5X1eoUIFKlSqxYcOGg+2SJElSkXNMJamoGEpJKjEqVKiwx6nfvyQSiQAQBEH+13trU65cuUJtr0yZMnu8Ni8v74BqkiRJCpNjKklFxTmlJJUac+bM2ePxCSecAEDjxo1ZtGgRmZmZ+c9/8MEHxMXFcfzxx1OpUiUaNGjAf/7znyKtWZIkqbhxTCXpUPFMKUklRlZWFuvXry+wLiEhgerVqwPw0ksv0bp1a0477TQmTJjAvHnzGD16NAC9evXi7rvvpm/fvgwdOpSNGzdy44030rt3b2rVqgXA0KFDGTRoEDVr1qRr165s3bqVDz74gBtvvLFoOypJknQYOaaSVFQMpSSVGG+++Sa1a9cusK5Ro0Z88cUXQPQuLi+88AK/+93vOOKII5gwYQKNGzcGoHz58kyfPp3f//73tGnThvLly3PxxRfz8MMP52+rb9++7Ny5k0ceeYRbbrmF6tWrc8kllxRdByVJkoqAYypJRSUSBEEQdhGSdLhFIhGmTJlC9+7dwy5FkiQpZjmmknQoOaeUJEmSJEmSipyhlCRJkiRJkoqcl+9JkiRJkiSpyHmmlCRJkiRJkoqcoZQkSZIkSZKKnKGUJEmSJEmSipyhlCRJkiRJkoqcoZQkSZIkSZKKnKGUJEmSJEmSipyhlCRJkiRJkoqcoZQkSZIkSZKKnKGUJEmSJEmSitz/BweiP+kcw7tkAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation F1: 0.2389\n"
     ]
    }
   ],
   "source": [
    "num_labels_2 = 6\n",
    "\n",
    "# Move model2 to device (GPU if available)\n",
    "device2 = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Set up configuration and add pad token ID\n",
    "\n",
    "configuration2 = GPT2Config.from_pretrained(\"openai-community/gpt2-large\")\n",
    "configuration2.pad_token_id = configuration2.eos_token_id  # Use eos_token_id as the pad token\n",
    "configuration2.num_labels = num_labels_2  # Update the number of labels\n",
    "\n",
    "# Load tokenizer and set pad token\n",
    "tokenizer2 = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2-large\")\n",
    "tokenizer2.pad_token = tokenizer2.eos_token  # Set pad token to eos token\n",
    "\n",
    "# Load model with configuration\n",
    "model2 = GPT2ForSequenceClassification.from_pretrained(\n",
    "    \"openai-community/gpt2-large\", \n",
    "    config=configuration2, \n",
    "    ignore_mismatched_sizes=True\n",
    ").to(device2)\n",
    "\n",
    "# Freeze GPT-2 transformer layers\n",
    "for param in model2.transformer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    # Concatenate the input columns for each example in the batch\n",
    "    combined_text = [\n",
    "        p + \" \" + e + \" \" + t for p, e, t in zip(examples[\"prompt\"], examples[\"essay\"], examples[\"text\"])\n",
    "    ]\n",
    "    # Tokenize the concatenated text\n",
    "    return tokenizer2(combined_text, padding=\"max_length\", truncation=True, max_length=1024)\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_datasets2 = dataset2.map(tokenize_function, batched=True)\n",
    "tokenized_datasets2 = tokenized_datasets2.remove_columns([\"prompt\", \"essay\", \"text\"])\n",
    "tokenized_datasets2 = tokenized_datasets2.rename_column(\"score\", \"labels\")\n",
    "tokenized_datasets2.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Get the labels from the tokenized dataset\n",
    "labels2 = tokenized_datasets2[\"labels\"]\n",
    "\n",
    "# Get the unique labels\n",
    "unique_labels2 = np.unique(labels2)\n",
    "\n",
    "# Store the indices for each label\n",
    "label_to_indices2 = {label: np.where(labels2 == label)[0] for label in unique_labels2}\n",
    "\n",
    "# Lists to hold the train and validation indices\n",
    "train_indices2 = []\n",
    "val_indices2 = []\n",
    "\n",
    "# For each label, split the indices into train and validation\n",
    "for label, indices in label_to_indices2.items():\n",
    "    # Shuffle the indices within each label to ensure random splitting\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Split 80% for training, 20% for validation\n",
    "    split_idx2 = int(0.8 * len(indices))\n",
    "    train_indices2.extend(indices[:split_idx2])\n",
    "    val_indices2.extend(indices[split_idx2:])\n",
    "\n",
    "# Convert indices to tensors\n",
    "train_indices2 = torch.tensor(train_indices2)\n",
    "val_indices2 = torch.tensor(val_indices2)\n",
    "\n",
    "# Create Subsets for train and validation datasets\n",
    "train_dataset2 = Subset(tokenized_datasets2, train_indices2)\n",
    "eval_dataset2 = Subset(tokenized_datasets2, val_indices2)\n",
    "\n",
    "# Dataloaders\n",
    "train_dataloader2 = DataLoader(train_dataset2, shuffle=True, batch_size=8)\n",
    "eval_dataloader2 = DataLoader(eval_dataset2, batch_size=8)\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "# optimizer2 = AdamW(model2.parameters(), lr=1e-5)\n",
    "\n",
    "# Ensure only the classification head is trainable\n",
    "optimizer2 = AdamW(filter(lambda p: p.requires_grad, model2.parameters()), lr=1e-5)\n",
    "\n",
    "num_epochs2 = 3\n",
    "num_training_steps2 = num_epochs2 * len(train_dataloader2)\n",
    "lr_scheduler2 = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer2, num_warmup_steps=0, num_training_steps=num_training_steps2\n",
    ")\n",
    "\n",
    "# Initialize lists to track training/validation losses and accuracies\n",
    "train_losses2 = []\n",
    "val_losses2 = []\n",
    "val_f1_scores2 = []\n",
    "\n",
    "# Training loop\n",
    "progress_bar2 = tqdm(range(num_training_steps2))\n",
    "\n",
    "# Initialize F1 score metric (weighted-averaged for multi-class classification)\n",
    "f1_metric2 = F1Score(task=\"multiclass\", num_classes=num_labels_2, average=\"weighted\").to(device2)\n",
    "\n",
    "for epoch in range(num_epochs2):\n",
    "    epoch_train_loss = 0\n",
    "    epoch_val_loss = 0\n",
    "    f1_metric2.reset()\n",
    "    model2.train()\n",
    "\n",
    "    for batch in train_dataloader2:\n",
    "        batch = {k: v.to(device2) for k, v in batch.items()}\n",
    "        outputs = model2(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        lr_scheduler2.step()\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "        progress_bar2.update(1)\n",
    "\n",
    "    # Record training loss for the epoch\n",
    "    train_losses2.append(epoch_train_loss / len(train_dataloader2))\n",
    "\n",
    "    # Evaluate the model2\n",
    "    model2.eval()\n",
    "    for batch in eval_dataloader2:\n",
    "        batch = {k: v.to(device2) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model2(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        loss = F.cross_entropy(logits, batch[\"labels\"])\n",
    "\n",
    "        epoch_val_loss += loss.item()\n",
    "        f1_metric2(predictions, batch[\"labels\"])  # Update F1 metric with predictions\n",
    "\n",
    "    # Record validation loss and accuracy\n",
    "    val_losses2.append(epoch_val_loss / len(eval_dataloader2))\n",
    "    val_f12 = f1_metric2.compute().item()\n",
    "    val_f1_scores2.append(val_f12)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs2}: train loss {train_losses2[-1]:.4f}, val loss {val_losses2[-1]:.4f}, val accuracy {val_f1_scores2[-1]:.4f}\")\n",
    "\n",
    "# Plotting function\n",
    "def eval_plot(train_losses, val_losses, val_f1_scores):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    # Validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, val_f1_scores, label=\"Validation F1\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.title('Validation F1')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot train loss, validation loss, validation accuracy\n",
    "eval_plot(train_losses2, val_losses2, val_f1_scores2)\n",
    "\n",
    "# Print final validation accuracy\n",
    "print(f\"Final validation F1: {val_f1_scores2[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPT2ForSequenceClassification' object has no attribute 'classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Save optimizer and scheduler if needed\u001b[39;00m\n\u001b[0;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer2\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscheduler_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: lr_scheduler2\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[0;32m      7\u001b[0m }, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./saved_models/training_state.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./saved_model/classifier_head.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\26597\\miniconda3\\envs\\ece1786\\lib\\site-packages\\torch\\nn\\modules\\module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GPT2ForSequenceClassification' object has no attribute 'classifier'"
     ]
    }
   ],
   "source": [
    "torch.save(model2.state_dict(), \"./saved_models/gpt2_large_3epoch_weights_new.pt\")\n",
    "\n",
    "# Save optimizer and scheduler if needed\n",
    "torch.save({\n",
    "    'optimizer_state_dict': optimizer2.state_dict(),\n",
    "    'scheduler_state_dict': lr_scheduler2.state_dict()\n",
    "}, \"./saved_models/training_state.pt\")\n",
    "\n",
    "torch.save(model2.classifier.state_dict(), \"./saved_model/classifier_head.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor([0, 1, 2, 2, 0, 0, 2, 5], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  464,  3707,   286,  ..., 50256, 50256, 50256],\n",
      "        [ 4366, 11390,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 5, 1, 1, 1, 2, 4, 1], device='cuda:0'), 'input_ids': tensor([[  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [11246,  2678,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 9492, 33571,  1296,  ..., 50256, 50256, 50256],\n",
      "        [  818,  1909,   338,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 3, 3, 0, 5, 3, 5, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 3152,   262,  3957,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,  4736,   290,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 3, 1, 3, 2, 5, 2, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 8888,    11,   661,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [15354,   393,   407,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [25714,   362,    25,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 1, 2, 2, 3, 3, 1, 0], device='cuda:0'), 'input_ids': tensor([[ 7085,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   779,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  259,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 5, 3, 2, 0, 4, 5, 4], device='cuda:0'), 'input_ids': tensor([[  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 1026,   318,  4143,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 5167,   290,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 4, 2, 5, 0, 1, 3, 4], device='cuda:0'), 'input_ids': tensor([[ 3152,   262,  3957,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [47213,  2465,   318,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 4, 2, 0, 2, 0, 0, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1624,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 5, 1, 3, 4, 0, 5, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [  464,  2620,   287,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   779,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,    11,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 4, 1, 3, 5, 3, 0, 3], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  2444,  1064,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 3, 3, 0, 5, 0, 1, 1], device='cuda:0'), 'input_ids': tensor([[  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   661,  5409,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 1639,   815,  4341,  ..., 50256, 50256, 50256],\n",
      "        [ 3198,   286,   262,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 5, 2, 2, 1, 1, 0, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [45833,   905,   326,  ..., 50256, 50256, 50256],\n",
      "        [17197,  1064,   340,  ..., 50256, 50256, 50256],\n",
      "        [41183,   329,  1862,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 4, 0, 1, 5, 1, 1, 0], device='cuda:0'), 'input_ids': tensor([[  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1064,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 0, 5, 5, 2, 3, 3, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        [  818,  2274,   812,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2284,  ..., 50256, 50256, 50256],\n",
      "        [26788,  4438,   329,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 5, 3, 1, 5, 3, 5, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,  1524,   443,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 9444, 31260,   389,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,  1524,   443,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 4, 1, 5, 0, 3, 4, 4], device='cuda:0'), 'input_ids': tensor([[  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   661,  3066,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [ 4366, 11155,  2897,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 5, 1, 1, 2, 1, 5, 3], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  464, 18772,   286,  ..., 50256, 50256, 50256],\n",
      "        [ 8061,   892,   326,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [26829,  1064,   340,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  3354,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  7267,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 4, 5, 3, 0, 5, 0, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [  818,  4736,   290,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,  2678,    11,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   661,  3066,  ..., 50256, 50256, 50256],\n",
      "        [15202,  1535,   318,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 3, 0, 3, 0, 4, 4, 2], device='cuda:0'), 'input_ids': tensor([[26807,   278,  4037,  ..., 50256, 50256, 50256],\n",
      "        [ 8061, 26760, 12444,  ..., 50256, 50256, 50256],\n",
      "        [ 6109,  1110,    11,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  2678,   517,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 1, 4, 3, 1, 5, 5, 2], device='cuda:0'), 'input_ids': tensor([[ 6109,  1110,    11,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [10049,  1230,  2223,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 3, 1, 5, 4, 0, 1, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   892,   326,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   661,  3066,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 1, 5, 1, 3, 4, 4, 1], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  464, 18772,   286,  ..., 50256, 50256, 50256],\n",
      "        [  818,  2274,   812,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  4736,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 3, 0, 4, 5, 4, 3, 2], device='cuda:0'), 'input_ids': tensor([[  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [ 9444, 31260,   389,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 5, 4, 2, 1, 4, 4, 1], device='cuda:0'), 'input_ids': tensor([[ 5167,   290,   517,  ..., 50256, 50256, 50256],\n",
      "        [10049,  1230,  2223,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [14214,   303,   893,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 0, 3, 4, 2, 5, 0, 2], device='cuda:0'), 'input_ids': tensor([[ 8061,   892,   326,  ..., 50256, 50256, 50256],\n",
      "        [15354,   393,   407,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [   45,   602,   815,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [45833,   905,   326,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 0, 2, 1, 1, 5, 0, 3], device='cuda:0'), 'input_ids': tensor([[ 7085,  2444,  1064,  ..., 50256, 50256, 50256],\n",
      "        [ 9444, 31260,   389,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 1, 0, 5, 0, 3, 0, 2], device='cuda:0'), 'input_ids': tensor([[   45,   602,   815,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  1180,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 0, 3, 3, 2, 0, 5, 4], device='cuda:0'), 'input_ids': tensor([[20490,  4568,   423,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  2678,   423,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  464,  3707,   286,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 4, 4, 2, 1, 3, 4, 5], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,  2274,   812,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 3791,  2777,  5656,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 3, 0, 1, 3, 2, 5, 1], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [   39, 12752, 18772,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 3844, 20544,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 1, 1, 3, 2, 4, 1, 1], device='cuda:0'), 'input_ids': tensor([[   32,  1256,   286,  ..., 50256, 50256, 50256],\n",
      "        [15354,   393,   407,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [45833,  2523,   326,  ..., 50256, 50256, 50256],\n",
      "        [  464,   691,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  4409,   743,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 5, 1, 2, 0, 1, 1, 1], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [  464,  2620,   287,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 1, 4, 1, 3, 2, 5, 1], device='cuda:0'), 'input_ids': tensor([[ 4366,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 8888,   661,   389,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 7085,  6403, 19087,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 0, 5, 2, 5, 5, 4, 1], device='cuda:0'), 'input_ids': tensor([[29193,  1560,   514,  ..., 50256, 50256, 50256],\n",
      "        [  464, 15822,  3544,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 7085,  6403, 19087,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 3, 5, 0, 5, 2, 5, 5], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   894,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   779,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,  8217,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 4, 2, 5, 4, 4, 2, 3], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 8061, 26760,  4327,  ..., 50256, 50256, 50256],\n",
      "        [26829,  1909,   423,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 1026,   318,  1593,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  2678,   517,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 1, 4, 4, 2, 2, 1, 0], device='cuda:0'), 'input_ids': tensor([[ 1639,   815,  4341,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 5, 1, 5, 1, 0, 3, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  3946,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [   39, 12752, 18772,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [15354,   393,   407,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 4, 4, 1, 0, 0, 4, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 1026,   318,  7189,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 1858,   389,  1811,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 1, 2, 5, 5, 3, 3, 1], device='cuda:0'), 'input_ids': tensor([[ 3849, 33571,  1296,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 9444, 31260,   389,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 1026,   318,  2219,  ..., 50256, 50256, 50256],\n",
      "        [ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 0, 3, 0, 2, 4, 5, 4], device='cuda:0'), 'input_ids': tensor([[26807,   278,  4037,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,   517,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [19452,  6944,   286,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 5, 3, 4, 5, 1, 3, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  464, 18772,   286,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [20917,   661,   508,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   290,   517,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 3, 1, 5, 3, 2, 0, 2], device='cuda:0'), 'input_ids': tensor([[  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 2, 5, 1, 1, 2, 0, 1], device='cuda:0'), 'input_ids': tensor([[ 3844, 20544,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [10049,  1230,  2223,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 3, 1, 3, 1, 1, 2, 0], device='cuda:0'), 'input_ids': tensor([[  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [10418,   290,  1466,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 7003,  4172,   423,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  1975,  3037,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 0, 2, 5, 3, 1, 2, 0], device='cuda:0'), 'input_ids': tensor([[  818,   617,  4736,  ..., 50256, 50256, 50256],\n",
      "        [ 1639,   815,  4341,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 4, 1, 1, 2, 0, 5, 1], device='cuda:0'), 'input_ids': tensor([[  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [15202,  1535,   318,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [10049,  1230,  2223,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 0, 1, 4, 4, 3, 4, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  6403, 19087,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 3, 1, 5, 5, 4, 3, 1], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   290,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 7085,  3946,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 1026,   318,  2219,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   661,  3066,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 2, 5, 5, 1, 2, 0, 4], device='cuda:0'), 'input_ids': tensor([[ 7085,   661,  7267,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  6154,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 5, 5, 0, 3, 5, 4, 0], device='cuda:0'), 'input_ids': tensor([[ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [14592,   389,  5033,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 5, 0, 3, 2, 5, 0, 0], device='cuda:0'), 'input_ids': tensor([[ 9444, 31260,   389,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [   50, 13649, 36388,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,    11,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 2, 0, 2, 2, 0, 1, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 2, 4, 5, 2, 1, 0, 4], device='cuda:0'), 'input_ids': tensor([[  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366, 11390,  1975,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 4, 2, 5, 0, 3, 1, 3], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 8061,   892,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 7085,  6403, 19087,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 5, 3, 5, 3, 0, 4, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 5167,   290,   517,  ..., 50256, 50256, 50256],\n",
      "        [   39, 12752, 18772,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 0, 1, 3, 5, 0, 5, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [26788,   815,   307,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 1, 0, 1, 3, 0, 3, 2], device='cuda:0'), 'input_ids': tensor([[ 1639,   815,  4341,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256],\n",
      "        [ 7085, 17112,   290,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 5167,   661,  3066,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 5, 0, 2, 3, 0, 3, 0], device='cuda:0'), 'input_ids': tensor([[ 3198,   286,   262,  ..., 50256, 50256, 50256],\n",
      "        [  464, 18772,   286,  ..., 50256, 50256, 50256],\n",
      "        [ 6943,   286,   262,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [ 7149,  1499,   815,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,   517,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 4, 3, 2, 5, 0, 3, 4], device='cuda:0'), 'input_ids': tensor([[  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [10049,  1230,  2223,  ..., 50256, 50256, 50256],\n",
      "        [  818,  2274,   812,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  4736,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        [  464,   691,   835,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 3, 2, 1, 3, 5, 4, 5], device='cuda:0'), 'input_ids': tensor([[  464,  2620,   287,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 1639,   815,  4341,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   290,   517,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 1, 3, 1, 4, 4, 1, 3], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  464,  2620,   287,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [10418,   290,  1466,  ..., 50256, 50256, 50256],\n",
      "        [13749, 12409,  5563,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 4, 2, 1, 0, 2, 1, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [47213,  2465,   318,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 0, 0, 2, 3, 4, 2, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [15354,   393,   407,  ..., 50256, 50256, 50256],\n",
      "        [  464,  2837,   286,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 8061,   892,   326,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  2678,  4341,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 2, 0, 1, 3, 2, 4, 3], device='cuda:0'), 'input_ids': tensor([[ 9444, 31260,   389,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1271,   286,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 3, 3, 4, 4, 3, 2, 5], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [   39, 12752, 28791,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 2, 1, 5, 1, 1, 0, 1], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [13470,   669,   286,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [   50, 10890, 17365,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1624,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 1, 5, 5, 5, 0, 4, 3], device='cuda:0'), 'input_ids': tensor([[26788,   815,   307,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [10418,   290,  1466,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 1, 2, 1, 1, 4, 4, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 1639,   815,  4341,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [15354,   393,   407,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,    11,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 0, 1, 3, 2, 4, 5, 2], device='cuda:0'), 'input_ids': tensor([[  464,  2620,   287,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   290,   517,  ..., 50256, 50256, 50256],\n",
      "        [26788,   815,   307,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [26316,  4438,   329,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 0, 2, 4, 1, 4, 3, 1], device='cuda:0'), 'input_ids': tensor([[ 5167,   290,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  4762,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [26788,   815,   307,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 4, 4, 3, 5, 0, 1, 1], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [29733,   364,   815,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 2, 3, 5, 4, 4, 4, 4], device='cuda:0'), 'input_ids': tensor([[ 7085, 17112,   290,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 1026,   318,  1593,  ..., 50256, 50256, 50256],\n",
      "        [  464, 18772,   286,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 2, 4, 5, 0, 1, 0, 0], device='cuda:0'), 'input_ids': tensor([[41183,   286,  1862,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   661,  3066,  ..., 50256, 50256, 50256],\n",
      "        [ 1026,   318,  1593,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,  1975,  3037,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 0, 5, 5, 0, 3, 3, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [11246,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [33874,  4876,   362,  ..., 50256, 50256, 50256],\n",
      "        [ 8061, 26760,  4327,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 2, 2, 3, 1, 4, 4, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  3946,   973,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [26829,  1064,   340,  ..., 50256, 50256, 50256],\n",
      "        [  818,  4736,   290,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   290,   517,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 0, 5, 0, 3, 2, 1, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 3, 1, 5, 3, 4, 5, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 8061, 26760,  4327,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  4736,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 5, 4, 2, 5, 1, 1, 3], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 6369, 18973,  4694,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [41183,   286,  1862,  ..., 50256, 50256, 50256],\n",
      "        [ 1639,   815,  4341,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 5, 1, 2, 2, 2, 5, 2], device='cuda:0'), 'input_ids': tensor([[  464,  7118,   286,  ..., 50256, 50256, 50256],\n",
      "        [11928,   907,   290,  ..., 50256, 50256, 50256],\n",
      "        [20917,   661,   508,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [28544,   287,   262,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  1909,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 2, 0, 1, 0, 0, 3, 2], device='cuda:0'), 'input_ids': tensor([[ 1026,   318,  1593,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 5, 5, 3, 0, 1, 1, 0], device='cuda:0'), 'input_ids': tensor([[ 9492, 33571,  1296,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1624,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [11246,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [26829,  1064,   340,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 5, 4, 5, 1, 0, 5, 0], device='cuda:0'), 'input_ids': tensor([[  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  4736,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [   45,   602,   815,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 0, 3, 3, 5, 3, 4, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,   779,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   262,  1613,  ..., 50256, 50256, 50256],\n",
      "        [ 8061,   892,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  7267,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 5, 2, 2, 1, 1, 2, 2], device='cuda:0'), 'input_ids': tensor([[  464,  2620,   287,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        [25714,   362,    25,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 1722,  5627,   318,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 5, 0, 5, 0, 3, 4, 3], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 3, 2, 1, 4, 3, 0, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 0, 2, 3, 2, 4, 5, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1624,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 4, 4, 3, 3, 0, 2, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  6403,  2444,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  4736,  ..., 50256, 50256, 50256],\n",
      "        [  464,   995,   468,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 3, 0, 0, 1, 0, 0, 2], device='cuda:0'), 'input_ids': tensor([[ 9444, 31260,   389,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  6154,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 4, 2, 2, 1, 5, 4, 1], device='cuda:0'), 'input_ids': tensor([[  464,  3707,   286,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  4380,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 4, 1, 3, 2, 3, 1, 1], device='cuda:0'), 'input_ids': tensor([[  464,  2620,   287,  ..., 50256, 50256, 50256],\n",
      "        [26829,  1064,   340,  ..., 50256, 50256, 50256],\n",
      "        [ 3198,   286,   262,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 1026,   318,  1593,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 2, 0, 2, 1, 2, 4, 3], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617, 23474,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 7149,  1499,   815,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 2, 3, 3, 4, 4, 1, 3], device='cuda:0'), 'input_ids': tensor([[  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 3791,  2777,  2136,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  4409,   743,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 0, 4, 5, 3, 2, 4, 5], device='cuda:0'), 'input_ids': tensor([[ 1169,   691,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [   51,  4366,   661,  ..., 50256, 50256, 50256],\n",
      "        [33308, 17057,   447,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 5, 5, 4, 3, 2, 3, 3], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  464,  7118,   286,  ..., 50256, 50256, 50256],\n",
      "        [  818,   262,  1613,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 3791,  2777,  5656,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  1975,   326,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 4, 3, 3, 3, 3, 2, 4], device='cuda:0'), 'input_ids': tensor([[ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,  4172,  ..., 50256, 50256, 50256],\n",
      "        [26829,  1909,   423,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 3152,   262,  5801,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,    11,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 3, 1, 5, 4, 2, 2, 5], device='cuda:0'), 'input_ids': tensor([[41183,   286,  1862,  ..., 50256, 50256, 50256],\n",
      "        [47213,  2465,   318,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  462,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [10049,  1230,  2223,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 2, 5, 4, 0, 1, 0, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [33308, 17057,   447,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [   50, 13649, 36388,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 0, 5, 0, 4, 0, 3, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1064,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,  1975,  3037,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 0, 4, 3, 0, 2, 5, 4], device='cuda:0'), 'input_ids': tensor([[26829,  1064,   340,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [13470,   669,   286,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 9444, 31260,   389,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 1, 0, 2, 2, 5, 1, 3], device='cuda:0'), 'input_ids': tensor([[ 3844, 20544,    11,  ..., 50256, 50256, 50256],\n",
      "        [ 8061, 26760,  4327,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  464,  2620,   287,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,    11,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 2, 5, 3, 0, 2, 5, 0], device='cuda:0'), 'input_ids': tensor([[  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  7267,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 5, 4, 1, 0, 1, 5, 5], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  4736,  ..., 50256, 50256, 50256],\n",
      "        [ 7149,  1499,   815,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 2, 0, 1, 5, 3, 4, 1], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1064,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [47213,  2465,   318,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 1, 5, 5, 3, 4, 3, 0], device='cuda:0'), 'input_ids': tensor([[  818,  2274,   812,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [45833,   905,   326,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 2, 1, 0, 5, 5, 0, 5], device='cuda:0'), 'input_ids': tensor([[ 4366,  1975,  3037,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [   82,   463,   444,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [10049,  1230,  2223,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 2, 1, 3, 3, 5, 1, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,  4736,   290,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   290,   517,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [21834,  3946,   973,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 2, 1, 2, 1, 2, 2, 4], device='cuda:0'), 'input_ids': tensor([[ 3844, 20544,  4172,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [28100,  1713,    25,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 6109,  1110,    11,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 4, 5, 3, 5, 4, 2, 0], device='cuda:0'), 'input_ids': tensor([[ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [  464, 18772,   286,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1624,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 5167,   290,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 1639,   815,  4341,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 3, 4, 4, 3, 3, 4, 5], device='cuda:0'), 'input_ids': tensor([[ 7085,   661,   423,  ..., 50256, 50256, 50256],\n",
      "        [21834, 11155,  4708,  ..., 50256, 50256, 50256],\n",
      "        [ 1026,   318,  1593,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 1639,   815,  4341,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,   954,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 0, 4, 5, 0, 1, 0, 1], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  7267,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   262,  1613,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  6403, 19087,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 0, 0, 0, 1, 3, 3, 3], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 9444, 31260,   389,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   894,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 3633,   617,   661,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   661,  3066,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 3, 5, 3, 2, 1, 2, 5], device='cuda:0'), 'input_ids': tensor([[  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 9444, 31260,   389,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 2, 3, 3, 5, 0, 3, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   894,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 7003,  4172,   423,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 1, 1, 5, 1, 4, 0, 1], device='cuda:0'), 'input_ids': tensor([[10049,  1230,  2223,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  6154,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  464,  2837,   286,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [28848,  4341,   257,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 5, 5, 4, 2, 5, 4, 4], device='cuda:0'), 'input_ids': tensor([[ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [10049,  1160,     4,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366, 11390,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 1, 4, 3, 4, 1, 0, 5], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 6943,   286,   262,  ..., 50256, 50256, 50256],\n",
      "        [  464,  2620,   287,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [    9,  4366,   661,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 5, 2, 1, 4, 2, 2, 3], device='cuda:0'), 'input_ids': tensor([[11246,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [20917,   661,   508,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 7085,  6403, 19087,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 3, 3, 2, 0, 0, 0, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 8061,   892,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 7085,   661,  7267,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  1524, 48872,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 1, 2, 2, 0, 0, 0, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,    11,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  464,  2620,   287,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  1909,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 3, 2, 1, 2, 1, 5, 1], device='cuda:0'), 'input_ids': tensor([[11246,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366, 11155,  2897,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [14592,   389,  5033,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 1, 4, 2, 5, 0, 3, 4], device='cuda:0'), 'input_ids': tensor([[ 1722,  5627,   318,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   892,   326,  ..., 50256, 50256, 50256],\n",
      "        [26807,   278,  3230,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [33221,    25,  2773,  ..., 50256, 50256, 50256],\n",
      "        [26829,  1064,   340,  ..., 50256, 50256, 50256],\n",
      "        [ 8061, 26760,  4327,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 0, 5, 3, 5, 3, 3, 1], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [26829,  1064,   340,  ..., 50256, 50256, 50256],\n",
      "        [ 8061, 26760,  4327,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 1026,   318,  8780,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  6403, 19087,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 1, 4, 2, 4, 1, 2, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1064,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,   542,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1624,  ..., 50256, 50256, 50256],\n",
      "        [  259,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 2, 0, 2, 4, 3, 2, 5], device='cuda:0'), 'input_ids': tensor([[ 1026,   318,  1593,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [14592,   389,  5033,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 3, 4, 2, 4, 3, 1, 2], device='cuda:0'), 'input_ids': tensor([[ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 9444, 31260,   389,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [ 4366, 11155,  2897,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 1, 0, 4, 0, 5, 4, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  464, 15822,  3544,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 1858,   389,  1811,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 0, 5, 1, 1, 3, 2, 1], device='cuda:0'), 'input_ids': tensor([[ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 5167,   290,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,  1524,  1751,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 3, 5, 1, 1, 2, 2, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [26829,  1909,   423,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 4, 2, 0, 5, 1, 5, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   661,  3066,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  6403, 19087,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 4, 5, 1, 3, 4, 5, 4], device='cuda:0'), 'input_ids': tensor([[ 7085,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  259,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 2, 4, 2, 5, 2, 0, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   779,  ..., 50256, 50256, 50256],\n",
      "        [10049,  1230,  2223,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 0, 3, 2, 3, 5, 5, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  4736,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 3, 5, 1, 1, 5, 5, 5], device='cuda:0'), 'input_ids': tensor([[  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1064,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  7267,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 5, 3, 3, 0, 4, 4, 1], device='cuda:0'), 'input_ids': tensor([[  818,   617,  4736,  ..., 50256, 50256, 50256],\n",
      "        [ 1026,   318,  1593,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,    11,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 2, 2, 1, 3, 5, 0, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 0, 1, 1, 4, 4, 4, 3], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617, 15433,  ..., 50256, 50256, 50256],\n",
      "        [  259,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 9444, 31260,   389,  ..., 50256, 50256, 50256],\n",
      "        [26807,   278,  3230,  ..., 50256, 50256, 50256],\n",
      "        [25714,   362,    25,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 1, 4, 4, 5, 1, 1, 1], device='cuda:0'), 'input_ids': tensor([[ 7085,  3640,   423,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 5, 2, 4, 2, 2, 0, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366, 11390,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [15354,   393,   407,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 1, 3, 5, 2, 1, 1, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   661,  3066,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 2, 2, 4, 4, 3, 3, 1], device='cuda:0'), 'input_ids': tensor([[ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [   18,    13,   197,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 9444, 31260,   389,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 4, 1, 2, 4, 2, 1, 4], device='cuda:0'), 'input_ids': tensor([[42969,   815,  7898,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366, 11155,  2897,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  7267,  ..., 50256, 50256, 50256],\n",
      "        [ 3791,  2777,  5656,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 4, 2, 3, 3, 0, 5, 3], device='cuda:0'), 'input_ids': tensor([[ 3844, 20544,    11,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   779,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,  4172,  ..., 50256, 50256, 50256],\n",
      "        [  464,   691,   835,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 2, 3, 2, 2, 4, 1, 0], device='cuda:0'), 'input_ids': tensor([[39945,  1296,   262,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  3354,  ..., 50256, 50256, 50256],\n",
      "        [20917,   661,   389,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 1026,   318,  7189,  ..., 50256, 50256, 50256],\n",
      "        [  818,  2274,   812,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 5, 1, 0, 3, 3, 2, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,  2274,   812,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,    11,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [14592,   389,  5033,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 5, 2, 0, 4, 1, 0, 5], device='cuda:0'), 'input_ids': tensor([[ 8061, 26760,  4327,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 4, 4, 0, 2, 4, 4, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [ 4366, 11155,  2897,  ..., 50256, 50256, 50256],\n",
      "        [ 1639,   815,  4341,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 7085,  6403, 19087,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   290,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 1, 5, 4, 5, 2, 0, 2], device='cuda:0'), 'input_ids': tensor([[ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [   82,   463,   444,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [10049,  1230,  2223,  ..., 50256, 50256, 50256],\n",
      "        [ 8061, 26760, 12444,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 0, 0, 3, 2, 0, 5, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  2444,  1064,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 5167,   661,  5409,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [   39, 12752, 28791,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 4, 5, 4, 0, 4, 1, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 7085,  2678,   389,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 5, 2, 2, 5, 4, 3, 2], device='cuda:0'), 'input_ids': tensor([[ 8888,    11,   661,  ..., 50256, 50256, 50256],\n",
      "        [ 1722,   880,   355,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 3844, 20544,   661,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 5, 4, 3, 1, 3, 5, 0], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 0, 3, 1, 2, 4, 2, 2], device='cuda:0'), 'input_ids': tensor([[  464,  2620,   287,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [11246,  2678,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 5, 1, 2, 2, 3, 0, 2], device='cuda:0'), 'input_ids': tensor([[ 1858,   318,   645,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 2, 2, 4, 2, 5, 3, 4], device='cuda:0'), 'input_ids': tensor([[  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 8888,    11,   661,  ..., 50256, 50256, 50256],\n",
      "        [  818,  2274,   812,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 0, 2, 0, 1, 4, 3, 5], device='cuda:0'), 'input_ids': tensor([[  818,  4736,   290,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 8061, 26760,  4327,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 7085, 17112,   290,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 0, 5, 3, 0, 3, 0, 5], device='cuda:0'), 'input_ids': tensor([[  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 5167,   661,  3066,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 3844, 20544,   661,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 4, 3, 5, 4, 5, 0, 5], device='cuda:0'), 'input_ids': tensor([[15354,   393,   407,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  3946,   973,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 3, 1, 0, 0, 5, 0, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [26130,    82,   815,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 1, 3, 5, 2, 1, 4, 2], device='cuda:0'), 'input_ids': tensor([[25714,   362,    25,  ..., 50256, 50256, 50256],\n",
      "        [42969,   815,  7898,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 6943,   286,   262,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 1, 0, 3, 4, 0, 3, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [19452,  6944,   286,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1064,  ..., 50256, 50256, 50256],\n",
      "        [20490,  4568,   423,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 2, 5, 1, 1, 0, 3, 2], device='cuda:0'), 'input_ids': tensor([[ 7085, 17112,   290,  ..., 50256, 50256, 50256],\n",
      "        [11246,   661,   220,  ..., 50256, 50256, 50256],\n",
      "        [ 1026,   318,  1593,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [45833,   905,   326,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 9444, 31260,   389,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 2, 5, 2, 3, 5, 2, 5], device='cuda:0'), 'input_ids': tensor([[ 7085,  1180,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   910,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 1, 3, 0, 0, 4, 1, 2], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,    11,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544, 21305,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 3, 0, 4, 2, 1, 4, 5], device='cuda:0'), 'input_ids': tensor([[  818,   617,  4736,  ..., 50256, 50256, 50256],\n",
      "        [10049,  1230,  2223,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,   517,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 5167,   661,  3066,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 3, 5, 1, 0, 2, 2, 4], device='cuda:0'), 'input_ids': tensor([[ 7085,   661,  7267,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 9492, 33571,  1296,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  7267,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 3844, 20544,    11,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([3, 4, 3, 4, 4, 5, 4, 3], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2284,  ..., 50256, 50256, 50256],\n",
      "        [  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 1, 1, 2, 5, 0, 1, 2], device='cuda:0'), 'input_ids': tensor([[11246,  2678,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [11246,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  2754,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([5, 4, 3, 0, 3, 0, 5, 5], device='cuda:0'), 'input_ids': tensor([[ 1026,   318,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [38897,  1975,   326,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([4, 0, 3, 5, 2, 3, 1, 4], device='cuda:0'), 'input_ids': tensor([[19452,  6944,   286,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  818,   867,  2678,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 5167,   290,   517,  ..., 50256, 50256, 50256],\n",
      "        [ 8807,  1160,     4,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([2, 3, 0, 3, 5, 2, 5, 5], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366, 11155,  2897,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 1129,    13,  7085,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([1, 3, 4, 3, 3, 2, 5, 4], device='cuda:0'), 'input_ids': tensor([[  464,  1266,   835,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [  464,   691,   835,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [18755,   353, 33571,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 9492, 33571,  1296,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "{'labels': tensor([0, 3, 1, 2, 3, 1, 1, 4], device='cuda:0'), 'input_ids': tensor([[ 4366,   661,  1975,  ..., 50256, 50256, 50256],\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,  1751,  1064,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4366,   661,   892,  ..., 50256, 50256, 50256],\n",
      "        [  818,   617,  2678,  ..., 50256, 50256, 50256],\n",
      "        [ 7085,   661,  1254,  ..., 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader2:\n",
    "    batch = {k: v.to(device2) for k, v in batch.items()}\n",
    "    print(batch)\n",
    "    # with torch.no_grad():\n",
    "    #     outputs = model2(**batch)\n",
    "\n",
    "    #     logits = outputs.logits\n",
    "    #     predictions = torch.argmax(logits, dim=-1)\n",
    "    #     # loss = F.cross_entropy(logits, batch[\"labels\"])\n",
    "\n",
    "    #     # epoch_val_loss += loss.item()\n",
    "    #     # f1_metric2(predictions, batch[\"labels\"])  # Update F1 metric with predictions\n",
    "    #     print(predictions)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination',\n",
      " '__annotations__',\n",
      " '__call__',\n",
      " '__class__',\n",
      " '__delattr__',\n",
      " '__dict__',\n",
      " '__dir__',\n",
      " '__doc__',\n",
      " '__eq__',\n",
      " '__format__',\n",
      " '__ge__',\n",
      " '__getattr__',\n",
      " '__getattribute__',\n",
      " '__getstate__',\n",
      " '__gt__',\n",
      " '__hash__',\n",
      " '__init__',\n",
      " '__init_subclass__',\n",
      " '__le__',\n",
      " '__lt__',\n",
      " '__module__',\n",
      " '__ne__',\n",
      " '__new__',\n",
      " '__reduce__',\n",
      " '__reduce_ex__',\n",
      " '__repr__',\n",
      " '__setattr__',\n",
      " '__setstate__',\n",
      " '__sizeof__',\n",
      " '__str__',\n",
      " '__subclasshook__',\n",
      " '__weakref__',\n",
      " '_apply',\n",
      " '_assisted_decoding',\n",
      " '_auto_class',\n",
      " '_autoset_attn_implementation',\n",
      " '_backward_compatibility_gradient_checkpointing',\n",
      " '_backward_hooks',\n",
      " '_backward_pre_hooks',\n",
      " '_beam_search',\n",
      " '_buffers',\n",
      " '_call_impl',\n",
      " '_check_and_enable_flash_attn_2',\n",
      " '_check_and_enable_sdpa',\n",
      " '_compiled_call_impl',\n",
      " '_constrained_beam_search',\n",
      " '_contrastive_search',\n",
      " '_convert_head_mask_to_5d',\n",
      " '_copy_lm_head_original_to_resized',\n",
      " '_create_repo',\n",
      " '_dispatch_accelerate_model',\n",
      " '_dola_decoding',\n",
      " '_expand_inputs_for_generation',\n",
      " '_extract_past_from_model_output',\n",
      " '_forward_hooks',\n",
      " '_forward_hooks_always_called',\n",
      " '_forward_hooks_with_kwargs',\n",
      " '_forward_pre_hooks',\n",
      " '_forward_pre_hooks_with_kwargs',\n",
      " '_from_config',\n",
      " '_get_backward_hooks',\n",
      " '_get_backward_pre_hooks',\n",
      " '_get_cache',\n",
      " '_get_candidate_generator',\n",
      " '_get_files_timestamps',\n",
      " '_get_initial_cache_position',\n",
      " '_get_logits_processor',\n",
      " '_get_name',\n",
      " '_get_no_split_modules',\n",
      " '_get_resized_embeddings',\n",
      " '_get_resized_lm_head',\n",
      " '_get_stopping_criteria',\n",
      " '_group_beam_search',\n",
      " '_has_unfinished_sequences',\n",
      " '_hf_peft_config_loaded',\n",
      " '_hook_rss_memory_post_forward',\n",
      " '_hook_rss_memory_pre_forward',\n",
      " '_init_added_embeddings_weights_with_mean',\n",
      " '_init_added_lm_head_bias_with_mean',\n",
      " '_init_added_lm_head_weights_with_mean',\n",
      " '_init_weights',\n",
      " '_initialize_weights',\n",
      " '_is_full_backward_hook',\n",
      " '_is_hf_initialized',\n",
      " '_is_quantized_training_enabled',\n",
      " '_is_stateful',\n",
      " '_keep_in_fp32_modules',\n",
      " '_keep_in_fp32_modules',\n",
      " '_keys_to_ignore_on_load_missing',\n",
      " '_keys_to_ignore_on_load_unexpected',\n",
      " '_keys_to_ignore_on_save',\n",
      " '_load_from_state_dict',\n",
      " '_load_pretrained_model',\n",
      " '_load_pretrained_model_low_mem',\n",
      " '_load_state_dict_post_hooks',\n",
      " '_load_state_dict_pre_hooks',\n",
      " '_maybe_initialize_input_ids_for_generation',\n",
      " '_maybe_warn_non_full_backward_hook',\n",
      " '_merge_criteria_processor_list',\n",
      " '_modules',\n",
      " '_named_members',\n",
      " '_no_split_modules',\n",
      " '_non_persistent_buffers_set',\n",
      " '_parameters',\n",
      " '_prepare_attention_mask_for_generation',\n",
      " '_prepare_cache_for_generation',\n",
      " '_prepare_decoder_input_ids_for_generation',\n",
      " '_prepare_encoder_decoder_kwargs_for_generation',\n",
      " '_prepare_generated_length',\n",
      " '_prepare_generation_config',\n",
      " '_prepare_model_inputs',\n",
      " '_prepare_special_tokens',\n",
      " '_register_load_state_dict_pre_hook',\n",
      " '_register_state_dict_hook',\n",
      " '_reorder_cache',\n",
      " '_replicate_for_data_parallel',\n",
      " '_resize_token_embeddings',\n",
      " '_sample',\n",
      " '_save_to_state_dict',\n",
      " '_set_default_torch_dtype',\n",
      " '_set_gradient_checkpointing',\n",
      " '_skip_keys_device_placement',\n",
      " '_slow_forward',\n",
      " '_state_dict_hooks',\n",
      " '_state_dict_pre_hooks',\n",
      " '_supports_cache_class',\n",
      " '_supports_default_dynamic_cache',\n",
      " '_supports_flash_attn_2',\n",
      " '_supports_num_logits_to_keep',\n",
      " '_supports_quantized_cache',\n",
      " '_supports_sdpa',\n",
      " '_supports_static_cache',\n",
      " '_temporary_reorder_cache',\n",
      " '_tie_encoder_decoder_weights',\n",
      " '_tie_or_clone_weights',\n",
      " '_tied_weights_keys',\n",
      " '_update_model_kwargs_for_generation',\n",
      " '_upload_modified_files',\n",
      " '_validate_assistant',\n",
      " '_validate_generated_length',\n",
      " '_validate_model_class',\n",
      " '_validate_model_kwargs',\n",
      " '_version',\n",
      " '_wrapped_call_impl',\n",
      " 'active_adapter',\n",
      " 'active_adapters',\n",
      " 'add_adapter',\n",
      " 'add_memory_hooks',\n",
      " 'add_model_tags',\n",
      " 'add_module',\n",
      " 'apply',\n",
      " 'base_model',\n",
      " 'base_model_prefix',\n",
      " 'bfloat16',\n",
      " 'buffers',\n",
      " 'call_super_init',\n",
      " 'can_generate',\n",
      " 'children',\n",
      " 'compile',\n",
      " 'compute_transition_scores',\n",
      " 'config',\n",
      " 'config_class',\n",
      " 'cpu',\n",
      " 'create_extended_attention_mask_for_decoder',\n",
      " 'cuda',\n",
      " 'dequantize',\n",
      " 'device',\n",
      " 'device_map',\n",
      " 'disable_adapters',\n",
      " 'disable_input_require_grads',\n",
      " 'double',\n",
      " 'dtype',\n",
      " 'dummy_inputs',\n",
      " 'dump_patches',\n",
      " 'enable_adapters',\n",
      " 'enable_input_require_grads',\n",
      " 'estimate_tokens',\n",
      " 'eval',\n",
      " 'extra_repr',\n",
      " 'float',\n",
      " 'floating_point_ops',\n",
      " 'forward',\n",
      " 'framework',\n",
      " 'from_pretrained',\n",
      " 'generate',\n",
      " 'generation_config',\n",
      " 'get_adapter_state_dict',\n",
      " 'get_buffer',\n",
      " 'get_extended_attention_mask',\n",
      " 'get_extra_state',\n",
      " 'get_head_mask',\n",
      " 'get_input_embeddings',\n",
      " 'get_memory_footprint',\n",
      " 'get_output_embeddings',\n",
      " 'get_parameter',\n",
      " 'get_position_embeddings',\n",
      " 'get_submodule',\n",
      " 'gradient_checkpointing_disable',\n",
      " 'gradient_checkpointing_enable',\n",
      " 'half',\n",
      " 'heal_tokens',\n",
      " 'init_weights',\n",
      " 'invert_attention_mask',\n",
      " 'ipu',\n",
      " 'is_gradient_checkpointing',\n",
      " 'is_parallelizable',\n",
      " 'load_adapter',\n",
      " 'load_state_dict',\n",
      " 'load_tf_weights',\n",
      " 'loss_function',\n",
      " 'main_input_name',\n",
      " 'model_parallel',\n",
      " 'model_tags',\n",
      " 'modules',\n",
      " 'name_or_path',\n",
      " 'named_buffers',\n",
      " 'named_children',\n",
      " 'named_modules',\n",
      " 'named_parameters',\n",
      " 'num_labels',\n",
      " 'num_parameters',\n",
      " 'parameters',\n",
      " 'post_init',\n",
      " 'prepare_inputs_for_generation',\n",
      " 'prune_heads',\n",
      " 'push_to_hub',\n",
      " 'register_backward_hook',\n",
      " 'register_buffer',\n",
      " 'register_for_auto_class',\n",
      " 'register_forward_hook',\n",
      " 'register_forward_pre_hook',\n",
      " 'register_full_backward_hook',\n",
      " 'register_full_backward_pre_hook',\n",
      " 'register_load_state_dict_post_hook',\n",
      " 'register_module',\n",
      " 'register_parameter',\n",
      " 'register_state_dict_pre_hook',\n",
      " 'requires_grad_',\n",
      " 'reset_memory_hooks_state',\n",
      " 'resize_position_embeddings',\n",
      " 'resize_token_embeddings',\n",
      " 'retrieve_modules_from_names',\n",
      " 'reverse_bettertransformer',\n",
      " 'save_pretrained',\n",
      " 'score',\n",
      " 'set_adapter',\n",
      " 'set_extra_state',\n",
      " 'set_input_embeddings',\n",
      " 'share_memory',\n",
      " 'state_dict',\n",
      " 'supports_gradient_checkpointing',\n",
      " 'tie_weights',\n",
      " 'to',\n",
      " 'to_bettertransformer',\n",
      " 'to_empty',\n",
      " 'train',\n",
      " 'training',\n",
      " 'transformer',\n",
      " 'type',\n",
      " 'warn_if_padding_and_no_attention_mask',\n",
      " 'warnings_issued',\n",
      " 'xpu',\n",
      " 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "model2\n",
    "pprint(dir(model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPT2ForSequenceClassification' object has no attribute 'classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter Name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\26597\\miniconda3\\envs\\ece1786\\lib\\site-packages\\torch\\nn\\modules\\module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GPT2ForSequenceClassification' object has no attribute 'classifier'"
     ]
    }
   ],
   "source": [
    "for name, param in model2.classifier.named_parameters():\n",
    "    print(f\"Parameter Name: {name}\")\n",
    "    print(f\"Shape: {param.shape}\")\n",
    "    print(f\"Requires Grad: {param.requires_grad}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
