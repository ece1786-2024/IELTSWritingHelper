{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Allocated: 0.0 MB\n",
      "Memory Reserved: 0.0 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "# Clear cache\n",
    "\n",
    "# For debugging purposes, check memory stats\n",
    "print(f\"Memory Allocated: {torch.cuda.memory_allocated() / 1e6} MB\")\n",
    "print(f\"Memory Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "model_path = \"andrijdavid/Llama-3-1B-Base\"\n",
    "llama3_model_path = \"meta-llama/Llama-3.2-1B\"\n",
    "file_path = \"../data/combined_dataset.csv\"\n",
    "example_file_path = \"../sample_data/llama3_sample_dataset.csv\"\n",
    "output_dir = \"../results/checkpoint-2400\"\n",
    "\n",
    "\n",
    "def create_input_text(row):\n",
    "    return (\n",
    "        f\"\"\"You are a member of the IELTS essay evaluation committee.\n",
    "        Your task is to evaluate the essay based on the given prompt and assign it a score\n",
    "        between 4 and 9 (in 0.5 increments). There is also a '<4' class, thus a total of 12 classes.\n",
    "        Provide only the score or '<4' as your response. Think step by step why this essay is good or bad.\n",
    "        \"Prompt: {row['prompt']}\\nEssay: {row['essay']}\"\"\"\n",
    "    )\n",
    "\n",
    "def map_band_to_class(band):\n",
    "    if band ==  \"<4\":\n",
    "        return band_to_class['<4']\n",
    "    return band_to_class[str(band)]\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"input_text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "band_classes = ['<4'] + ['4', '4.5', '5', '5.5', '6', '6.5', '7', '7.5', '8', '8.5', '9'] \n",
    "band_to_class = {band: i for i, band in enumerate(band_classes)}  # Band → Class\n",
    "class_to_band = {i: band for band, i in band_to_class.items()}  # Class → Band\n",
    "\n",
    "# Map bands to classes\n",
    "def map_band_to_class(band):\n",
    "    if band ==  \"<4\":\n",
    "        return band_to_class['<4']\n",
    "    return band_to_class[str(band)]\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"input_text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Model and Tokenizer, Move them to CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b75229a9ef64545bd0f7f1a2495b677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(example_file_path).head(3)\n",
    "data['input_text'] = data.apply(create_input_text, axis=1)\n",
    "data['labels'] = data['band'].apply(map_band_to_class)\n",
    "# Drop unnecessary columns. Might need them later\n",
    "data = data.drop(columns=[\"evaluation\", \"band\", \"prompt\", \"essay\"])\n",
    "\n",
    "# train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare datasets for Hugging Face Trainer\n",
    "from datasets import Dataset\n",
    "# train_dataset = Dataset.from_pandas(train_data)\n",
    "# test_dataset = Dataset.from_pandas(test_data)\n",
    "test_dataset = Dataset.from_pandas(data)\n",
    "\n",
    "# print(f\"Train dataset length: {len(train_dataset)}, Test dataset length: {len(test_dataset)}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(llama3_model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "# print(f\"train_dataset columns: {train_dataset.column_names}\")\n",
    "# print(f\"train_dataset[0]: {train_dataset[0]}, train_dataset['labels'][0]: {train_dataset['labels'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Allocated: 0.0 MB\n",
      "Memory Reserved: 0.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "882"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Memory Allocated: {torch.cuda.memory_allocated() / 1e6} MB\")\n",
    "print(f\"Memory Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "num_labels = 12  # Total number of unique band scores\n",
    "# C:\\Users\\26597\\.cache\\huggingface\\hub Models are here\n",
    "model_path = \"andrijdavid/Llama-3-1B-Base\"\n",
    "llama3_model_path = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    output_dir,\n",
    "    num_labels=num_labels,\n",
    ")\n",
    "t = model.config.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Freeze the base model\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Device: {device}\")\n",
    "# # Test the model\n",
    "# prompt = \"The key to life is\"\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "# outputs = model.generate(**inputs, max_length=30)\n",
    "\n",
    "# Decode the generated text\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a7acc5a1254ee089126312c8486091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Labels: ['6', '8.5', '8.5']\n",
      "Predicted Labels: ['7', '5.5', '7']\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    # per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    # num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    load_best_model_at_end=True,\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    ")\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prediction_labels = [class_to_band[p] for p in preds]\n",
    "    true_labels = [class_to_band[l] for l in labels]\n",
    "    print(f\"True Labels: {true_labels}\")\n",
    "    print(f\"Predicted Labels: {prediction_labels}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    return {\"accuracy\": acc}\n",
    "    \n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "# # Fine-tune the model\n",
    "# trainer.train()\n",
    "\n",
    "# # Evaluate on the test dataset\n",
    "# test_results = trainer.evaluate()\n",
    "# print(f\"Test Results: {test_results}\")\n",
    "\n",
    "predictions = trainer.predict(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
