{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import F1Score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"/Users/barrychen/Desktop/IELTSWritingHelper/datasets_ready/Lexical.csv\"\n",
    "df4 = pd.read_csv(fpath)\n",
    "# df4['score'] = df4['score'].round(1)\n",
    "# df_filtered4 = df4[(df4['score'] > 1.5) & (df4['score'] < 12.0)]\n",
    "\n",
    "# reverse_mapping_3 = {\n",
    "#     3.5: 0, 4.0: 0,\n",
    "#     4.5: 1, 5.0: 1,\n",
    "#     5.5: 2, 6.0: 2,\n",
    "#     6.5: 3, 7.0: 3,\n",
    "#     7.5: 4, 8.0: 4,\n",
    "#     8.5: 5, 9.0: 5\n",
    "# }\n",
    "\n",
    "# df_filtered4['score'] = df_filtered4['score'].map(reverse_mapping_3)\n",
    "\n",
    "# df_sampled4 = df_filtered4.groupby('score').sample(\n",
    "#     n=290, \n",
    "#     random_state=42\n",
    "# ).reset_index(drop=True)\n",
    "\n",
    "# df_sampled4['score'] = df_sampled4['score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7117.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1319.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>45.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8.50</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8.00</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.50</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.00</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.50</td>\n",
       "      <td>1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.00</td>\n",
       "      <td>2343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.50</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.00</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.50</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.00</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.50</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.00</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.50</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.00</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.00</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  count\n",
       "0   10000.00      1\n",
       "1    7117.00      1\n",
       "2    2019.00      1\n",
       "3    2018.00      1\n",
       "4    2012.00      1\n",
       "5    2000.00      1\n",
       "6    1319.00      1\n",
       "7     100.00      1\n",
       "8      80.00      1\n",
       "9      60.00      1\n",
       "10     45.00      2\n",
       "11     30.00      2\n",
       "12     24.00      3\n",
       "13     23.00      1\n",
       "14     20.00      3\n",
       "15     18.00      2\n",
       "16     16.00      1\n",
       "17     15.00      2\n",
       "18     10.00      1\n",
       "19      9.00      2\n",
       "20      8.50     23\n",
       "21      8.00    313\n",
       "22      7.50    411\n",
       "23      7.25      1\n",
       "24      7.00   1413\n",
       "25      6.50   1167\n",
       "26      6.00   2343\n",
       "27      5.54      1\n",
       "28      5.50    877\n",
       "29      5.00    788\n",
       "30      4.50     61\n",
       "31      4.00    749\n",
       "32      3.50    339\n",
       "33      3.00    665\n",
       "34      2.50    104\n",
       "35      2.00    326\n",
       "36      1.50      3\n",
       "37      1.00    130\n",
       "38      0.00     16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts_df = df4[\"score\"].value_counts().reset_index()\n",
    "value_counts_df.columns = [\"score\", \"count\"]\n",
    "value_counts_df = value_counts_df.sort_values(by=\"score\", ascending=False).reset_index(drop=True)\n",
    "value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vx/57ntql9x3lg7fsldp3xp6w1c0000gn/T/ipykernel_13740/4189222091.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled = df_filtered.groupby('score', group_keys=False).apply(\n",
      "/var/folders/vx/57ntql9x3lg7fsldp3xp6w1c0000gn/T/ipykernel_13740/4189222091.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled = df_filtered.groupby('score', group_keys=False).apply(\n",
      "/var/folders/vx/57ntql9x3lg7fsldp3xp6w1c0000gn/T/ipykernel_13740/4189222091.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled = df_filtered.groupby('score', group_keys=False).apply(\n",
      "/var/folders/vx/57ntql9x3lg7fsldp3xp6w1c0000gn/T/ipykernel_13740/4189222091.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled = df_filtered.groupby('score', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "def df_sampling(fpath):\n",
    "    df = pd.read_csv(fpath)\n",
    "    df['score'] = df['score'].round(1)\n",
    "    df_filtered = df[df['score'].isin([3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0])]\n",
    "    reverse_mapping = {\n",
    "        3.5: 0, 4.0: 0,\n",
    "        4.5: 1, 5.0: 1,\n",
    "        5.5: 2, 6.0: 2,\n",
    "        6.5: 3, 7.0: 3,\n",
    "        7.5: 4, 8.0: 4,\n",
    "        8.5: 5, 9.0: 5\n",
    "    }\n",
    "    df_filtered['score'] = df_filtered['score'].map(reverse_mapping)\n",
    "\n",
    "    # n = 50\n",
    "    # df_sampled = df_filtered.groupby('score').sample(\n",
    "    #     n=n, \n",
    "    #     random_state=42\n",
    "    #     ).reset_index(drop=True)\n",
    "\n",
    "    df_sampled = df_filtered.groupby('score', group_keys=False).apply(\n",
    "        lambda x: x.sample(len(x), random_state=42)\n",
    "        ).reset_index(drop=True)\n",
    "    \n",
    "    df_sampled['score'] = df_sampled['score'].astype(int)\n",
    "\n",
    "    return df_sampled\n",
    "\n",
    "fpath_ta = \"/Users/barrychen/Desktop/IELTSWritingHelper/datasets_ready/Task_Achievement.csv\"\n",
    "fpath_co = \"/Users/barrychen/Desktop/IELTSWritingHelper/datasets_ready/Coherence.csv\"\n",
    "fpath_le = \"/Users/barrychen/Desktop/IELTSWritingHelper/datasets_ready/Lexical.csv\"\n",
    "fpath_gr = \"/Users/barrychen/Desktop/IELTSWritingHelper/datasets_ready/Grammatical.csv\"\n",
    "\n",
    "df_ta = df_sampling(fpath_ta)\n",
    "df_co = df_sampling(fpath_co)\n",
    "df_le = df_sampling(fpath_le)\n",
    "df_gr = df_sampling(fpath_gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>essay</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Some people say that to prevent illness and di...</td>\n",
       "      <td>Emerging disease is a complex matter as it IS ...</td>\n",
       "      <td>The candidate has effectively addressed the gi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nowadays celebrities are more famous for their...</td>\n",
       "      <td>In this present world,  famous personalities a...</td>\n",
       "      <td>The essay adequately addresses the task and at...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>More people decided to have children in their ...</td>\n",
       "      <td>currently, there are more and more people make...</td>\n",
       "      <td>The essay generally addresses the task by disc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Many people believe that the current system of...</td>\n",
       "      <td>Once every month no private vehicles  a day ca...</td>\n",
       "      <td>The essay fails to address the prompt effectiv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some people think that instead of preventing c...</td>\n",
       "      <td>In today's time, human activities are having a...</td>\n",
       "      <td>The essay effectively addresses the given task...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Some people say that to prevent illness and di...   \n",
       "1  Nowadays celebrities are more famous for their...   \n",
       "2  More people decided to have children in their ...   \n",
       "3  Many people believe that the current system of...   \n",
       "4  Some people think that instead of preventing c...   \n",
       "\n",
       "                                               essay  \\\n",
       "0  Emerging disease is a complex matter as it IS ...   \n",
       "1  In this present world,  famous personalities a...   \n",
       "2  currently, there are more and more people make...   \n",
       "3  Once every month no private vehicles  a day ca...   \n",
       "4  In today's time, human activities are having a...   \n",
       "\n",
       "                                                text  score  \n",
       "0  The candidate has effectively addressed the gi...      0  \n",
       "1  The essay adequately addresses the task and at...      0  \n",
       "2  The essay generally addresses the task by disc...      0  \n",
       "3  The essay fails to address the prompt effectiv...      0  \n",
       "4  The essay effectively addresses the given task...      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barrychen/anaconda3/envs/ece1786/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at mrm8488/deberta-v3-ft-financial-news-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/vx/57ntql9x3lg7fsldp3xp6w1c0000gn/T/ipykernel_13740/2724072977.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f))\n",
      "/Users/barrychen/anaconda3/envs/ece1786/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from deberta_9k_ep15_4597.pt\n"
     ]
    }
   ],
   "source": [
    "# Specify the file name from which to load the model\n",
    "modelsavename = \"deberta_9k_ep15_4597.pt\"\n",
    "\n",
    "# Initialize the same model architecture\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\",num_labels=6, ignore_mismatched_sizes=True)\n",
    "\n",
    "# Load the saved state_dict into the model\n",
    "with open(modelsavename, \"rb\") as f:\n",
    "    model.load_state_dict(torch.load(f))\n",
    "\n",
    "# Move model to the device (GPU if available)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\")\n",
    "\n",
    "print(f\"Model loaded from {modelsavename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(input_text):\n",
    "  # Tokenize input and get model output\n",
    "  inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "  # Get logits (output for classification)\n",
    "  outputs = model(**inputs)\n",
    "  logits = outputs.logits\n",
    "\n",
    "  # Convert logits to probabilities using softmax\n",
    "#   probs = softmax(logits, dim=1)\n",
    "\n",
    "  # Map classes to polarity values\n",
    "#   polarity_values = torch.tensor([-1.0, 0.0, 1.0])\n",
    "\n",
    "  # Calculate polarity score as the weighted sum of probabilities\n",
    "#   polarity_score = torch.sum(probs * polarity_values, dim=1).item()\n",
    "\n",
    "  # Get the predicted class (optional, for reference)\n",
    "  predicted_class = logits.argmax(dim=1).item()\n",
    "\n",
    "  return predicted_class\n",
    "\n",
    "def compute_mae(df):\n",
    "    df['score_pred'] = df.apply(lambda row: get_class(row['prompt'] + row['essay'] + row['text']), axis=1)\n",
    "    mae = mean_absolute_error(df['score'], df['score_pred'])\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for task achievement is 0.5481417083242773\n"
     ]
    }
   ],
   "source": [
    "mae_ta = compute_mae(df_ta)\n",
    "print('MAE for task achievement is', mae_ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barrychen/anaconda3/envs/ece1786/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at mrm8488/deberta-v3-ft-financial-news-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/vx/57ntql9x3lg7fsldp3xp6w1c0000gn/T/ipykernel_13740/688501456.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_co.load_state_dict(torch.load(f))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from COHERENCE_EPOCH4_F10.4253.pt\n"
     ]
    }
   ],
   "source": [
    "# Specify the file name from which to load the model\n",
    "modelsavename_co = \"COHERENCE_EPOCH4_F10.4253.pt\"\n",
    "\n",
    "# Initialize the same model architecture\n",
    "model_co = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\",num_labels=6, ignore_mismatched_sizes=True)\n",
    "\n",
    "# Load the saved state_dict into the model\n",
    "with open(modelsavename_co, \"rb\") as f:\n",
    "    model_co.load_state_dict(torch.load(f))\n",
    "\n",
    "# Move model to the device (GPU if available)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_co.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\")\n",
    "\n",
    "print(f\"Model loaded from {modelsavename_co}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for coherence is 0.6632443531827515\n"
     ]
    }
   ],
   "source": [
    "mae_co = compute_mae(df_co)\n",
    "print('MAE for coherence is', mae_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barrychen/anaconda3/envs/ece1786/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at mrm8488/deberta-v3-ft-financial-news-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/vx/57ntql9x3lg7fsldp3xp6w1c0000gn/T/ipykernel_13740/934866803.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_le.load_state_dict(torch.load(f))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from Lexical_epoch5.pt\n"
     ]
    }
   ],
   "source": [
    "# Specify the file name from which to load the model\n",
    "modelsavename_le = \"Lexical_epoch5.pt\"\n",
    "\n",
    "# Initialize the same model architecture\n",
    "model_le = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\",num_labels=6, ignore_mismatched_sizes=True)\n",
    "\n",
    "# Load the saved state_dict into the model\n",
    "with open(modelsavename_le, \"rb\") as f:\n",
    "    model_le.load_state_dict(torch.load(f))\n",
    "\n",
    "# Move model to the device (GPU if available)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_le.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\")\n",
    "\n",
    "print(f\"Model loaded from {modelsavename_le}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for lexical is 0.6453399316601862\n"
     ]
    }
   ],
   "source": [
    "mae_le = compute_mae(df_le)\n",
    "print('MAE for lexical is', mae_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barrychen/anaconda3/envs/ece1786/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at mrm8488/deberta-v3-ft-financial-news-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/vx/57ntql9x3lg7fsldp3xp6w1c0000gn/T/ipykernel_13740/3790183536.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_gr.load_state_dict(torch.load(f))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from grammatical_epoch4_F10.5099.pt\n"
     ]
    }
   ],
   "source": [
    "# Specify the file name from which to load the model\n",
    "modelsavename_gr = \"grammatical_epoch4_F10.5099.pt\"\n",
    "\n",
    "# Initialize the same model architecture\n",
    "model_gr = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\",num_labels=6, ignore_mismatched_sizes=True)\n",
    "\n",
    "# Load the saved state_dict into the model\n",
    "with open(modelsavename_gr, \"rb\") as f:\n",
    "    model_gr.load_state_dict(torch.load(f))\n",
    "\n",
    "# Move model to the device (GPU if available)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_gr.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\")\n",
    "\n",
    "print(f\"Model loaded from {modelsavename_gr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for grammatical is 0.6624760536398467\n"
     ]
    }
   ],
   "source": [
    "mae_gr = compute_mae(df_gr)\n",
    "print('MAE for grammatical is', mae_gr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece1786",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
