{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, AdamW, get_scheduler, GPT2Config\n",
    "from torch.nn.functional import softmax\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchmetrics import F1Score\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath2 = \"/Users/barrychen/Desktop/IELTSWritingHelper/datasets_ready/Task_Achievement.csv\"\n",
    "df2 = pd.read_csv(fpath2)\n",
    "df2['score'] = df2['score'].round(1)\n",
    "df_filtered2 = df2[(df2['score'] > 1.5) & (df2['score'] < 12.0)]\n",
    "\n",
    "reverse_mapping_3 = {\n",
    "    3.5: 0, 4.0: 0,\n",
    "    4.5: 1, 5.0: 1,\n",
    "    5.5: 2, 6.0: 2,\n",
    "    6.5: 3, 7.0: 3,\n",
    "    7.5: 4, 8.0: 4,\n",
    "    8.5: 5, 9.0: 5\n",
    "}\n",
    "\n",
    "df_filtered2['score'] = df_filtered2['score'].map(reverse_mapping_3)\n",
    "\n",
    "df_sampled2 = df_filtered2.groupby('score').sample(\n",
    "    n=290, \n",
    "    random_state=42\n",
    ").reset_index(drop=True)\n",
    "\n",
    "df_sampled2['score'] = df_sampled2['score'].astype(int)\n",
    "\n",
    "dataset2 = Dataset.from_pandas(df_sampled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels_2 = 6\n",
    "\n",
    "# Move model2 to device (GPU if available)\n",
    "device2 = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Set up configuration and add pad token ID\n",
    "configuration2 = GPT2Config.from_pretrained(\"openai-community/gpt2-xl\")\n",
    "configuration2.pad_token_id = configuration2.eos_token_id  # Use eos_token_id as the pad token\n",
    "configuration2.num_labels = num_labels_2  # Update the number of labels\n",
    "\n",
    "# Load tokenizer and set pad token\n",
    "tokenizer2 = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2-xl\")\n",
    "tokenizer2.pad_token = tokenizer2.eos_token  # Set pad token to eos token\n",
    "\n",
    "# Load model with configuration\n",
    "model2 = GPT2ForSequenceClassification.from_pretrained(\n",
    "    \"openai-community/gpt2-xl\", \n",
    "    config=configuration2, \n",
    "    ignore_mismatched_sizes=True\n",
    ").to(device2)\n",
    "\n",
    "# Freeze GPT-2 transformer layers\n",
    "for param in model2.transformer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    # Concatenate the input columns for each example in the batch\n",
    "    combined_text = [\n",
    "        p + \" \" + e + \" \" + t for p, e, t in zip(examples[\"prompt\"], examples[\"essay\"], examples[\"text\"])\n",
    "    ]\n",
    "    # Tokenize the concatenated text\n",
    "    return tokenizer2(combined_text, padding=\"max_length\", truncation=True, max_length=1024)\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_datasets2 = dataset2.map(tokenize_function, batched=True)\n",
    "tokenized_datasets2 = tokenized_datasets2.remove_columns([\"prompt\", \"essay\", \"text\"])\n",
    "tokenized_datasets2 = tokenized_datasets2.rename_column(\"score\", \"labels\")\n",
    "tokenized_datasets2.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Get the labels from the tokenized dataset\n",
    "labels2 = tokenized_datasets2[\"labels\"]\n",
    "\n",
    "# Get the unique labels\n",
    "unique_labels2 = np.unique(labels2)\n",
    "\n",
    "# Store the indices for each label\n",
    "label_to_indices2 = {label: np.where(labels2 == label)[0] for label in unique_labels2}\n",
    "\n",
    "# Lists to hold the train and validation indices\n",
    "train_indices2 = []\n",
    "val_indices2 = []\n",
    "\n",
    "# For each label, split the indices into train and validation\n",
    "for label, indices in label_to_indices2.items():\n",
    "    # Shuffle the indices within each label to ensure random splitting\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Split 80% for training, 20% for validation\n",
    "    split_idx2 = int(0.8 * len(indices))\n",
    "    train_indices2.extend(indices[:split_idx2])\n",
    "    val_indices2.extend(indices[split_idx2:])\n",
    "\n",
    "# Convert indices to tensors\n",
    "train_indices2 = torch.tensor(train_indices2)\n",
    "val_indices2 = torch.tensor(val_indices2)\n",
    "\n",
    "# Create Subsets for train and validation datasets\n",
    "train_dataset2 = Subset(tokenized_datasets2, train_indices2)\n",
    "eval_dataset2 = Subset(tokenized_datasets2, val_indices2)\n",
    "\n",
    "# Dataloaders\n",
    "train_dataloader2 = DataLoader(train_dataset2, shuffle=True, batch_size=8)\n",
    "eval_dataloader2 = DataLoader(eval_dataset2, batch_size=8)\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "# optimizer2 = AdamW(model2.parameters(), lr=1e-5)\n",
    "\n",
    "# Ensure only the classification head is trainable\n",
    "optimizer2 = AdamW(filter(lambda p: p.requires_grad, model2.parameters()), lr=1e-5)\n",
    "\n",
    "num_epochs2 = 3\n",
    "num_training_steps2 = num_epochs2 * len(train_dataloader2)\n",
    "lr_scheduler2 = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer2, num_warmup_steps=0, num_training_steps=num_training_steps2\n",
    ")\n",
    "\n",
    "# Initialize lists to track training/validation losses and accuracies\n",
    "train_losses2 = []\n",
    "val_losses2 = []\n",
    "val_f1_scores2 = []\n",
    "\n",
    "# Training loop\n",
    "progress_bar2 = tqdm(range(num_training_steps2))\n",
    "\n",
    "# Initialize F1 score metric (weighted-averaged for multi-class classification)\n",
    "f1_metric2 = F1Score(task=\"multiclass\", num_classes=num_labels_2, average=\"weighted\").to(device2)\n",
    "\n",
    "for epoch in range(num_epochs2):\n",
    "    epoch_train_loss = 0\n",
    "    epoch_val_loss = 0\n",
    "    f1_metric2.reset()\n",
    "    model2.train()\n",
    "\n",
    "    for batch in train_dataloader2:\n",
    "        batch = {k: v.to(device2) for k, v in batch.items()}\n",
    "        outputs = model2(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        lr_scheduler2.step()\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "        progress_bar2.update(1)\n",
    "\n",
    "    # Record training loss for the epoch\n",
    "    train_losses2.append(epoch_train_loss / len(train_dataloader2))\n",
    "\n",
    "    # Evaluate the model2\n",
    "    model2.eval()\n",
    "    for batch in eval_dataloader2:\n",
    "        batch = {k: v.to(device2) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model2(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        loss = F.cross_entropy(logits, batch[\"labels\"])\n",
    "\n",
    "        epoch_val_loss += loss.item()\n",
    "        f1_metric2(predictions, batch[\"labels\"])  # Update F1 metric with predictions\n",
    "\n",
    "    # Record validation loss and accuracy\n",
    "    val_losses2.append(epoch_val_loss / len(eval_dataloader2))\n",
    "    val_f12 = f1_metric2.compute().item()\n",
    "    val_f1_scores2.append(val_f12)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs2}: train loss {train_losses2[-1]:.4f}, val loss {val_losses2[-1]:.4f}, val accuracy {val_f1_scores2[-1]:.4f}\")\n",
    "\n",
    "# Plotting function\n",
    "def eval_plot(train_losses, val_losses, val_f1_scores):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    # Validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, val_f1_scores, label=\"Validation F1\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.title('Validation F1')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot train loss, validation loss, validation accuracy\n",
    "eval_plot(train_losses2, val_losses2, val_f1_scores2)\n",
    "\n",
    "# Print final validation accuracy\n",
    "print(f\"Final validation F1: {val_f1_scores2[-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece1786",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
