{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import F1Score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from comment import category as comment_categories\n",
    "from comment import generate_comment\n",
    "\n",
    "import math\n",
    "\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping_3 = {\n",
    "    3.5: 0, 4.0: 0,\n",
    "    4.5: 1, 5.0: 1,\n",
    "    5.5: 2, 6.0: 2,\n",
    "    6.5: 3, 7.0: 3,\n",
    "    7.5: 4, 8.0: 4,\n",
    "    8.5: 5, 9.0: 5\n",
    "}\n",
    "\n",
    "class_mapping = {\n",
    "    0: \"3.5 - 4.0\",\n",
    "    1: \"4.5 - 5.0\",\n",
    "    2: \"5.5 - 6.0\",\n",
    "    3: \"6.5 - 7.0\",\n",
    "    4: \"7.5 - 8.0\",\n",
    "    5: \"8.5 - 9.0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at mrm8488/deberta-v3-ft-financial-news-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\20838\\AppData\\Local\\Temp\\ipykernel_57072\\1972804818.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at mrm8488/deberta-v3-ft-financial-news-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at mrm8488/deberta-v3-ft-financial-news-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "classifier_categories = ['task_achievement', \n",
    "              'grammatical',\n",
    "              'coherence',\n",
    "              # 'lexical'  # not available\n",
    "              ]\n",
    "models = []\n",
    "\n",
    "for category in classifier_categories:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\",num_labels=6, ignore_mismatched_sizes=True)\n",
    "    # Load the saved state_dict into the model\n",
    "    with open(f'models/{category}.pt', \"rb\") as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "\n",
    "    # Move model to the device (GPU if available)\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    models.append(model)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" Some people feel that with the rise of artificial intelligence, computers and robots will take over the roles of teachers. To what extent do you agree or disagree with this statement? \n",
    "Give reasons for your answer and include any relevant examples from your knowledge or experience. \n",
    "You should write at least 250 words. \"\"\"\n",
    "\n",
    "essay = \"\"\" With ever increasing technological advances, computers and robots are replacing human roles in different areas of society. This trend can also be seen in education, where interactive programs can enhance the educational experience for children and young adults. Whether, however, this revolution can also take over the role of the teacher completely is debatable, and I oppose this idea as it is unlikely to serve students well. \n",
    "The roles of computers and robots can be seen in many areas of the workplace. Classic examples are car factories, where a lot of the repetitive precision jobs done on assembly lines have been performed by robots for many years, and medicine, where diagnosis, and treatment, including operations, have also been assisted by computers for a long time. According to the media, it won't also be long until we have cars that are driven automatically. \n",
    "It has long been discussed whether robots and computers can do this in education. It is well known that the complexity of programs can now adapt to so many situations that something can already be set up that has the required knowledge of the teacher, along with the ability to predict and answer all questions that might be asked by students. In fact, due to the nature of computers, the knowledge levels can far exceed a teacher's and have more breadth, as a computer can have equal knowledge in all the subjects that are taught in school, as opposed to a single teacher's specialisation. It seems very likely, therefore, that computers and robots should be able to deliver the lessons that teachers can, including various ways of differentiating and presenting materials to suit varying abilities and ages of students. \n",
    "Where I am not convinced is in the pastoral role of teachers. Part of teaching is managing behaviour and showing empathy with students, so that they feel cared for and important. Even if a robot or computer can be programmed to imitate these actions, students will likely respond in a different way when they know an interaction is part of an algorithm rather than based on human emotion. \n",
    "Therefore, although I feel that computers should be able to perform a lot of the roles of teachers in the future, they should be used as educational tools to assist teachers and not to replace them. In this way, students would receive the benefits of both ways of instruction. \n",
    "\"\"\"\n",
    "# comment = \"\"\"Will the comment affect the overall score?\"\"\"\n",
    "\n",
    "example_input1 = f\"\"\"Prompt: {prompt}\n",
    "Essay: {essay}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline 1: generate comment\n",
    "comments = []\n",
    "for each in comment_categories:\n",
    "    # print(each)\n",
    "    comment = generate_comment(prompt, essay, each)\n",
    "    comments.append(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The essay effectively addresses the prompt by presenting a clear position against the complete takeover of teaching roles by computers and robots. It discusses relevant examples from both technology in the workplace and the specific context of education, illustrating the potential advantages of AI while emphasizing the irreplaceable human qualities of teachers. However, there could be more development of ideas; for instance, the paragraph on the pastoral role of teachers, while strong, could include specific examples to enhance its impact. Overall, the response demonstrates a good understanding of the task, with a clear stance and logical argumentation, but it could benefit from deeper exploration of certain points.\n",
      "The essay effectively addresses the task by presenting a clear position against the notion that computers and robots can entirely replace teachers. The introduction sets the tone well, and the progression of ideas is logical. Each paragraph focuses on a central topic: the potential roles of technology in education and the importance of the human element in teaching. However, the development of ideas could be strengthened; some points are overly general, such as the mention of \"different areas of the workplace\" without specifics. Moreover, transitions between ideas could be smoother to enhance cohesion. Overall, there is a clear position and relevant examples, but further development and clarity would improve the response.\n",
      "The essay demonstrates a generally adequate range of vocabulary, addressing the task while effectively communicating the author's opinion. Phrases like “technological advances” and “interactive programs enhance the educational experience” show effective use of less common vocabulary. However, there is occasional imprecision, such as in “the complexity of programs can now adapt to so many situations,” which could benefit from more specific language. The overall word choice is mostly appropriate, yet some phrasing, like “the roles of computers and robots can be seen in many areas of the workplace,” feels slightly vague and could be refined for clarity. Overall, while the lexical resource is sufficient, there is room for improvement in precision and variety to enhance clarity and depth.\n",
      "The essay effectively addresses the task by clearly presenting a position against the idea that computers and robots can entirely replace teachers. The introduction outlines the topic well, and the arguments are relevant and structured logically with distinct paragraphs. However, there are instances of grammatical inaccuracies, such as the phrase \"where diagnosis, and treatment,\" which incorrectly includes a comma. Additionally, while the essay shows a good range of vocabulary and complex sentence structures, occasional errors, like \"something can already be set up that has the required knowledge of the teacher,\" detract slightly from clarity. Overall, the essay demonstrates a decent grasp of grammatical range but could benefit from more precise sentence construction.\n"
     ]
    }
   ],
   "source": [
    "for each in comments:\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass downstream to provide band score for each categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Achievement: 6.5 - 7.0\n",
      "Coherence and Cohesion: 6.5 - 7.0\n",
      "Lexical Resource: 5.5 - 6.0\n"
     ]
    }
   ],
   "source": [
    "classifier_output = []\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    classifier_input = f\"Prompt: {prompt}\\n\\nEssay:{essay}\\n\\nComment: {comments[i]}\"\n",
    "    inputs = tokenizer(classifier_input, return_tensors=\"pt\").to(device)\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = logits.argmax(dim=1).item()\n",
    "    classifier_output.append(predicted_class)\n",
    "\n",
    "    print(f\"{comment_categories[i]}: {class_mapping[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average to get final band score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 2]\n",
      "2.6666666666666665\n",
      "final band score: 6.5 - 7.0\n"
     ]
    }
   ],
   "source": [
    "print(classifier_output)\n",
    "avg = sum(classifier_output) / len(classifier_output)\n",
    "print(avg)\n",
    "\n",
    "final_band_score = math.ceil(avg)\n",
    "\n",
    "print(f'final band score: {class_mapping[final_band_score]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, provide tips for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI: Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def process_input(prompt, essay):\n",
    "    \"\"\"\n",
    "    Processes the given prompt and essay, checking word counts and returning feedback.\n",
    "    \"\"\"\n",
    "    comments = []\n",
    "    for each in comment_categories:\n",
    "        yield f\"Generating comments for {each} ...\"\n",
    "        comment = generate_comment(prompt, essay, each)\n",
    "        # comment = \"debug\"\n",
    "        comments.append(comment)\n",
    "        time.sleep(1)  # avoid OpenAI firewall\n",
    "\n",
    "    yield \"Generating comments complete ... Calculating suggested band score\"\n",
    "    \n",
    "    classifier_output = []\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        classifier_input = f\"Prompt: {prompt}\\n\\nEssay:{essay}\\n\\nComment: {comments[i]}\"\n",
    "        inputs = tokenizer(classifier_input, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = logits.argmax(dim=1).item()\n",
    "        classifier_output.append(predicted_class)\n",
    "\n",
    "    avg = sum(classifier_output) / len(classifier_output)\n",
    "    final_band_score = math.ceil(avg)\n",
    "    final_band_score = class_mapping[final_band_score]\n",
    "\n",
    "    output = \"\"\n",
    "    for i in range(len(classifier_categories)):\n",
    "        output += (f\"- {comment_categories[i]}:\\n\"\n",
    "                   f\"- {comments[i]}\\n\"\n",
    "                   f\"- Suggested Band Score ({comment_categories[i]}): {class_mapping[classifier_output[i]]}\\n\\n\")\n",
    "    \n",
    "    output += f\"Suggested overall Band Score: {final_band_score}\\n\\n\"\n",
    "\n",
    "    output += f\"Tips for improvement: \\nCurrently unavailable\"  # TODO\n",
    "\n",
    "    yield output\n",
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    ### Prompt and Essay Input\n",
    "    Please provide a **prompt** (about 100 words) and an **essay** (250-300 words).\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        prompt_input = gr.Textbox(\n",
    "            label=\"Prompt (about 100 words)\",\n",
    "            placeholder=\"Enter your prompt here (approximately 100 words)...\",\n",
    "            lines=7  # Approximate height for 100 words\n",
    "        )\n",
    "        essay_input = gr.Textbox(\n",
    "            label=\"Essay (250-300 words)\",\n",
    "            placeholder=\"Enter your essay here (approximately 250-300 words)...\",\n",
    "            lines=15  # Approximate height for 300 words\n",
    "        )\n",
    "\n",
    "    submit_button = gr.Button(\"Submit\")\n",
    "    output = gr.Textbox(label=\"Output\", lines=25, interactive=False)\n",
    "\n",
    "    submit_button.click(process_input, inputs=[prompt_input, essay_input], outputs=output)\n",
    "\n",
    "# Launch the Gradio app\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece1786",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
